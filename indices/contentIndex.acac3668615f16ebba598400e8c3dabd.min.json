{"/":{"title":"🪴","content":"\n치즈 나무 지식 걸렸네 🧀🌲\n\n## All notes 📝\n\n- [All notes](/notes/)\n- [All tags](/tags/)\n","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/%EB%B9%84%ED%8A%B8%EC%BD%94%EC%9D%B8":{"title":"비트코인","content":"\n- 그래픽카드가 비싸진 이유는 비트코인때문이라는 말이 많지만, 이제 채굴 난이도가 높아서 ASIC 비트코인 채굴 전용 기계가 아니면 무용지물이다. ","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/%EC%8A%A4%ED%85%8C%EC%9D%B4%EB%B8%94%EC%BD%94%EC%9D%B8":{"title":"스테이블코인","content":"\n## References\n","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/%EC%9D%B4%EB%8D%94%EB%A6%AC%EC%9B%80-2.0":{"title":"이더리움 2.0","content":"- PoW(작업증명) 으로 보완하지 못했던 부분들을 \n- PoS(지분증명)의 시간 단위는 슬롯과 에팍\n\n## 밸리데이터 \n- 보증금 32ETH 를 예치하여야 한다.\n- 역할 \n\t- 밸리데이터 집단을 저장 및 유지 관리 \n\t- Crosslinks 처리\n\t- 블록 합의 처리\n\n## 슬롯 (slot)\n- 시간의 가장 작은 단위 \n- 12초 = 1 슬롯 (1 슬롯당 1개의 블록 형성)\n- 32슬롯 = 1 에팍. 즉 384초 = 1 에팍\n\n## 에팍 (epoch)\n- 매 에팍마다 모든 밸리데이터들에게 임무가 주어짐 \n- 1 에팍 = 32 슬롯 이므로, 32 밸리데이터를 선택, 각 슬롯에 배치\n\t- 이들이 블록 프로듀서. 블록을 만듬\n\t- 이 밸리데이터들은 블록 만들고 검증도 하여 \"노드 위원회\" 라고도 부른다.\n\t- 2/3 노드 위원회가 이 블록이 정확하다 승인하면 검증이 완료 됨. \n- 모든 검증이 완료되면 다음 에팍에서 새로운 슬롯에 각 밸리데이터들 배치 \n\n## 비콘체인\n- 밸리데이터들을 램덤하게 배치하고 상태 저장 관리.\n\n## References\n- [해시넷 - 슬롯](http://wiki.hash.kr/index.php/%EC%8A%AC%EB%A1%AF_(%EB%B8%94%EB%A1%9D%EC%B2%B4%EC%9D%B8))\n- [# Ethereum 2.0 Phase 0 -- Beacon Chain Fork Choice](https://github.com/ethereum/annotated-spec/blob/master/phase0/fork-choice.md)","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/%ED%95%98%EB%93%9C%ED%8F%AC%ED%81%AC":{"title":"하드포크","content":"\n- 블록체인 업그레이드 작업\n- 기존 블록체인에서 다른 블로체인으로 넘어갈때 사용하는 방식\n\n## 이유 \n- 기술적 문제 혹은 보안 개선을 위해\n- 새로운 기능을 추가 하기 위해 \n- 거래 반전을 위해","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/ABI":{"title":"ABI","content":"\n- Contract **A**pplication **B**inary **I**nterface\n- Smart Contract 함수와 파라미터에 대한 Interface 정의 \n- 가지고 있는 정보\n\t- 함수에 대한 **정보** \n\t- 함수에서 사용하는 **인수**\n![](https://static.packt-cdn.com/products/9781789954111/graphics/assets/fe0f2ffc-2f3c-4615-9cb5-43c8e036239b.png)\n- 예시 : https://etherscan.io/address/0xb59f67a8bff5d8cd03f6ac17265c550ed8f33907#code\n```json\n{\n   \"anonymous\":false,\n   \"inputs\":[\n      {\n         \"indexed\":true,\n         \"name\":\"from\",\n         \"type\":\"address\"\n      },\n      {\n         \"indexed\":true,\n         \"name\":\"to\",\n         \"type\":\"address\"\n      },\n      {\n         \"indexed\":false,\n         \"name\":\"value\",\n         \"type\":\"uint256\"\n      }\n   ],\n   \"name\":\"Transfer\",\n   \"type\":\"event\"\n},\n{\n   \"anonymous\":false,\n   \"inputs\":[\n      {\n         \"indexed\":true,\n         \"name\":\"old\",\n         \"type\":\"address\"\n      },\n      {\n         \"indexed\":true,\n         \"name\":\"current\",\n         \"type\":\"address\"\n      }\n   ],\n   \"name\":\"NewOwner\",\n   \"type\":\"event\"\n}\n```\n- `anonymous` : 이 method가 public인지 아닌지 (default: `false`. public 이다.)\n- `type` : 어떤 데이터 타입인지\n\t- `event`\n\t- `inputs` 안에는 input type\n- `name` : item 혹은 파라미터의 이름 \n- `indexed` \n\t- `true` : `topics` 에 저장된다. \n\t- `false` : `data` 필드에 들어간다. \n\n\n## References\n- [Understanding Logs: Deep Dive into eth_getLogs](https://docs.alchemy.com/docs/deep-dive-into-eth_getlogs)\n- [Understanding event logs on the Ethereum blockchain](https://medium.com/mycrypto/understanding-event-logs-on-the-ethereum-blockchain-f4ae7ba50378)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/AWS-%EB%B9%84%EC%9A%A9-%EC%B5%9C%EC%A0%81%ED%99%94":{"title":"AWS 비용 최적화","content":"\n## 1) 리소스에 Tag 달기\n- 리소스 만들고 맨 마지막에 나오는 optional 메타데이터 (key-value)\n- \n## 2) 데이터 전송 비용\n\n## 3) Compute 비용 최적화 정리\n\n## 4) AWS Trusted Advisor\n\n## 5) 우리 회사에 맞는 비용 대시보드 \n\n\n## References\n- [AWS 쓰다 보면 꼭 고민하는 것, 비용 최적화!](https://www.youtube.com/watch?v=hY7ssLoJcWQ)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/AWS-CLI":{"title":"AWS CLI","content":"\n\n## AWS Configuration 설정 확인하기 \n`aws configure`로 구성한 credential 확인하려면 아래와 같이 할 수 있다.\n\n```sh\nvi ~/.aws/credentials\n\n[default]\naws_access_key_id={ACCESS_KEY}\naws_secret_access_key={SECRET_ACCESS_KEY}\n\nvi ~/.aws/config\n\n[default]\nregion=us-west-2\noutput=json\n```\n\n- https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/cli-configure-files.html\n\n\n## AWS S3 파일 옮기기\n\n```sh\naws s3 mv s3://{from_path} s3://{to_path} --recursive\n```\n\n- web console 에서도 가능하다\n![](https://user-images.githubusercontent.com/2231510/206854577-026b629c-6c0d-4e25-a8bd-a47fda6dab95.png)\n","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/AWS-S3-presigned-URL":{"title":"AWS S3 presigned URL 사용 방법","content":"- S3는 기본적으로 private이지만, presigned_url을 통해 권한이 없는 사람에게도 object를 받을 수 있도록 임시로 허용할 수 있다. \n-  만료시간을 주어 access를 조절할 수 있다. \n- presigned_url 만들 시에는 만든 **사용자의 권한**에 따라 제한된다.\n\t- IAM instance profile : 최대 6시간 사용 가능한 presigned_url 생성 가능 \n\t- AWS Security Token Service : 최대 36시간 \n\t- IAM user : 최대 7일 (AWS Signature Version 4 사용시)\n- 만료 시간 전까지는 계속 사용할 수 있다. \n## `generate_presigned_url` \n- `boto3` 를 이용하여 쉽게 presigned URL을 만들 수 있다. \n\n```python\nimport logging\nimport boto3\nfrom botocore.exceptions import ClientError\n\ndef create_presigned_url(bucket_name, object_name, expiration=3600):\n    \"\"\"Generate a presigned URL to share an S3 object\n\n    :param bucket_name: string\n    :param object_name: string\n    :param expiration: Time in seconds for the presigned URL to remain valid\n    :return: Presigned URL as string. If error, returns None.\n    \"\"\"\n\n    # Generate a presigned URL for the S3 object\n    s3_client = boto3.client('s3')\n    try:\n        response = s3_client.generate_presigned_url('get_object',\n                                                    Params={'Bucket': bucket_name,\n                                                            'Key': object_name},\n                                                    ExpiresIn=expiration)\n    except ClientError as e:\n        logging.error(e)\n        return None\n\n    # The response contains the presigned URL\n    return response\n```\n\npresigned URL을 통해서는 GET, PUT 모두 가능한데 이때 client method를 지정하여 내려줄 수 있다. \n- GET : `get_object`\n- PUT : `put_object`\n``\n`get_object` 용으로 반환된 URL은 다음과 같은 모양으로 생겼다. \n```\nhttps://{bucket_name}.s3.amazonaws.com/{key}?AWSAccessKeyId={aws_access_key}\u0026Signature={signature}\u0026Expires={expire_unixtimestamp}\n```\n\n\n### 동작 방식 \n![](https://user-images.githubusercontent.com/2231510/208320571-2ef6f2c5-c6db-413a-b171-879d8bed1b78.png)\n(출처 : https://insecurity.blog/2021/03/06/securing-amazon-s3-presigned-urls/)\n\n안전하게 사용하기 위해서는 \n- 해당 S3 버킷의 sever access log 활성화\n- 파일 이름은 예측하기 어렵도록 UUID를 사용한다.\n\n## S3 Client Sample Code with boto3 in Python\n```python\nimport boto3\n\nS3_ACCESS_KEY = 's3_access_key'\nS3_SECRET_KEY = 's3_secret_key'\n\nclass S3Client():\n\n    def __init__(self, aws_access_key=S3_ACCESS_KEY, aws_secret_key=S3_SECRET_KEY):\n        self.aws_access_key = aws_access_key\n        self.aws_secret_key = aws_secret_key\n        self.client = boto3.client(\n            's3',\n            aws_access_key_id=self.aws_access_key,\n            aws_secret_access_key=self.aws_secret_key)\n\n    def list_folder_contents(self, bucket_name, folder_name=None, exclude_self=True):\n        if folder_name:\n            folder_name = os.path.join(folder_name, '') # ensure it ends in a slash\n        else:\n            folder_name = '' # non-prefixed -- all folders\n\n        objects = []\n        incomplete = True\n        continuation_token = None\n\n        while incomplete:\n            if continuation_token:\n                response = self.client.list_objects_v2(\n                    Bucket=bucket_name,\n                    Prefix=folder_name,\n                    ContinuationToken=continuation_token,\n                )\n            else:\n                response = self.client.list_objects_v2(\n                    Bucket=bucket_name,\n                    Prefix=folder_name,\n                )\n\n            objects += response.get('Contents', [])\n            if response.get('isTruncated', False):\n                continuation_token = response['NextContinuationToken']\n            else:\n                incomplete = False\n\n        if exclude_self:\n            contents = [obj['Key'] for obj in objects if obj['Key'] != folder_name]\n        else:\n            contents = [obj['Key'] for obj in objects]\n\n        return contents\n\n    def move_object(self, source_bucket_name=None, source_name=None, target_name=None, target_bucket_name=None):\n        \"\"\"\n        Moving an object on S3 requires two steps:\n        1) copy to destination\n        2) delete from source\n        :param source_bucket_name: (str) name of bucket to copy from\n        :param source_name: (str) object key to copy from\n        :param target_name: (str) object key to copy to\n        :param target_bucket_name: (str) name of bucket to copy to. If None, use the source_bucket_name\n        :return None:\n        \"\"\"\n\n        if target_bucket_name is None:\n            target_bucket_name = source_bucket_name\n\n        response = self.client.copy_object(\n            Bucket=target_bucket_name,\n            Key=target_name,\n            CopySource={\n                'Bucket': source_bucket_name,\n                'Key': source_name\n            }\n        )\n\n        if response.get('CopyObjectResult', False):\n            # Assume it worked\n            response = self.client.delete_object(\n                Bucket=source_bucket_name,\n                Key=source_name\n            )\n\n\n    def upload_file(self, source_name, target_name, bucket_name):\n        \"\"\"\n        Uploads the source to the target in the bucket\n        :params source_name: (str) name of file to upload\n        :params target_name: (str) name of object on S3 (include any folder or path)\n        :params bucket_name: (str) bucket to receive file\n        :returns: None\n        \"\"\"\n        self.client.upload_file(\n            source_name,\n            bucket_name,\n            target_name\n        )\n\n    def download_file(self, source_name, target_name, bucket_name):\n        \"\"\"\n        Downloads the source object from the bucket into the target file. Note that the target_name paths should already exist.\n        :params source_name: (str) object key to download\n        :params target_name: (str) destination for download -- all paths to the base file must already exist\n        :params bucket_name: (str) name of bucket to download from\n        :returns: None\n        \"\"\"\n        self.client.download_file(\n            bucket_name,\n            source_name,\n            target_name\n        )\n\tdef generate_presigned_url(self, bucket_name, key, expiration=3600):\n        return self.client.generate_presigned_url(\n            ClientMethod=\"get_object\",\n            Params={\n                \"Bucket\": bucket_name,\n                \"Key\": key,\n            },\n            ExpiresIn=expiration, # seconds\n        )\n```\n\n\n## Preferences\n- [미리 서명된 URL을 생성하여 객체 업로드](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/PresignedUrlUploadObject.html)\n- [미리 서명된 URL 기능 제한](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/using-presigned-url.html#PresignedUrlUploadObject-LimitCapabilities)\n- [Example: An S3 proxy client written in Python](https://gist.github.com/tamouse/b5c725082743f663fb531fa4add4b189)\n- [Using presigned URLs](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html)\n- [Securing your Amazon AWS S3 presigned URLs, tips and tricks](https://insecurity.blog/2021/03/06/securing-amazon-s3-presigned-urls/)\n- [S3 pre-signed URL 한번만 사용하기](https://mygumi.tistory.com/380)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Amazon-Athena":{"title":"Amazon Athena","content":"\n","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Block-Proposer":{"title":"Block Proposer","content":"\n\n## References\n- [What is Proposer / Builder Separation (PBS)?](https://www.alchemy.com/overviews/proposer-builder-separation#what-is-a-block-proposer-2)\n","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Blockchain":{"title":"Blockchain","content":"\n## Blockchain\n-   public database\n-   한 네트워크 내 여러 컴퓨터들을 통해 저장하고, 공유하는 분산형 데이터베이스\n\n## Block\n-   연속성있는 그룹(Blocks)에 저장되는 데이터(data+state)\n-   예를 들어, ETH를 전송했다면, 이 트랜잭션 데이터는 block에 저장됨\n\n## Chain\n-   각 블록은 부모 블록를 참조하고 있다. 즉, 블록들은 연결되어 있음.\n-   블록들은 연결되어 있기 때문에, 블록체인이라고 부름\n\n## Web3\n- 탈중앙화, 블록체인 기술, 토큰 기반 경제학과 같은 개념을 통합한 WWW의 새로운 아이디어\n- Web1 : read-only\n- Web2 : read-write\n- Web3 : read-write-own\n\n## Cryptocurrency\n- 중앙 기관이 아닌 암호를 사용하여 분산 시스템에서 검증 및 유지되는 디지털 통화\n- crypto-currency 혹은 crypto 라고 불린다.\n\n## References\n- [alchemy Web3 Glossary](https://docs.alchemy.com/docs/web3-glossary)\n- ","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Clickhouse":{"title":"Clickhouse","content":"- [https://clickhouse.com/](https://clickhouse.com/)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/DB-Index":{"title":"DB Index","content":"\n## Simple indexes\n## Secondary indexes\n## B-trees\n## Hash tables\n","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/ERC-1155":{"title":"ERC-1155","content":"","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/ERC-721":{"title":"ERC-721","content":"","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/ERC721A":{"title":"ERC721A","content":"- [ERC721A](https://www.erc721a.org/)\n- [[notes/ERC-721]] 표준의 확장. \n- 토큰을 배치로 발행하여 막대한 양의 gas fee를 방지. 여러 토큰을 한번에 발행  \n\n### ERC721A 구현하기 \n- [[notes/Hardhat]]으로 프로젝트 세팅하기 \n\n```sh\nnpx hardhat\n```\n\n\n\n## References\n- [# **ERC721A** Quick Start](https://coinsbench.com/erc721a-quick-start-24131e198e37)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Ethereum":{"title":"Ethereum","content":"\n## Ethereum\n- 컴퓨터가 내장된 블록체인.\n- 비트코인과 다른 점 : 암호화폐로서의 기능 뿐만 아니라 프로그래밍이 가능. 네트워크에서 분산형 애플리케이션을 구축 및 배포할 수 있음.\n- 중앙 주체의 통제 없이 앱과 조직을 구축하고, 자산을 보유하고, 거래하고 소통할 수 있음\n\n## EVM\n- [[notes/Ethereum Virtual Machine]]\n- 글로벌 가상 컴퓨터, 모든 참여자들이 코드 실행을 요청 할 수 있고, 코드 실행은 EVM 상태를 변경시킴\n- [https://ethereum.org/ko/developers/docs/evm](https://ethereum.org/ko/developers/docs/evm)\n\n## Ether\n- ETH : native cryptocurrency of Ethereum\n- 화폐로서 사용되는 암호화폐\n- 거래 요청 확인 및 실행한 컴퓨터에 대한 보상으로 지급됨\n\n## Ethereum Classic\n- 오리지널 이더리움 네트워크 해킹을 해결하기 위해 하드포크 하기 전의 오픈소스 블록체인\n- ETC : 이더리움 클래식의 고유 통화\n\n## Smart contracts\n- 이더리움 블록체인 상에서 실행되는 프로그램\n- 이더리움 블록체인 상의 특정 주소에 있는 코드(function)과 데이터(state)의 모음\n\n### Smart contract 동작 방식\n- 네트워크 상에 미리 결정된 조건이 충족될 때 동작 실행\n\n## Minting Ether\n- 이더리움 원장(Ethereum ledger)에 새로운 이더리움을 발행하는 것\n- underlying Ethereum 만이 새로운 ether를 만들 수 있다.\n\n## Burning Ether\n- 이더리움 원장(Ethereum ledger)에서 이더리움을 삭제하는 것\n\n## Denominations of ether\n- 이더 종파\n- 이더리움에서 적은 금액으로 거래가 자주 일어나, 이를 용이하게 하기 위해 만든 단위\n- \"Wei\"와 \"Gwei\"가 가장 유명하다.\n- [https://ethereum.org/ko/developers/docs/intro-to-ether/#denominations](https://ethereum.org/ko/developers/docs/intro-to-ether/#denominations)\n\n### Wei\n- 이더(ether)의 가장 작은 단위\n- 1 wei = 10^-18 ether = 0.000000000000000001 ether\n- 1 ether = 10^18 wei = 1,000,000,000,000,000,000 wei\n- 주로 기술적 구현단에서 자주 사용됨.\n- 비트코인 탄생에 큰 영향을 준 B-Money를 고안한 인물인 [Wei Dai](https://en.wikipedia.org/wiki/Wei_Dai)의 이름을 따서 만들어졌다.\n\n### Gwei\n- giga-wei. 1,000,000,000 wei\n- Gas 이야기 할 때 많이 사용됨.\n\n## Transferring ether\n- 각 트랜잭션에는 `value` 필드 : 전송할 ether의 양(wei 단위로)\n- sender -\u003e recipient 주소로 옮겨짐\n- recipient 주소가 smart contract라면 smart contract 실행에 대한 gas fee 지불하는데 새용될 수도 있다.\n- [https://ethereum.org/ko/developers/docs/intro-to-ether/#transferring-ether](https://ethereum.org/ko/developers/docs/intro-to-ether/#transferring-ether)\n\n  \n## Ethereum accounts\n- 이더리움에서 거래할 수 있는 ether 잔고를 가지고 있는 entity\n- account은 사용자가 사용하거나 smart contract를 배포할 수 있다.\n\n## Types of Ethereum accounts\n- 1) Externally-owned account (EOA) : priveate key를 가지고 있는 계정\n- 2) Contract account : 네트워크에 배포된 smart contract.\n\n### 1) Externally-owned account (EOA)\n- 만드는데 비용이 들지 않는다.\n- 트랜잭션을 일으킬 수 있다.\n- EOA 사이에서 ETH나 토큰을 전송할 수 있다.\n- public key와 private key 암호화된 키 쌍을 가지고 있다.\n\n### 2) Contract account\n- 생성시 비용이 든다. 네트워크 스토리지를 사용하기 때문에\n- 트랜잭션 수신하는 응답으로만 트랜잭션을 보낼 수 있다. (스스로 트랜잭션을 보낼 수 없다.)\n- 외부에서 contract account로의 전송을 통해 여러 가지 작업할 수 있는 코드를 트리거링 할 수 있다. ex. 토큰 보내기 혹은 새로운 contract 만들기 등\n- private 키가 없다. 대신 code 내 로직에 의해 컨트롤 된다.\n\n\n## Ethereum accounts have four fields\n![](https://ethereum.org/static/19443ab40f108c985fb95b07bac29bcb/302a4/accounts.png)\n - [AN ACCOUNT EXAMINED](https://ethereum.org/ko/developers/docs/accounts/#an-account-examined)\n\n### nonce\n- 각 account에서 보낸 트랜잭션의 수. 트랜잭션 카운터\n- 한 트랜잭션을 한번만 처리할 수 있게 됨. replay attack 방지.\n- account 에서 생성된 contract 갯수.\n\n### balance\n- 주소가 소유한 wei의 수.\n\n### codeHash\n- EVM(이더리움 가상머신) 내 account 코드.\n- 변하지 않는 값. (다른 필드들은 변함)\n- contract account의 경우, contract의 코드를 가리킨다.\n- account가 메세지를 받게되면 코드 실행\n- 코드 조각은 나중에 검색할 수 있도록 해당 해시 아래 상태 데이터베이스(state database)에 포함됨\n- EOA의 경우, 빈 string 해시 값.\n\n### storageRoot\n- storage hash\n- account의 storage content의 해시 값.\n- default는 비어 있음.\n\n## Contract address\n- 42자로 구성된 16진수 주소\n\t- ex. `0x06012c8cf97bead5deae237070f9587f8e7a266d`\n- Contract가 이더리움 블록체인에 배포될 때 부여된다.\n- 만든 사람의 주소와 해당 주소에서 보낸 트랜잭션의 수([nonce](#nonce))를 통해 만들어진다.\n\n## Validator Keys\n- 작업 증명(proof-of-work)에서 지분 증명(proof-of-stake)로 변경되며 필요해짐\n- BLS(Boneh-Lyn-Shacham) 키는 검증인(validator)를 식별하는데 사용 \n- BLS키는 효율적으로 집계하여 네트워크 합의 도달하는데 필요한 대역폭을 줄일 수 있다. \n- private key + public key\n\n## Wallets\n- account != wallet\n- account와 인터렉션 할 수 있는 interface 이자 application\n\n## Querying Ether\n- [[notes/Etherscan]]에서 주소 검색하여 잔액을 확인할 수 있다. \n\n## DApp\n- decentralized application\n- decentralized network 상 위에 smart contract와 front end 인터페이스로 만들어진 어플리케이션. \n\t- smart contract는 접근 가능하며 투명하게 공개된다. \n- 장점\n\t- Zero downtime\n\t\t- 블록체인 네트워크 상에서 운영되기 때문에 \n\t- privacy\n\t- 검열이 따로 없음\n\t- 데이터 무결성\n\t\t- 블록체인에 데이터가 저장되기 때문에 불변이며 위조할 수 없다. \n\t- 검증 가능한 동작 \n\t\t- 별도 중앙 기관 없이 따로 신뢰할 것 없이 사용 가능하다. \n\t\t- 현실 세계에서는  은행 시스템 사용시 금융 기관을 믿고 사용하지만 DApp에서는 그럴 필요가 없다.\n- 단점\n\t- 운영이 어렵다.\n\t\t- 블록체인에 올라가고나면 수정이 어렵다. \n\t- 퍼포먼스 이슈 \n\t\t- 이더리움이 지향하는 보안, 무결성, 투명성, 신뢰성 수준 달성을 위해 모든 노드가 모든 트랜잭션을 실행 및 저장. 증명 합의에도 시간이 걸리게 된다. \n\t- 네트워크 정체\n\t\t- 하나의 DApp이 너무 많은 리소스를 사용하게 되면 전체 네트워크가 정체된다. 현재 네트워크는 초당 10~15개의 트랜잭션만 처리 가능하며, 이보다 더 많은 트랜잭션이 생기면 풀이 빠르게 증가 할 수 있다. \n\t- 사용성\n\t\t- 사용자 역시 블록체인의 보안 방식을 설정해야함으로 진입 장벽이 높을 수 있다.\n\t- 중앙 집중화 \n\t\t- 사용자 친화적으로 하려면 전통적인 중앙 집중화된 서비스로 만들게 되는데, 이렇게 되면 블록체인의 장점들을 더 이상 사용할 수 없게 된다. \n\n## Transaction\n- account의 암호화된 명령\n- 예를 들어, account =\u003e account ETH 전송\n- [EVM](#EVM) 상태를 변경하는 트랜잭션은 전체 네트워크로 브로드캐스트 되어야 한다.\n\t- **recipient** : 수신 주소 \n\t\t- EOA : 전송 받는 사람\n\t\t- Contact account : 이 트랜잭션은 contract code를 실행하는 트랜잭션임. \n\t- **signature** : 보낸 사람 식별자 \n\t\t- 보낸 사람의 private key가 트랜잭션에 싸인하고 보낸 사람이 이 트랜잭션을 승인 했다고 확인 할 때 생성됨. \n\t- **nonce** : 계정의 트랜잭션 번호. 순차적으로 증가하는 카운터\n\t- **value** : 전송하는 ETH 양 ([WEI](#wei))\n\t- **data** : 임의 데이터 (optional)\n\t- **gasLimit** : 트랜잭션에서 사용할 수 있는 최대 가스 단위의 양. 계산 단계에서 나오는 가스 양\n\t- **maxPriorityFeePerGas** : validator에게 보낼 최대 가스량\n\t- **maxFeePerGas** : 거래에 대해 지불할 수 있는 최대 가스량 ( baseFeePerGas 와 maxPriorityFeePerGas 포함)\n\n## Gas\n- 이더리움 네트워크에서 특정 작업을 실행하는데 필요한 계산 노력의 양을 측정하는 단위 \n- 거래를 실행하기 위해 계산 자원 필요 =\u003e 각 거래는 수수료가 필요.\n- 이 거래를 성공적으로 수행하기 위한 필요한 수수료 \n- `gasLimit` 와 `maxPriorityFeePerGas` 를 이용하여 validator에게 줄 최대 거래 수수료를 결정한다. \n\n### 거래 수수료 계산 방법 \n- 이더리움 네트워크 거래 수수료 계산 방식은 [[notes/London upgrade]] 이후로 변경됨.\n- 기존 동작 방식 (런던 업그레이드 전)\n\t- `gasLimit` : 21,000 unit, gas price : 200 gwei 인 경우 =\u003e Gas units * price = 21,000 * 200 = 4,2000,000 gwei (0.0042 ETH)\n- 이후 동작 방식 (런던 업그레이드 이후)\n\t- gasLimit` : 21,000 unit`, **base fee** 10 gwei, tip은 2 gwei \n\t  =\u003e 21,000 ( 10 + 2) = 252,000 gwei (0.000252ETH)\n\t- validator는 0.000042 ETH 팁을 받고, base fee인 0.00021 ETH는 burn 된다.\n\t- `maxFeePerGas` 설정할 수 있다.\n\t\t- refund = 최대 수수료 - ( base fee + priority fee )\n\t- 이를 통해 기본료 이상의 과도한 지불을 막는다.\n\n## Block\n- 트랜잭션을 담고 있다. \n- 즉, 트랜잭션은 기록이고 블록은 장부다. \n- hash는 블록 데이터에서 암호화되어 이 링크로 블록들을 연결 \n\t- 한번 연결된 hash는 모든 이용자가 알고 있기 때문에 쉽게 변조할 수 없다. \n\n### 왜 block이 필요한가\n- 이더리움 네트워크에 잇는 모든 참가자가 동기화 상태를 유지하고 트랜잭션의 정확한 기록을 동의\n- 밸리데이터(validator)들은 랜덤으로 트랜잭션을 블록에 담을 수 있는 권한을 받고 그 트랜잭션을 블록에 담아 또 다른 밸리데이터들에게 공유 \n\n### block 작동 방식 \n- 트랜잭션 기록 보존을 위해 블록은 반드시 정렬된다\n- 블록이 밸리데이터에 의해 합쳐지고 나면, 네트워크에 모두 전파된다.\n- 블록이 합쳐지고 나면 새로운 벨리데이터를 선택하고 다음 블록을 만든다.\n- 현재 이더리움은 proof-of-stake(POS) 프로토콜로 명시되어있다. \n\n### Proof-of-stake Protocol \n- 지분 증명 \n- 밸리데이터가 되기 위해서는 담보로 32ETH 지불해야한다. \n- 부정행위가 걸릴 경우, 이 담보에서 사라지게 됨으로 네트워크 보호용으로 사용된다.\n- 모든 [[notes/이더리움 2.0#슬롯 (slot)]]마다 [[notes/Block Proposer]]로 부터 밸리데이터가 무작위로 선택\n- 밸리데이터는 트랜잭션을 묶고, 실행, 새로운 상태(state)를 결정 후 다른 밸리데이터들에게 전달 \n\t- 다른 밸리데이터들 : 변경 사항들을 실행해보고, 유효하다고 판단하면 해당 블록을 자체 데이터베이스에 추가 \n- 동일 슬롯에 대해 두개의 충돌 블록이 있을 경우 [fork-choice algorithm](https://github.com/ethereum/annotated-spec/blob/master/phase0/fork-choice.md) 으로 가장 많이 연결된 ETH가 지원하는 블록 선택\n\n### What's in a block\n![](https://user-images.githubusercontent.com/2231510/205472611-01a88b46-e4f4-4d97-8907-1d2f095761b3.png)\n- `slot` : 이 블록이 속한 슬롯 \n- `proposer_index` : 블록 제안한 밸리데이터의 ID\n- `parent_root` : 이전 블록 해시\n- `state_root` : 상태 오브젝트의 루트 해시\n- `body`\n\t- `randao_reveal` : 다음 [[notes/Block Proposer]]을 위해 사용될 값 \n\t- `eth1_data` : 담보 컨트렉트 정보\n\t- `graffiti` : 블록 태그를 위한 임의 데이터\n\t- `proposer_slashings` :  잘라낼 밸리데이터 목록\n\t- `attester_slashings` : 잘라낼 밸리데이터 목록\n\t- `attestations` : 현재 블록을 지원하는 증명 목록\n\t- `deposits` : 담보 컨트랙트를 위한 새로운 담보 리스트 \n\t- `voluntary_exits` : 네트워크 내 밸리데이터 목록\n\t- `sync_aggregate` : light client에 전달하는 밸리데이터의 subset\n\t- `execution_payload` : 실행 client로 부터의 트랜잭션\n\n### Block Time\n- 블록을 분리하는 시간\n- 이더리움에서 시간은 슬롯([[notes/이더리움 2.0#슬롯 (slot)]] = 12초\n- 모든 밸리데이터가 온라인 상태고 완전히 동작한다고 가정했을 때, 모든 슬롯에 블록이 있다. -\u003e 즉, 블록 시간은 **12초** \n- 하지만, 밸리데이터가 오프라인일수도 있어서, 슬롯이 빌 수도 있음. \n\n### Block Size\n- 각 블록의 목표 사이즈는 1500만 가스.\n- 하지만 네트워크 수요에 따라 증가, 감소가 가능하여 최대 3000만 가스(목표의 2배)까지 늘어날 수 있다.\n- 블록 내 모든 트랜잭션에서 지출되는 가스피의 총량은 블록 가스 한도보다 작아야 한다.\n\t- 블록이 임의로 커져버리지 않게 하기위한 장치\n\t- 블록이 너무 커지면 전체 노드의 리소스와 속도 요구사항으로 인해 네트워크를 따라갈 수 없게 될 수 있음\n\n### Base fee\n- 모든 블록에는 base fee가 있어 예비 가격 역할을 함\n- 블록에 들어가려면 이 base fee 보다는 커야 함\n- 각각의 블록마다 독립적으로 계산됨. \n- 이전 블록에 의해 결정됨으로 사용자는 fee를 예측할 수 있음\n- 블록이 채굴될때마다 연소(burned)된다. \n\n### Priority fee (tips)\n- \n\n### Max fee\n\n\n\n## References\n- Ethereum official website : [https://ethereum.org/ko/what-is-ethereum/](https://ethereum.org/ko/what-is-ethereum/)\n- [Learn Ethereum Blockchain daily and Keep the Knowledge Awake :)](https://medium.com/coinsbench/learn-ethereum-blockchain-daily-and-keep-the-knowledge-awake-day-1-6d482ae67ac7)\n- [Account Abstraction \u0026 ERC 4337](https://medium.com/decipher-media/account-abstraction-erc-4337-2b8dff6b0a34)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Ethereum-Virtual-Machine":{"title":"Ethereum Virtual Machine","content":"\n\n## References\n- [The Ethereum Virtual Machine — How does it work?](https://medium.com/mycrypto/the-ethereum-virtual-machine-how-does-it-work-9abac2b7c9e)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Etherscan":{"title":"Etherscan","content":"\n- [Etherscan](https://etherscan.io/)\n- 웹 어플리케이션으로 address로 [[notes/Ethereum]]의 모든 트랜잭션과 블록을 추적할수 있는 툴\n\t- transaction\n\t- block\n\t- address \n- 읽는 방법 \n\t- [[notes/How NFT smart contract really work]]\n\n## Transaction Details\n- \n## Block \n- \n## Address\n\n","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/FastAPI%EB%A1%9C-reverse-proxy-server-%EB%A7%8C%EB%93%A4%EA%B8%B0":{"title":"FastAPI로 reverse proxy server 만들기","content":"\n```python\nimport httpx\nfrom fastapi import FastAPI, Request\n\nfrom starlette.requests import Request\nfrom starlette.responses import StreamingResponse\nfrom starlette.background import BackgroundTask\n\napp = FastAPI(docs_url=None, redoc_url=None, openapi_url=None)\n\nclient = httpx.AsyncClient(base_url=\"http://localhost:8000\")\n\nasync def _reverse_proxy(request: Request):\n    url = httpx.URL(path=request.url.path,\n                    query=request.url.query.encode(\"utf-8\"))\n    rp_req = client.build_request(request.method, url,\n                                  headers=request.headers.raw,\n                                  content=await request.body())  \n    rp_resp = await client.send(rp_req, stream=True) \n    return StreamingResponse(\n        rp_resp.aiter_raw(),\n        status_code=rp_resp.status_code,\n        headers=rp_resp.headers,\n        background=BackgroundTask(rp_resp.aclose),\n    )\n\napp.add_route(\"/{path:path}\",\n              _reverse_proxy, [\"GET\", \"POST\"])\n```\n\n## References\n- [Can fastapi proxy another site as a response to the request?](https://github.com/tiangolo/fastapi/issues/1788)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/FastAPI-OpenAPI":{"title":"FastAPI OpenAPI custom setting","content":"\n## References\n- [Extending OpenAPI](https://fastapi.tiangolo.com/advanced/extending-openapi/)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Hardhat":{"title":"Hardhat","content":"- [hardhat](https://hardhat.org/)\n- ","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/How-NFT-smart-contract-really-work":{"title":"How NFT smart contract really work","content":"\n\u003e Ethereum NFT 기준\n\n## OpenSea \n\n- 예제 [Doodle #1815](https://opensea.io/assets/ethereum/0x8a90cab2b38dba80c64b7734e58ee1db38b8992e/1815)\n![](https://user-images.githubusercontent.com/2231510/204299525-29388efa-cc3f-4fed-bd2b-9acc83e8d2a5.png\")\n![](https://user-images.githubusercontent.com/2231510/204299525-29388efa-cc3f-4fed-bd2b-9acc83e8d2a5.png)\n\n- OpenSea 주소에서 `chain`, `contract address`, `token` 확인할 수 있다.\n- `https://opensea.io/assets/{chain}/{contract address}/{token id}`\n\n![](https://user-images.githubusercontent.com/2231510/204303462-86a6c32d-033c-4052-ac52-c559d0a2c944.png)\n- Details 에서도 동일하게 NFT에 대해 알 수 있다.\n- Contract Address 링크 : NFT Collection contract [[notes/Etherscan]] 페이지로 연결\n- Token ID 링크 : NFT Token의 metadata \n\n## Etherscan\n- [예제 Contract 0x8a90CAb2b38dba80c64b7734e58Ee1dB38B8992e](https://etherscan.io/address/0x8a90cab2b38dba80c64b7734e58ee1db38b8992e)\n\n### \"Contract\" tab\n- Code\n\t- Contract Source Code : solidity. contract code 내용\n\t- Contract ABI \n\t- Contract Creation Code\n\t\t- ByteCode\n\t\t- Opcodes\n- Read Contract : 해당 스마트 컨트렉트에 대해 READ 할수 있는 function들 \n\t- 예를 들어, `onwnerOf`  function에 `tokenId`를 넣으면 해당 `tokenId`의 NFT를 가진 owner query 가능\n\t  ![](https://user-images.githubusercontent.com/2231510/204311713-6f1ea517-9144-43bc-9add-3e39f0ce9386.png)\n\t- `tokenURI` : NFT metadata link \n\t  ![](https://user-images.githubusercontent.com/2231510/204314326-005287a8-b0f2-43d6-a94a-dd5b8c4bac92.png)\n\t  - [[notes/IPFS]] 주소\n\t  - `https://ipfs.io/ipfs/{뒤쪽 주소}` \n\t\t  - 앞부분은 바뀌지 않고 맨 뒤 token ID만 변경된다. \n\t  - [https://ipfs.io/ipfs/QmPMc4tcBsMqLRuCQtPmPe84bpSjrC3Ky7t3JWuHXYB4aS/13](https://ipfs.io/ipfs/QmPMc4tcBsMqLRuCQtPmPe84bpSjrC3Ky7t3JWuHXYB4aS/13)\n\t  - 이렇게 다른 곳에 저장되어있기 때문에 **owner**가 원하면 metada를 바꿀 수 있다.\n\t  - owner를 만약 resign(이 역시도 function) 한다면 owner가 없게 되고 해당 NFT는 영원히 바꿀 수 없게 된다. \n\t- `balanceOf` : owner 주소가 해당 contract NFT 를 몇개 가졌는지 \n\t  ![](https://user-images.githubusercontent.com/2231510/204318782-5f27a4cd-4f0d-42ff-92cc-04e2d2cdf3d7.png)\n\t- `totalSupply` : 이 contract의 최대 발행갯수 \n\t  ![](https://user-images.githubusercontent.com/2231510/204319392-9b9c2e31-1b97-43f7-8a67-ee509a4594a2.png)\n\t  \n- Write code \n\t- 지갑과 연결하여 code를 실행시킬 수 있다. \n\t- `setBaseURI` : Metadata URL 세팅하기 \n\t  ![](https://user-images.githubusercontent.com/2231510/204317487-52539b7e-2fe6-444f-b450-f93f8cd83604.png)\n\t  (내가 `owner`가 아니기 때문에 denied 됨)\n\t  ![](https://user-images.githubusercontent.com/2231510/204317791-d5d95e9d-1074-453d-b198-e8f78f78c8d6.png)\n\t  (코드 보면 `onlyOwner` contract owner 만 가능하게 되어있음 )\n\t  나중에 metadata가 호오오옥시나 바뀌게 되면 이 `setBaseURI`로 변경할 수 있음. \n\t  - `withdraw` : `onlyOwner`\n\t    해당 contract의 balance를 해당 function call 한 사람에게 transfer 한다. (누구든 부를 수 있긴 하지만 `onlyOwner`에서 막히니 owner만이 balance를 가져갈 수 있다.)\n\t    ![](https://user-images.githubusercontent.com/2231510/204320002-9f55dc99-5744-4f15-ac68-8cc8d5480336.png)\n\t    \n## NFT Staking\n- [예시 Wizards \u0026 Dragons Game (WnD)](https://opensea.io/collection/wizards-dragons-game-v2)\n- [Contract Etherscan](https://etherscan.io/address/0x999e88075692bcee3dbc07e7e64cd32f39a1d3ab#readContract)\n- `Contract` tab \u003e `Read Contract` \u003e `tower` 다른 contract 주소가 있음\n  ![](https://user-images.githubusercontent.com/2231510/204322362-d41719e9-015d-403f-91e0-8bc9986dfd42.png)\n  staking contract \n  ![](https://user-images.githubusercontent.com/2231510/204323453-a5c3738a-c8d6-45cd-a02b-40523d298f07.png)\n  `transferFrom` : [[notes/ERC-20]] standard function\n\t  - `tokenOwner` 로 부터 이 `address` 에게 NFT를 보내겠다. \n- unstaking\n  ![](https://user-images.githubusercontent.com/2231510/204324932-81b03754-0647-4039-9982-b511ff4bca45.png)\n  \"claim\", \"unstaking\" function을 보면 대부분 여기에 reward에 대한 코드가 있다. \n\n\n## References\n- [HOW NFT SMART CONTRACTS REALLY WORK - Can metadata be changed? How staking works?](https://www.youtube.com/watch?v=Wu436_IwWmo)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/IPFS":{"title":"IPFS","content":"- [ipfs.tech](https://ipfs.tech/)\n- InterPlanetary File System. \n- 분산형 파일 시스템.\n- P2P 방식. \n- NFT Metadata 저장하는 곳으로 많이 쓰임. \n\t- 다른 서비스로는  [[arweave.org]] 도 있음.","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/LaunchDarkly":{"title":"LaunchDarkly","content":"\n- [[notes/unleash]]와 거의 비슷하지만, enterprise만 제공하고 있다. \n-  stream 방식으로 polling 방식 unleash 보다 반영이 더 빠름\n-   unleash와 다르게 client쪽에서 변수를 좀 더 자유롭게 사용할 수 있음. (unleash는 미리 정의해두어야함)\n-   rollout 전략에서 비율 조절 뿐만 아니라 복합 속성으로 여러개 섞을 수 있음\n-   [available client side도 고를수 있음.](https://docs.launchdarkly.com/home/getting-started/feature-flags?site=launchDarkly#making-flags-available-to-client-side-and-mobile-sdks)\n-   [toggle scheduling도 가능](https://docs.launchdarkly.com/home/feature-workflows/scheduled-changes)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Logstash":{"title":"Logstash","content":"\n## Configuration\n\n```yaml\ninput {\n  beats {\n    port =\u003e 5044\n  }\n}\n\nfilter{\n}\n\noutput {\n  s3 {\n    region =\u003e \"us-east-1\"\n    bucket =\u003e \"log-bucket\"\n    prefix =\u003e \"%{+YYYY}/%{+MM}/%{+dd}\"\n    codec =\u003e line { format =\u003e \"%{message}\"}\n  }\n}\n\n```\n\n## Input\n### filebeat\n\n### file\n\n\n## Filter\n\n## Output\n### S3\n- ``\n\n## References \n- [Using Logstash to Send Directly to an S3 Object Store](https://joshua-robinson.medium.com/using-logstash-to-send-directly-to-an-s3-object-store-34a4365a0960)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/London-upgrade":{"title":"London Upgrade","content":"\n- 런던 [[notes/하드포크]]\n- 2021년 8월 5일 \n- 수수료 구조 개선 및 공급량 조절 등 \n\n## EIP-1559\n- 가스비를 줄이기 위한 새로운 수수료 구조 도입 (수수료 절감)\n- 런던 업그레이드의 핵심 내용\n- 문제점\n\t- 더 높은 수수료를 제시하는 거래가 더 빠르게 이루어지는 구조. 이로 인해 가스비 경쟁이 과열 =\u003e 일부 거래가 지나치게 높은 수수료를 지불하게 됨.\n\t- 사용자가 직접 계산 해야 함 =\u003e 과도하게 비싸게 지출할 수도 있음\n- 개선\n\t- 자동으로 계산된 기본 수수료로 지불 \n\n## EIP-3554\n- 이더리움 채굴 난이도 폭탄을 12월 1일로 연기\n- 난이도 폭탄 : 이더리움 플랫폼에 기본적 내장된 코드로, 채굴 난이도를 높이는 코드이다. \n\t- 난이도가 높아지면 자연스럽게 작업증명(PoW)의 수요가 줄어들며, 지분증명(PoS)의 수요가 높아진다.\n\t- 즉, 채굴 방식 변경을 위한 코드다. 작업증명(PoW) → 지분증명(PoS)\n\n## EIP-3198 \n- 기본료에 대응하는 연산부호 도입(Basefee opcode)\n\n## EIP-3529 \n- 가스비 환불 기능 제거 (블록 크기에 유연성을 두는 EIP-15999를 방해하는 기능을 없애자는 차원\n\n## EIP-3541 \n- 0xEF 바이트로 시작하는 새 콘트랙트 생성 거부\n- EIP(Ethereum Improvement Proposal) : 이더리움 개선 제안","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/NFT":{"title":"NFT","content":"- Non-Fungible Token : 대체 불가능 토큰\n- 모두 동일한 가치를 가지는 화폐와 달리 **\"고유성\"**을 가진 토큰\n- 창작물에 대한 저작권이나 소유권\n- 게임 내 유니크한 아이템 등 재화에 대한 소유권\n- 예술품, 부동산, 골동품 등 등기가 필요한 자산에 대한 소유권\n- 회원권과 같은 자격에 대한 증명 \n\n\n## Marketplace\n- OpenSea\n\n## References\n- [NFT, 대체 불가능한 토큰](https://youtu.be/P40WjHh1Hzs)\n- ","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Poetry":{"title":"Poetry","content":"\n- [Python poetry](https://python-poetry.org/)\n\nPython의 기본 패키지 매니저인 pip의 불편한점 \n- 기본적으로 global 설치 : `virtualenv`와 같은 가상 환경을 따로 작업해주어야 한다. \n- lock 파일이 없어 협업시 의존성 버전 불일치가 일어날 수 있음. \n\n## 장점\n### `poetry.lock` \n\n### virtualenv \n- 추가 작업없이 virtualenv를 사용할 수 있다. \n\n## 설치 방법 \n### Linux, MacOS, Windows(WSL)\n```\ncurl -sSL https://install.python-poetry.org | python3 -\n```\n\n### windows (powershell)\n```\n(Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -\n```\n\n## 새 프로젝트 시작하기 \n```\npoetry new new-poetry-repository\ncd new-poetry-repository\n```\n들어가보면 다음과 같은 프로젝트 구조로 되어있다. ([[notes/Tree 명령어]] 를 사용)\n```\nnew-poetry-repository/\n├── README.md\n├── new_poetry_repository\n│   └── __init__.py\n├── pyproject.toml\n└── tests\n    └── __init__.py\n```\n\n만약, 패키지 이름을 바꾸려면 아래와 같이 `name`을 따로 줄 수도 있다.\n```\npoetry new new-poetry-repository --name cheese-poetry\n```\n\n```\nnew-poetry-repository\n├── README.md\n├── cheese_poetry\n│   └── __init__.py\n├── pyproject.toml\n└── tests\n    └── __init__.py\n```\n\n## 이미 있는 프로젝트 내에 세팅하기\n\n```sh\npoetry init\n```\n- `pyproject.toml` 파일이 생성되며 안에 의존성이 추가된다. \n\n## 의존성 추가 \n```sh\npoetry add {package}\npoetry add aioredis\n```\n\n## `pyproject.toml`\n\n```toml\n[tool.poetry]\nname = \"cheese-poetry\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"cheese \u003cseojeee@gmail.com\u003e\"]\nreadme = \"README.md\"\npackages = [{include = \"cheese_poetry\"}]\n\n[tool.poetry.dependencies]\npython = \"^3.10\"\n\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```\n\n## Virtual Environment\n```sh\npoetry env list\n\npoetry env use python3\n```\n지금 사용중인 virtual env 위치 확인하기 \n```sh\npoetry show -v\n```\n\n\n## References\n- [파이썬 의존성 관리자 Poetry 사용기](https://spoqa.github.io/2019/08/09/brand-new-python-dependency-manager-poetry.html)\n- [Dependency management with Python Poetry](https://realpython.com/dependency-management-python-poetry/)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/PostgreSQL":{"title":"PostgreSQL","content":"\n## Vacuum\n- DB 디스크 조각 모음\n- 데이터가 `update`/`delete` \n- \n### vacuum 시간 확인하기\n```sql\nSELECT relname, last_vacuum, last_autovacuum FROM pg_stat_user_tables;\n```\n\n\n## References\n- [PostgreSQL: 베큠(VACUUM)을 실행해야되는 이유 그리고 성능 향상](https://blog.gaerae.com/2015/09/postgresql-vacuum-fsm.html)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Rate-Limiter":{"title":"처리율 제한 장치 Rate Limitter","content":"\n## 필요한 이유\n- 일정 시간 당 요청수를 제한함.\n\t- e.g. RPS (Request Per Second)\n- 서비스에 한 번에 엄청난 수의 요청을 받게 된 경우 서버를 안정적으로 운영하기 위해 특정 요청에 대해서만 허용하는 방법. 요청의 임계치를 정하여 그 값을 초과하게 되면 처리하지 않는다. \n- 특히, DDOS와 같이 불필요한 요청을 하여 시스템을 공격을 방어하기 위해 사용.\n- 수용 가능한 요청에 대해 처리하며, 이로 인해 서버 리소스 비용을 조절할 수 있게 됨으로써 비용 절감의 효과도 얻을 수 있다.\n\n아래와 같이 실제 서비스에 닿기 전 유효한 요청인지 받을 수 있을지에 대해 Rate Limiter가 판단 후  실제 서비스로 요청이 갈 수 있도록 한다. \n\n![](https://miro.medium.com/max/720/1*maqXnVMCWj_Z28qfmB_ZgQ.webp)\n( ref : https://towardsdatascience.com/designing-a-rate-limiter-6351bd8762c6 )\n\n너무 많은 요청이 와서 이를 막을 경우 [HTTP status 429 Too Many Requests](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429)를 반환한다. 이러한 중간 역할을 하는 장치를 주로 API Gateway라고 부르는데, 처리율 제한 뿐만 아니라 SSL 종단(termination), 인증(Autherntication), IP 차단/허용(deny/allow list) 등을 지원하는데, 클라우드 프로바이더들이 제공하는 managed를 사용할수도 있고, 직접 만들어 사용할 수도 있다. \n\n## 처리율 제한 알고리즘\n### 토큰 버킷 알고리즘 \n\n### 누출 버킷 \n\n### 고정 윈도 카운터\n\n### 이동 윈도 로그\n\n### 이동 윈도 카운터\n\n## 처리율 제한 규칙\n\n### 1) 시간당 처리율 \n- RPS, PRM 등 시간 내 요청 수 제한\n- \n### 2) Compute Unit \n- API endpoint 마다 정보를 쿼리하는데 필요한 계산에 따라, 각 API 요청에 대한 가중치를 부여하는 방법. 이 단위를 Compute Unit 줄여 CU라고 부른다. \n- CUPS (Compute Unit Per Second) \n\n## Response\n- API 요청 입장에서도 얼마나 나의 limit이 남았는지, 그리고 초과되었다면 언제 부터 다시 요청이 가능한지 알수 있으면 더 효율적으로 API 요청을 할 수 있다. \n- `x-ratelimit-limit` : 윈도우 마다의 제한 수 \n- `x-ratelimit-remaining` : 현재 윈도우 내 남은 요청 제한 수 \n- `x-ratelimit-retry-after` : 요청 제한이 넘어간 경우, 얼마 뒤(대부분 \"초\") 다시 요청을 보내야하는 지\n\n## References\n- [Designing a rate limiter](https://towardsdatascience.com/designing-a-rate-limiter-6351bd8762c6)\n- [가상 면접 사례로 배우는 대규모 시스템 설계 기초](http://www.yes24.com/Product/Goods/102819435)\n- [Examples of HTTP Rate Limiting Response headers](https://stackoverflow.com/questions/16022624/examples-of-http-api-rate-limiting-http-response-headers)\n- [What is a compute unit(CU)?](https://moralis.io/faq/what-is-a-compute-unit-cu/)","lastmodified":"2022-12-28T04:42:22.101473432Z","tags":null},"/notes/Redash":{"title":"Redash","content":"\n## 지원 데이터 소스 \n- Amazon 계열 : Athena, CloudWatch, DynamoDB, Redshift\n- Google 계열 : Analytics, BigQuery, Spreadsheets\n- Microsoft Azure 계열 : Data Warehouse / Synapse, SQL Database, SQL Server\n- Cassandra\n- Clickhouse\n- CockroachDB\n- CSV (self-hosted에서는 지원하지 않음)\n- MongoDB\n- PostgresQL\n- [Supported Data Sources](https://redash.io/help/data-sources/querying/supported-data-sources)\n\n## Queries\n- \n\n## Dashboards\n- \n\n## Alerts\n\n\n## References\n- [Creating and Editing Queries](https://redash.io/help/user-guide/querying/writing-queries)","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/Redis-%ED%8A%B8%EB%9F%AC%EB%B8%94%EC%8A%88%ED%8C%85":{"title":"Redis 트러블슈팅","content":"\n## \"WRONGTYPE Operation against a key holding the wrong kind of value\"\n- Redis는 [여러 데이터 타입](https://redis.io/docs/data-types/)을 제공한다. 각각에 맞는 명령어를 써 주어야 하는데 실제 키 값의 타입과 명령어가 맞지 않으면 이와 같은 에러가 난다. \n- 실제 value의 타입과 명령어가 일치하는지 확인 필요\n\t- value 타입 확인 명령어 : `type \u003ckey\u003e`\n### 타입별 값 가져오는 명령어 \n- type `string` -\u003e `GET \u003ckey\u003e`, `MGET \u003ckey\u003e`\n\t- [INCR](https://redis.io/commands/incr/) 은 string 값도 integer로 파싱하여 +1 해준다. \n- type `hash` -\u003e `HGET \u003ckey\u003e` , `HMGET \u003ckey\u003e`\n- type `list` -\u003e `Irange \u003ckey\u003e \u003cstart\u003e \u003cend\u003e`\n- type `sets` -\u003e `smembers \u003ckey\u003e`\n- type `sorted sets` -\u003e `ZRANGEBYSCORE \u003ckey\u003e \u003cmin\u003e \u003cmax`\n### References\n- [WRONGTYPE Operation against a key holding the wrong kind of value php](https://stackoverflow.com/questions/37953019/wrongtype-operation-against-a-key-holding-the-wrong-kind-of-value-php)","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/Redis-OM-Python":{"title":"Redis OM","content":"- [Object Mapper for Redis and Python](https://github.com/redis/redis-om-python)\n- high-level 추상화로 데이터 모델과 쿼리를 코드로 편하게 할수 있도록 도와주는 라이브러리\n- 인메모리 DB Redis에서도 기존 RDB 라이브러리(SQLAlchemy, Peewee, Django ORM 등)에서와 같이 **declarative model**로 데이터를 다룰 수 있게 해준다. \n- **Pydantic** 사용하여 데이터 유효성 검사 기능 역시 편리하게 사용할 수 있다. \n- Query문과 Secondary indexes  제공. \n- 동기, 비동기(asyncio) 모두 제공.\n- Python 뿐만 아니라 [.NET](https://github.com/redis/redis-om-dotnet), [Node.js](https://github.com/redis/redis-om-node), [Spring/Java](https://github.com/redis/redis-om-spring) 등 다양한 라이브러리를 제공하고 있다. \n\n## 설치하기 \n```sh\n# With pip\n$ pip install redis-om\n\n# Or, using Poetry\n$ poetry add redis-om\n```\n\n## Redis 연결\n```py\n# Model마다 redis connection을 연결하는 경우\nCustomer.Meta.database = get_redis_connection(url=\"redis://localhost:6379\",\n                          decode_responses=True))\n\n# 전체 같은 redis connection인 경우 \nredis = get_redis_connection()\nMigrator(redis).run()\n\n```\n\n## base models\n- `HashModel` : Hash 형식으로 redis에 값을 저장.\n- `JsonModel` : Json object 형식으로 redis에 값을 저장.\n\n```py\nimport datetime\n\nfrom typing import Optional\n\nfrom pydantic import EmailStr\n\nfrom redis_om import HashModel\n\nclass Customer(HashModel):\n\tfirst_name: str\n\tlast_name: str\n\temail: EmailStr\n\tjoin_date: datetime.date\n\tage: int\n\tbio: Optional[str]\n\n# andrew라는 Customer 객체 생성\n\nandrew = Customer(\n\tfirst_name=\"Andrew\",\n\tlast_name=\"Brookins\",\n\temail=\"andrew.brookins@example.com\",\n\tjoin_date=datetime.date.today(),\n\tage=38,\n\tbio=\"Python developer, works at Redis, Inc.\"\n)\n\n# 모델은 unique PK를 자동으로 생성한다.\nprint(andrew.pk) # (Redis 통신 따로 필요 없음.)\n# \u003e '01FJM6PH661HCNNRC884H6K30C'\n\n# `save()` 호출로 Redis에 모델 저장 \nandrew.save()\n\n# pk로 Customer 에서 객체를 찾을 수도 있다.\nassert Customer.get(andrew.pk) == andrew\n```\n- 자동으로 생성되는  PK는 unique 하며 정렬 가능하다. (sortable)\n- async 는 `aredis` module에서 import 받아야 한다. \n```py\n# synchronously\nfrom redis_om import HashModel\nfrom redis_om import get_redis_connection\n\n# asynchronously\nfrom aredis_om import HashModel, NotFoundError  \nfrom aredis_om import get_redis_connection\n```\n- 저장하게 되면 다음과 같이 저장된다. \n\t- Key :  `:{package}:{class_name}:{pk}`\n\t- Value : pk, 정의된 field들\n![](https://user-images.githubusercontent.com/2231510/209757427-59aab035-d09c-4332-ae86-32375257108f.png)\n\n### Globally unique primary keys\n- Redis OM은 자동으로 유니크 키값을 생성하며 이 값으로 객체를 저장하거나 검색시 사용할 수 있다. \n- 객체 생성시 바로 반환되며 Redis와의 통신은 따로 필요하지 않다. \n- 이렇게 할 수 있는 것은 [[notes/Universally Unique Lexicographically Sortable Identifiers]] 스펙을 따르고 있기 때문이다. \n\n### Data validation with Pydantic\n- 기존 레디스에서는 데이터 스키마를 강제하지 않고 있지만 Redis OM의 Pydantic model을 이용하면 다른 RDB에서와 같이 validation을 체크 할 수 있다. \n\n```py\ntry:\n\tCustomer(\n\t\tfirst_name=\"Andrew\",\n\t\tlast_name=\"Brookins\",\n\t\temail=\"Not an email address!\",\n\t\tjoin_date=datetime.date.today(),\n\t\tage=38,\n\t\tbio=\"Python developer, works at Redis, Inc.\"\n\t)\nexcept ValidationError as e:\n\tprint(e)\n\t\"\"\"\n\tpydantic.error_wrappers.ValidationError: 1 validation error for Customer\n\temail\n\tvalue is not a valid email address (type=value_error.email)\n\t\"\"\"\n```\n\n### Query expressions\n- ORM의 또다른 강력한 무기는 API를 이용한 쿼리이다. Redis OM 역시 [RediSearch](https://redis.com/modules/redis-search/) 를 이용하여 Redis에서도 DB처럼 쿼리 및 인덱싱을 할 수 있도록 해준다. \n```py\nfrom redis_om import get_redis_connection\n\nclass Customer(HashModel):\n\tfirst_name: str\n\tlast_name: str = Field(index=True) # 인덱싱할 키를 정해주고 \n\temail: EmailStr\n\tjoin_date: datetime.date\n\tage: int = Field(index=True)\n\tbio: Optional[str]\n\n# last name이 \"Brookins\" 인 모든 customers\nCustomer.find(Customer.last_name == \"Brookins\").all()\n\n```\n- async 인 경우는 아래와 같이 `aredis_om` module을 사용하며, 값을 가져올 때 `await`을 사용한다. \n```py\nfrom aredis_om import HashModel\n\nclass Customer(HashModel):\n\tfirst_name: str\n\t...\n\nawait Customer.all_pks()\n```\n-\n\n\n### Embedded model\n- `HashModel`에서는 List, Set, Hash와 같은 다른 타입은 사용할 수 없다\n- `JsonModel` 에서는 가능하다. \n```py\nfrom redis_om import EmbeddedJsonModel, JsonModel, Field\n\n  \nclass Address(EmbeddedJsonModel):\n\taddress_line_1: str\n\taddress_line_2: Optional[str]\n\tcity: str = Field(index=True)\n\tstate: str = Field(index=True)\n\tcountry: str\n\tpostal_code: str = Field(index=True)\n\nclass Customer(JsonModel):\n\tfirst_name: str = Field(index=True)\n\tlast_name: str = Field(index=True)\n\temail: str = Field(index=True)\n\tjoin_date: datetime.date\n\tage: int = Field(index=True)\n\tbio: Optional[str] = Field(index=True, full_text_search=True, default=\"\")\n\taddress: Address\n\n# \"San Antonio, TX\"에 사는 모든 customers 구하기 \nCustomer.find(Customer.address.city == \"San Antonio\",\n\t\t\t\tCustomer.address.state == \"TX\")\n```\n\n### 다른 Redis 명령어 사용하기 \n```py\nfrom redis_om import HashModel\n\nclass Demo(HashModel):\n    some_field: str\n\nredis_conn = Demo.db()\nredis_conn.sadd(\"myset\", \"a\", \"b\", \"c\", \"d\")\n\nprint(redis_conn.sismember(\"myset\", \"e\")) # False\nprint(redis_conn.sismember(\"myset\", \"b\")) # True\n```\n\n## References\n- [Introducing Redis OM for python](https://redis.com/blog/introducing-redis-om-for-python/)\n- [Introducing the Redis OM Client Libraries](https://redis.com/blog/introducing-redis-om-client-libraries/)\n- [Redis OM Python](https://redis.io/docs/stack/get-started/tutorials/stack-python/)\n- [FastAPI Integration](https://github.com/redis/redis-om-python/blob/main/docs/fastapi_integration.md) - asynchronous example code\n- [Flask Integration](https://github.com/redis-developer/redis-om-python-flask-skeleton-app) - synchronous example code","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/TimescaleDB-%EC%9A%B4%EC%98%81-%EC%BF%BC%EB%A6%AC":{"title":"TimescaleDB 운영 쿼리","content":"---\n## Timescale DB Version 확인\n```sql\nSELECT extversion FROM pg_extension where extname = 'timescaledb';\n```\n\n## Hypertable 만들기\n```sql\nSELECT create_hypertable('public.cheese_table_name', 'time');\n```\n\n## Hypertable interval 설정하기\n```sql\nSELECT set_chunk_time_interval('public.cheese_table_name', INTERVAL '24 hours');\nSELECT set_chunk_time_interval('public.cheese_table_name', INTERVAL '3 days');\n```\n- doc : [Change hypertable chunk intervals](https://docs.timescale.com/timescaledb/latest/how-to-guides/hypertables/change-chunk-intervals/#change-the-chunk-interval-length-on-an-existing-hypertable)\n\n## 테이블 사이즈 확인하기 \n```sql\nSELECT table_name, pg_size_pretty(pg_relation_size(quote_ident(table_name))) , pg_relation_size(quote_ident(table_name)) \nFROM information_schema.tables \nWHERE table_schema = 'public' \nORDER BY 3 \n```\n\n## Internal Table 까지 모두 사이즈 확인하기 (hypertable, compressed 모두 포함 )\n```sql\n\n\nSELECT table_schema, table_name, pg_size_pretty(pg_relation_size('\"'||table_schema||'\".\"'||table_name||'\"')) , pg_relation_size('\"'||table_schema||'\".\"'||table_name||'\"') \nFROM information_schema.tables \nORDER BY 4\n```\n\n## Compression 하기\n```sql\n\n-- 5일보다 오래된 chunk 찾기 \nSELECT show_chunks('cheese_table_name', older_than =\u003e INTERVAL '5 days');\n\n-- 특정 chunk compression 하기 \nSELECT compress_chunk( '\u003cchunk_name\u003e');\nSELECT compress_chunk('_timescaledb_internal._hyper_5_53187_chunk');\n\n-- compression 결과 확인 \nSELECT * FROM chunk_compression_stats('example');\n\n-- 기간 내 compression 안된게 있는 경우 수동 compression \nSELECT compress_chunk(i, if_not_compressed =\u003e true)\n    FROM show_chunks(\n        'example',\n        now()::timestamp - INTERVAL '1 week',\n        now()::timestamp - INTERVAL '3 weeks'\n    ) i;\n\n```\n\ndoc : [Manual compression](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/manually-compress-chunks/)\n\n## Decompression 하기\n```sql\nSELECT decompress_chunk('_timescaledb_internal.\u003cchunk_name\u003e');\n```\n\ndoc : [Decompression](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/decompress-chunks/)[](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/decompress-chunks/)\n\n## Compression된 Hypertable에 데이터 다시 넣기 (Backfill)\n```sql\n-- chunk 확인하기 \nSELECT show_chunks('public.cheese_table_name'); \n\n-- policy 먼저 확인하기 \nSELECT j.job_id\n    FROM timescaledb_information.jobs j\n    WHERE j.proc_name = 'policy_compression'\n        AND j.hypertable_name = 'public.cheese_table_name'; -- 1006\n\n-- policy 멈춰주기 \nSELECT alter_job(\u003cjob_id\u003e, scheduled =\u003e false);\nSELECT alter_job(1006, scheduled =\u003e false);\n\n-- chunk decompression 하기 \nSELECT decompress_chunk('_timescaledb_internal.\u003cchunk_name\u003e');\n\n-- policy 다시 활성화 시켜주기\nSELECT alter_job(\u003cjob_id\u003e, scheduled =\u003e true);\nSELECT alter_job(1006, scheduled =\u003e true);\n```\n\n## 등록된 모든 job 확인하기 \n- refresh continous aggregate policy\n- compression policy \n```sql\nSELECT * FROM timescaledb_information.jobs;\n```\n\n## Replication lag 체크하기 \n```sql\nSELECT \n  CASE \n    WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn() THEN 0\n    ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp()) \n  END AS log_delay;\n```\n\n## Job \n- retention, continuous aggregate 등 주기적으로 작업되는 policy들은 모두 job으로 등록되어있다. \n- doc : [Actions and automation](https://docs.timescale.com/api/latest/actions/)\n\n### 등록된 job 확인\n```sql\nSELECT *\nFROM timescaledb_information.jobs j\n```\n\n```markdown\n|job_id|application_name|schedule_interval|max_runtime|max_retries|retry_period|proc_schema|proc_name|owner|scheduled|config|next_start|hypertable_schema|hypertable_name|check_schema|check_name|\n\n|------|----------------|-----------------|-----------|-----------|------------|-----------|---------|-----|---------|------|----------|-----------------|---------------|------------|----------|\n\n|1|Telemetry Reporter [1]|24:00:00|00:01:40|-1|01:00:00|_timescaledb_internal|policy_telemetry|postgres|true||2022-12-18 08:02:08.220 +0900|||||\n\n|1001|Refresh Continuous Aggregate Policy [1001]|01:00:00|00:00:00|-1|01:00:00|_timescaledb_internal|policy_refresh_continuous_aggregate|nftbankci|true|{\"end_offset\": \"01:00:00\", \"start_offset\": \"3 days\", \"mat_hypertable_id\": 7}|2022-12-17 12:48:56.433 +0900|_timescaledb_internal|_materialized_hypertable_7|_timescaledb_internal|policy_refresh_continuous_aggregate_check|\n\n|1003|Compression Policy [1003]|35 days|00:00:00|-1|01:00:00|_timescaledb_internal|policy_compression|nftbankci|true|{\"hypertable_id\": 7, \"compress_after\": \"5 days\"}|2023-01-05 20:39:47.486 +0900|_timescaledb_internal|_materialized_hypertable_7|_timescaledb_internal|policy_compression_check|\n\n|1011|Retention Policy [1011]|1 day|00:05:00|-1|00:05:00|_timescaledb_internal|policy_retention|nftbankci|true|{\"drop_after\": \"90 days\", \"hypertable_id\": 20}|2022-12-17 16:55:15.014 +0900|_timescaledb_internal|_materialized_hypertable_20|_timescaledb_internal|policy_retention_check|\n\n```\n\n- `Refresh Continuous Aggregate Policy`\n\t- continuous aggregate 내가 지정한 테이블 이름으로 보이지 않는다. 내부적으로는 internal table로 되어있다. \n\t```sql\n\t   select * from _timescaledb_internal._materialized_hypertable_20\n\t```\n\t\n- `Compression Policy`\n\t- 일정 기간이 지난 데이터는 압축한다. \n\t- read만 가능 update, delete를 위해서는 uncompression을 따로 해주어야 한다.\n\t- doc : [Compression](https://docs.timescale.com/api/latest/compression/)\n- `Retention Policy`\n\t- 일정 기간이 지난 후에는 자동 삭제한다. \n\t- doc : [Data Retention](https://docs.timescale.com/api/latest/data-retention/)\n\n\n### job 삭제\n```sql\nSELECT delete_job(\u003cjob id\u003e);\nSELECT delete_job(1000);\n```","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/Tree-%EB%AA%85%EB%A0%B9%EC%96%B4":{"title":"Tree 명령어","content":"- 폴더 구조를 시각적으로 보기 쉽도록 트리 형태로 보여주는 명령어\n\n## Install\n\n### MacOS (Homebrew)\n```\nbrew install tree\n```\n\n### Linux (RHEL / CentOS / Fedora / Rocky / Alma Linux)\n```\nyum install tree  \n## CentOS/RHEL 8.x and Fedora user try the dnf command ##  \ndnf install tree\n```\n\n### Linux (Debian / Mint / Ubuntu Linux)\n```\nsudo apt-get install tree\n```\n\n## How to use\n```\ntree .\n\n➜  new-poetry-repository tree\n.\n├── README.md\n├── new_poetry_repository\n│   └── __init__.py\n├── pyproject.toml\n└── tests\n    └── __init__.py\n\n```\n\n## References\n- [Linux see directory tree structure using tree command](https://www.cyberciti.biz/faq/linux-show-directory-structure-command-line/)","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/Uncle-Block":{"title":"Uncle Block","content":"\n## References \nhttps://docs.alchemy.com/docs/what-are-uncle-blocks","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/Universally-Unique-Lexicographically-Sortable-Identifiers":{"title":"ULID","content":"- 128 bits 이며 UUID와 호환 가능\n- 매 밀리세컨드마다 1.21e+24 유니크값 생성 가능\n- 시간을 나타내는 앞 48bits와 임의값 80bits로 구성된 값. \n```\n 01AN4Z07BY      79KA1307SR9X4MV3\n\n|----------|    |----------------|\n Timestamp          Randomness\n   48bits             80bits\n```\n- Timestamp\n\t- timestamp에서 밀리세컨드 단위로 기록하여 생성 순서대로 정렬할 수 있다.\n\t- 10889년까지 만들수 있음. \n- 대소문자 구별하지 않음 \n- Crockford's Base32 인코딩 (I, L, O, U 제외) - UUID 보다 더 나은 성능 \n- [monotonicity](https://github.com/ulid/spec#monotonicity) 옵션을 사용하여 랜덤 숫자에 1씩 증가하여 충돌을 피할 수도 있다. \n\n## UUID의 한계점\n- [Universally Unique Identifier(UUID)](https://datatracker.ietf.org/doc/html/rfc4122.html)는 중앙 관리식이 아니면서도 유일성을 보장해주는 방식\n- 32개의 16진수로 표시되며 총 5개의 version이 있다. \n\t- v1/v2 : 고유한 MAC주소에 대한 접근 필요. 다양한 환경에 사용되기 어려움\n\t- v3/v5 : 고유한 시드가 필요하고 무작위 ID 생성으로 여러 데이터 구조에서 조각화가 될 수 있다. \n\t- v4 : 완전 랜덤으로 조각화 될 가능성이 있다. \n\n## References\n- [ulid spec](https://github.com/ulid/spec)\n- [UUID vs ULID](https://velog.io/@injoon2019/UUID-vs-ULID)\n- [How probable are collisions with ULID’s monotonic option?](https://zendesk.engineering/how-probable-are-collisions-with-ulids-monotonic-option-d604d3ed2de)","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/arweave.org":{"title":"arweave.org","content":"\n- [www.arweave.org](https://www.arweave.org/)\n- ","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/atomic-swap":{"title":"Atomic swap","content":"\n- 중앙화된 거래소를 거치지않고 서로 다른 코인을 직접 교환하는 것\n- full name : atomic cross chain trading\n- 코인 스왑(coin swap) 혹은 에어스왑(airswap)이라고도 한다. ","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/erc-20":{"title":"ERC-20","content":"- [ERC-20 Token Standard](https://ethereum.org/en/developers/docs/standards/tokens/erc-20/)\n\n- 각 토큰은 다른 토큰과 정확히 동일한 속성을 가지고 있다. ETH과 동일하게 작동하며, 1개의 토큰은 다른 토큰과 항상 같다. \n\n```sol\nmapping(address =\u003e uint256) private _balances;\n```\n- 누가(adress) =\u003e 얼마(unit256) 를 가지고 있는지 저장  \n\n## Methods \n```\nfunction name() public view returns (string)\nfunction symbol() public view returns (string)\nfunction decimals() public view returns (uint8)\nfunction totalSupply() public view returns (uint256)\nfunction balanceOf(address _owner) public view returns (uint256 balance)\nfunction transfer(address _to, uint256 _value) public returns (bool success)\nfunction transferFrom(address _from, address _to, uint256 _value) public returns (bool success)\nfunction approve(address _spender, uint256 _value) public returns (bool success)\nfunction allowance(address _owner, address _spender) public view returns (uint256 remaining)\n\n```\n- `transfer` : `from` 계좌 =\u003e `to`계좌로 잔고를 바꿈 ([구현 코드](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/ERC20.sol#L226-L248))\n\n## References\n- [OpenZeppelin - ERC-20 Implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/ERC20.sol)\n- ","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/ethers.js":{"title":"ethers.js","content":"- [ethers.js](https://docs.ethers.io/v5/)\n-  Web3 JavaScript 라이브러리로 2016년에 Richard Moore가 만들었다. \n- 기존 라이브러리와 다르게 web3 기반으로 [[notes/Ethereum]] 네트워크와 상호작용이 쉽다.\n- 처음에는 ethers.io를 위해 만들어졌음\n- Typescript로 작성되어있으며 \n\n## References\n-[Full Guide: What is Ethers.js?](https://moralis.io/full-guide-what-is-ethers-js/)","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/hello-%EA%B2%80%EC%83%89-%EC%97%94%EC%A7%84":{"title":"hello 검색 엔진","content":"- [https://beta.sayhello.so/](https://beta.sayhello.so/)\n- The search engine for instant answers\n- 질문에 대해 바로 대답(answer)를 보여주고 써먹을 수 있는 코드 조각을 바로 보여주는 개발자 친화 검색 엔진 \n\n![](https://user-images.githubusercontent.com/2231510/204835776-eae19bc0-3a41-44c9-bed5-03ddbd0d51fd.png)\n\n\n## How to best use Hello\n- 자연어 검색어 지원. \n- `How to~` `What is~` 와 같이 검색하기\n- \"check if string is a palindrome\" =\u003e \"how to check if string is a palindrome in javascript\"\n- 질문 형식으로 검색하기 \n\t- \"rust\" =\u003e \"what is rust?\"\n\n## VSCode Extension\n\n![](https://hello-code-snippets-vscode-extension-assets-public.s3.amazonaws.com/demo.png)\n\n- [Hello Code Snippets](https://marketplace.visualstudio.com/items?itemName=HelloCognition.hello-code-snippets)\n","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/readme.io-setting":{"title":"readme.io 세팅","content":"\n## API References Try it Authentication  추가하기 \n![](https://user-images.githubusercontent.com/2231510/205079888-b4b68d17-aefc-4043-be51-6a94e89e64cd.png)\n- `openapi.json` 으로 싱크하는 경우, open api spec 중 `SecurityScheme` 을 맞춰주어야 한다. \n- [Security Scheme Object](https://docs.readme.com/main/docs/openapi-compatibility-chart#security-scheme-object)\n\n### FastAPI에서 추가하기 \n```python\nfrom fastapi import FastAPI, Security\nfrom fastapi.security import APIKeyHeader\n\nx_api_key = APIKeyHeader(name=\"x-api-key\", auto_error=False)\n\nasync def auth(x_api_key: str = Security(x_api_key)):\n  if x_api_key == get_config(\"API_KEY\"):\n    return x_api_key\n  else:\n    raise UnauthorizedException()\n\nrouter = APIRouter(dependencies= [Depends(auth)])\n\napp = FastAPI()\napp.include_router(router)\n\n```\n\nswagger에서도 Authorize가 생긴 것을 볼 수 있다. \n![](https://user-images.githubusercontent.com/2231510/205088702-dc58cc59-75d9-47d1-8215-2329a673400d.png)\n`openapi.json` 확인하면 `components.securitySchemes` 가 추가 되어있다.\n![](https://user-images.githubusercontent.com/2231510/205089535-3e12ea04-6082-44ff-93f3-ac7ca1e3a491.png)\n- default값 까지 넣으려면 아래와 같이 `x-default` 를 추가해주면 된다.\n ```json\nsecurityDefinitions: {\n     API_KEY: {\n        type: \"apiKey\",\n        name: \"x-api-key\",\n        in: \"header\",\n        \"x-default\": \"demo-api-key\",\n\t},\n},\n```\n- [swagger authentication spec](https://swagger.io/docs/specification/authentication/) ","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null},"/notes/unleash":{"title":"unleash","content":"- 피쳐 토글 서비스 (비슷한 서비스로는 [[notes/LaunchDarkly]] 가 있다.)  \n- 코드 배포와 기능 배포를 서로 분리시킴으로써 더욱 안전한 배포 유연한 기능 오픈/클로즈를 수행할 수 있다. \n- Client (Server Side) / Frontend (Web+Mobile) 각각의 SDK를 잘 지원하고 있어 여러 방면에서 사용하기 좋다. \n![](https://docs.getunleash.io/assets/images/unleash-architecture-40c7293e777a7bea0df4edeeef8a6bf4.svg)\n- Enterprise와 opensource 둘 다 제공하고 있어 입맛에 알맞게 사용할 수 있다. \n\t- [Dockerfile](https://docs.getunleash.io/reference/deploy/getting-started)\n\t- [Helm chart](https://github.com/unleash/helm-charts/)\n\t\n## Feature 토글 타입\n- Unleash에서는 5가지 토글 타입을 제공하고 있다. ([doc](https://docs.getunleash.io/reference/feature-toggle-types))\n- 토글 타입별로 기능차이는 없으며 표현되는 **아이콘 모양만 다르고** 각각의 **예상 수명시간**이 다를 뿐이다. \n\t- 토글 타입을 정했더라도 나중에 변경 가능하다. \n\t- [타입별 예상 수명시간](https://www.getunleash.io/blog/feature-toggle-life-time-best-practices) \n- Feature 토글 타입\n\t- Release : trunk based 환경에서 CD에서 계속해서 배포시 (예상 수명 : 40 days)\n\t- Experiment : 여러 변수를 사용하는 경우 혹은 A/B 테스팅(예상 수명 : 40 days)\n\t- Operational :  운영 측면에서 사용하는 경우 (예상 수명 : 7 days)\n\t- Kill switch : 천천히 기능 삭제해나갈때. (예상 수명 : 영구) - [kill switch best practice](https://www.getunleash.io/blog/kill-switches-best-practice)\n\t- Permission : 특정 유저들에게만 기능 혹은 프러덕트를 열어주는 경우 (예상 수명 : 영구)\n- `stale` 로 mark 해주면 더 이상 사용하지 않는 토글로 표시해둘 수 있다. \n\t- \u0008바로 삭제하게 되면 혹시나 예상치 못한 장애로 이어질 수 있지만 이렇게 먼저 표시를 해두게 되면 \"health\" 탭에서 stale 된 토글이 현재 얼마나 들어오고 있는지 확인할 수 있다. \n\t- [Technical Debt](https://docs.getunleash.io/reference/technical-debt) 이 기능이 깨끗한 코드를 유지하는데 큰 도움이 될 것 같다.\n\n![](https://user-images.githubusercontent.com/2231510/208935165-cda5e879-5848-47e7-a15a-357c8e5daae8.png)\n\n## API Token 만들기 \n- [How to create API Tokens](https://docs.getunleash.io/how-to/how-to-create-api-tokens)\n- 연결 코드에서 사용할 API Token을 먼저 만들어야 한다.\n- 서버사이드는 Type `Client`, 모바일이나 웹은 Type `Frontend`, Unleash 자체에 대한 API를 위해서는 Type `Admin` 으로 만들면 된다.\n- environment 마다 token을 발행하여 환경별로 기능을 조절할 수 있다. \n![](https://user-images.githubusercontent.com/2231510/208928220-536afe05-ba09-4875-8dc4-6bb8d223f4c7.png)\n- 생성하면 SDK에서 연결시 사용해야하는 \"API URL\"이 나온다. \n\t- managed를 사용하게되면 `https://us.app.unleash-hosted.com/**/api/` \n\n## SDK 연결하기 - Python\n- [Python SDK](https://docs.getunleash.io/reference/sdks/python)\n```py \nfrom UnleashClient import UnleashClient  \n  \nclient = UnleashClient(  \nurl=\"`https://us.app.unleash-hosted.com/**/api/\",  # 위에서 받은 API URL 입력\napp_name=\"\u0008cheese\", # 나중에 admin ui에서 applications에 뜬다.  \ncustom_headers={'Authorization': '\u003cAPI token\u003e'})  # 위에서 만든 API token Thpe \"Client\"\n  \nclient.initialize_client()  \n  \nclient.is_enabled(\"unleash.beta.variants\")\n```\n- 위와 같이 연결 후 서버를 시작하면 다음과 같이 연결된 application들을 확인 할 수 있다. \n![](https://user-images.githubusercontent.com/2231510/208928977-8bd642f0-578c-4351-9915-04658a9725a6.png)\n\n\n## References\n- [맘편한세상에서 사용하는 피쳐 토글 서비스](https://tech.mfort.co.kr/blog/2022-11-24-feature-toggle/)\n- [# Feature Toggles (aka Feature Flags)](https://martinfowler.com/articles/feature-toggles.html)","lastmodified":"2022-12-28T04:42:22.105473524Z","tags":null}}