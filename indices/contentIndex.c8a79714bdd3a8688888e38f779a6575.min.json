{"/":{"title":"🪴","content":"\n치즈 나무 지식 걸렸네 🧀🌲\n\n## All notes 📝\n\n- [All notes](/notes/)\n- [All tags](/tags/)\n","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/2023.01-books":{"title":"2023년  1월 독서","content":"\n## 오늘 또 일을 미루고 말았다\n- [오늘 또 일을 미루고 말았다 : 일에 쫓겨 인생마저 꼬였을 때, 오늘부터 로켓 스타트 시간 관리법](http://www.yes24.com/Product/Goods/45094325)\n- 마이크로소프트에서 윈도우 95, 더블클릭 등 개발에 참여했던 개발자 나카지마 사토시의 시간관리 법에 대한 책.\n- 효율적인 시간관리로 좋아하는 일을 더 자유롭게 할 수 있는 방법에 대해서 이야기 하고 있다. \n- **로켓 스타트 시간 관리법** : 싫어하는 일을 빨리 끝내고, 좋아하는 일을 오래 하기 위한 해결책 \n\t- \"두려워해야 할 대상은 실패가 아니다. 자신이 '하고 싶은 일'에 불성실하게 임하는 태도다.'\" \n\t- \"프로그래머에게 요구되는 것은 100점이 아닌 80~ 90점짜리 프로그램을 기한 내에 완성하는 일이다.\"\n\t- \"하루 업무량의 80%를 오전 중에 끝내야 한다.\"\n- 하기 싫은 일을 빨리 끝내버리면 좋아하는 일을 충분히 즐길 수 있다. 80%일을 빨리 끝내면 나머지 시간에 20%의 엣지를 채워서 완성도를 높힐 수 있다.\n- 개발자의 이야기, 그것도 윈도우 개발에 관련한 이야기이기 때문에 개발자 커리어 측면에서도 즐겁게 읽을 수 있었다.","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/ABI":{"title":"ABI","content":"\n- Contract **A**pplication **B**inary **I**nterface\n- Smart Contract 함수와 파라미터에 대한 Interface 정의 \n- 가지고 있는 정보\n\t- 함수에 대한 **정보** \n\t- 함수에서 사용하는 **인수**\n![](https://static.packt-cdn.com/products/9781789954111/graphics/assets/fe0f2ffc-2f3c-4615-9cb5-43c8e036239b.png)\n- 예시 : https://etherscan.io/address/0xb59f67a8bff5d8cd03f6ac17265c550ed8f33907#code\n```json\n{\n   \"anonymous\":false,\n   \"inputs\":[\n      {\n         \"indexed\":true,\n         \"name\":\"from\",\n         \"type\":\"address\"\n      },\n      {\n         \"indexed\":true,\n         \"name\":\"to\",\n         \"type\":\"address\"\n      },\n      {\n         \"indexed\":false,\n         \"name\":\"value\",\n         \"type\":\"uint256\"\n      }\n   ],\n   \"name\":\"Transfer\",\n   \"type\":\"event\"\n},\n{\n   \"anonymous\":false,\n   \"inputs\":[\n      {\n         \"indexed\":true,\n         \"name\":\"old\",\n         \"type\":\"address\"\n      },\n      {\n         \"indexed\":true,\n         \"name\":\"current\",\n         \"type\":\"address\"\n      }\n   ],\n   \"name\":\"NewOwner\",\n   \"type\":\"event\"\n}\n```\n- `anonymous` : 이 method가 public인지 아닌지 (default: `false`. public 이다.)\n- `type` : 어떤 데이터 타입인지\n\t- `event`\n\t- `inputs` 안에는 input type\n- `name` : item 혹은 파라미터의 이름 \n- `indexed` \n\t- `true` : `topics` 에 저장된다. \n\t- `false` : `data` 필드에 들어간다. \n\n\n## References\n- [Understanding Logs: Deep Dive into eth_getLogs](https://docs.alchemy.com/docs/deep-dive-into-eth_getlogs)\n- [Understanding event logs on the Ethereum blockchain](https://medium.com/mycrypto/understanding-event-logs-on-the-ethereum-blockchain-f4ae7ba50378)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/AWS-CLI":{"title":"AWS CLI","content":"\n\n## AWS Configuration 설정 확인하기 \n`aws configure`로 구성한 credential 확인하려면 아래와 같이 할 수 있다.\n\n```sh\nvi ~/.aws/credentials\n\n[default]\naws_access_key_id={ACCESS_KEY}\naws_secret_access_key={SECRET_ACCESS_KEY}\n\nvi ~/.aws/config\n\n[default]\nregion=us-west-2\noutput=json\n```\n\n- https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/cli-configure-files.html\n\n\n## AWS S3 파일 옮기기\n\n```sh\naws s3 mv s3://{from_path} s3://{to_path} --recursive\n```\n\n- web console 에서도 가능하다\n![](https://user-images.githubusercontent.com/2231510/206854577-026b629c-6c0d-4e25-a8bd-a47fda6dab95.png)\n","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/AWS-Cost-Optimization":{"title":"AWS 비용 최적화","content":"\n## 1) 리소스에 Tag 달기\n- 리소스 만들고 맨 마지막에 나오는 optional 메타데이터 (key-value)\n- \n## 2) 데이터 전송 비용\n\n## 3) Compute 비용 최적화 정리\n\n## 4) AWS Trusted Advisor\n\n## 5) 우리 회사에 맞는 비용 대시보드 \n\n\n## References\n- [AWS 쓰다 보면 꼭 고민하는 것, 비용 최적화!](https://www.youtube.com/watch?v=hY7ssLoJcWQ)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/AWS-S3-presigned-URL":{"title":"AWS S3 presigned URL 사용 방법","content":"- S3는 기본적으로 private이지만, presigned_url을 통해 권한이 없는 사람에게도 object를 받을 수 있도록 임시로 허용할 수 있다. \n-  만료시간을 주어 access를 조절할 수 있다. \n- presigned_url 만들 시에는 만든 **사용자의 권한**에 따라 제한된다.\n\t- IAM instance profile : 최대 6시간 사용 가능한 presigned_url 생성 가능 \n\t- AWS Security Token Service : 최대 36시간 \n\t- IAM user : 최대 7일 (AWS Signature Version 4 사용시)\n- 만료 시간 전까지는 계속 사용할 수 있다. \n## `generate_presigned_url` \n- `boto3` 를 이용하여 쉽게 presigned URL을 만들 수 있다. \n\n```python\nimport logging\nimport boto3\nfrom botocore.exceptions import ClientError\n\ndef create_presigned_url(bucket_name, object_name, expiration=3600):\n    \"\"\"Generate a presigned URL to share an S3 object\n\n    :param bucket_name: string\n    :param object_name: string\n    :param expiration: Time in seconds for the presigned URL to remain valid\n    :return: Presigned URL as string. If error, returns None.\n    \"\"\"\n\n    # Generate a presigned URL for the S3 object\n    s3_client = boto3.client('s3')\n    try:\n        response = s3_client.generate_presigned_url('get_object',\n                                                    Params={'Bucket': bucket_name,\n                                                            'Key': object_name},\n                                                    ExpiresIn=expiration)\n    except ClientError as e:\n        logging.error(e)\n        return None\n\n    # The response contains the presigned URL\n    return response\n```\n\npresigned URL을 통해서는 GET, PUT 모두 가능한데 이때 client method를 지정하여 내려줄 수 있다. \n- GET : `get_object`\n- PUT : `put_object`\n``\n`get_object` 용으로 반환된 URL은 다음과 같은 모양으로 생겼다. \n```\nhttps://{bucket_name}.s3.amazonaws.com/{key}?AWSAccessKeyId={aws_access_key}\u0026Signature={signature}\u0026Expires={expire_unixtimestamp}\n```\n\n\n### 동작 방식 \n![](https://user-images.githubusercontent.com/2231510/208320571-2ef6f2c5-c6db-413a-b171-879d8bed1b78.png)\n(출처 : https://insecurity.blog/2021/03/06/securing-amazon-s3-presigned-urls/)\n\n안전하게 사용하기 위해서는 \n- 해당 S3 버킷의 sever access log 활성화\n- 파일 이름은 예측하기 어렵도록 UUID를 사용한다.\n\n## S3 Client Sample Code with boto3 in Python\n```python\nimport boto3\n\nS3_ACCESS_KEY = 's3_access_key'\nS3_SECRET_KEY = 's3_secret_key'\n\nclass S3Client():\n\n    def __init__(self, aws_access_key=S3_ACCESS_KEY, aws_secret_key=S3_SECRET_KEY):\n        self.aws_access_key = aws_access_key\n        self.aws_secret_key = aws_secret_key\n        self.client = boto3.client(\n            's3',\n            aws_access_key_id=self.aws_access_key,\n            aws_secret_access_key=self.aws_secret_key)\n\n    def list_folder_contents(self, bucket_name, folder_name=None, exclude_self=True):\n        if folder_name:\n            folder_name = os.path.join(folder_name, '') # ensure it ends in a slash\n        else:\n            folder_name = '' # non-prefixed -- all folders\n\n        objects = []\n        incomplete = True\n        continuation_token = None\n\n        while incomplete:\n            if continuation_token:\n                response = self.client.list_objects_v2(\n                    Bucket=bucket_name,\n                    Prefix=folder_name,\n                    ContinuationToken=continuation_token,\n                )\n            else:\n                response = self.client.list_objects_v2(\n                    Bucket=bucket_name,\n                    Prefix=folder_name,\n                )\n\n            objects += response.get('Contents', [])\n            if response.get('isTruncated', False):\n                continuation_token = response['NextContinuationToken']\n            else:\n                incomplete = False\n\n        if exclude_self:\n            contents = [obj['Key'] for obj in objects if obj['Key'] != folder_name]\n        else:\n            contents = [obj['Key'] for obj in objects]\n\n        return contents\n\n    def move_object(self, source_bucket_name=None, source_name=None, target_name=None, target_bucket_name=None):\n        \"\"\"\n        Moving an object on S3 requires two steps:\n        1) copy to destination\n        2) delete from source\n        :param source_bucket_name: (str) name of bucket to copy from\n        :param source_name: (str) object key to copy from\n        :param target_name: (str) object key to copy to\n        :param target_bucket_name: (str) name of bucket to copy to. If None, use the source_bucket_name\n        :return None:\n        \"\"\"\n\n        if target_bucket_name is None:\n            target_bucket_name = source_bucket_name\n\n        response = self.client.copy_object(\n            Bucket=target_bucket_name,\n            Key=target_name,\n            CopySource={\n                'Bucket': source_bucket_name,\n                'Key': source_name\n            }\n        )\n\n        if response.get('CopyObjectResult', False):\n            # Assume it worked\n            response = self.client.delete_object(\n                Bucket=source_bucket_name,\n                Key=source_name\n            )\n\n\n    def upload_file(self, source_name, target_name, bucket_name):\n        \"\"\"\n        Uploads the source to the target in the bucket\n        :params source_name: (str) name of file to upload\n        :params target_name: (str) name of object on S3 (include any folder or path)\n        :params bucket_name: (str) bucket to receive file\n        :returns: None\n        \"\"\"\n        self.client.upload_file(\n            source_name,\n            bucket_name,\n            target_name\n        )\n\n    def download_file(self, source_name, target_name, bucket_name):\n        \"\"\"\n        Downloads the source object from the bucket into the target file. Note that the target_name paths should already exist.\n        :params source_name: (str) object key to download\n        :params target_name: (str) destination for download -- all paths to the base file must already exist\n        :params bucket_name: (str) name of bucket to download from\n        :returns: None\n        \"\"\"\n        self.client.download_file(\n            bucket_name,\n            source_name,\n            target_name\n        )\n\tdef generate_presigned_url(self, bucket_name, key, expiration=3600):\n        return self.client.generate_presigned_url(\n            ClientMethod=\"get_object\",\n            Params={\n                \"Bucket\": bucket_name,\n                \"Key\": key,\n            },\n            ExpiresIn=expiration, # seconds\n        )\n```\n\n\n## Preferences\n- [미리 서명된 URL을 생성하여 객체 업로드](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/PresignedUrlUploadObject.html)\n- [미리 서명된 URL 기능 제한](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/using-presigned-url.html#PresignedUrlUploadObject-LimitCapabilities)\n- [Example: An S3 proxy client written in Python](https://gist.github.com/tamouse/b5c725082743f663fb531fa4add4b189)\n- [Using presigned URLs](https://docs.aws.amazon.com/AmazonS3/latest/userguide/using-presigned-url.html)\n- [Securing your Amazon AWS S3 presigned URLs, tips and tricks](https://insecurity.blog/2021/03/06/securing-amazon-s3-presigned-urls/)\n- [S3 pre-signed URL 한번만 사용하기](https://mygumi.tistory.com/380)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Amazon-Athena":{"title":"Amazon Athena","content":"\n","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Block-Proposer":{"title":"Block Proposer","content":"\n\n## References\n- [What is Proposer / Builder Separation (PBS)?](https://www.alchemy.com/overviews/proposer-builder-separation#what-is-a-block-proposer-2)\n","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Blockchain":{"title":"Blockchain","content":"\n## Blockchain\n-   public database\n-   한 네트워크 내 여러 컴퓨터들을 통해 저장하고, 공유하는 분산형 데이터베이스\n\n## Block\n-   연속성있는 그룹(Blocks)에 저장되는 데이터(data+state)\n-   예를 들어, ETH를 전송했다면, 이 트랜잭션 데이터는 block에 저장됨\n\n## Chain\n-   각 블록은 부모 블록를 참조하고 있다. 즉, 블록들은 연결되어 있음.\n-   블록들은 연결되어 있기 때문에, 블록체인이라고 부름\n\n## Web3\n- 탈중앙화, 블록체인 기술, 토큰 기반 경제학과 같은 개념을 통합한 WWW의 새로운 아이디어\n- Web1 : read-only\n- Web2 : read-write\n- Web3 : read-write-own\n\n## Cryptocurrency\n- 중앙 기관이 아닌 암호를 사용하여 분산 시스템에서 검증 및 유지되는 디지털 통화\n- crypto-currency 혹은 crypto 라고 불린다.\n\n## References\n- [alchemy Web3 Glossary](https://docs.alchemy.com/docs/web3-glossary)\n- ","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Clickhouse":{"title":"Clickhouse","content":"- [https://clickhouse.com/](https://clickhouse.com/)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Common-Injection":{"title":"Common Injection","content":"\n\n## References\n- https://owasp.org/www-community/attacks/Command_Injection","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/DB-Connection-Pool":{"title":"DB Connection Pool이 필요한 이유","content":"\n## DB Connection\n어플리케이션이 DB server와의 통신을 위한 연결로 SQL 문을 보내고 그 결과값을 받기 위해 사용한다. 데이터베이스 서버도 앱서버와 같이 특정 포트 (예를 들어, MySQL 데이터베이스 서버는 기본 `3306`)로 떠 있으며, 이 서버와 백엔드 서버가 **TCP-IP protocol**로 Connection을 맺는다. 이때, 필요에 따라 user name, password와 같은 credentials 가 필요할 수도 있다.\n\nDB Connection을 맺기 위해서는 DB Host, Port, database name, driver, user name, password 등이 필요하다. \n\n```yaml\ndb_url      = jdbc:mysql://HOST/DATABASE  \ndb_driver   = com.mysql.jdbc.Driver  \ndb_username = USERNAME  \ndb_password = PASSWORD\n```\n\n## DB Connection 생애주기\n![](https://vladmihalcea.com/wp-content/uploads/2014/04/connectionlifecycle.gif)\n(ref : https://vladmihalcea.com/wp-content/uploads/2014/04/connectionlifecycle.gif)\n1. DB로 Connection을 처음 연결 시도 한다.\n2. Connection을 실제로 열기 전, user credential 이 유효한지 인증 검사를 한다. \n3. 검사를 통과하면 TCP socket을 연다.\n4. SQL 문이 들어오면 이에 대한 결과 데이터를 보내준다. \n5. DB Connection을 닫는다.\n6. TCP socket이 닫힌다. \n\n위에서 보다시피 DB Connection을 맺는 것은 매우 비싸고 시간이 많이 드는 작업이다. 그렇기 때문에 필요할 때마다 connection을 맺는 것은 어플리케이션 자체 속도를 늦춰서 서비스 품질에 악영향을 끼칠 수 있다. 또 각각의 요청마다 connection을 맺게되면 동시에 너무 많은 connection이 만들어지게 되며 DB server의 CPU와 memory를 너무 많이 사용하여 resource 부족 문제를 야기할 수 있다. \n\n이 문제를 풀기 위하여 Connection Pool을 사용한다. 미리 Connection을 맺어두고 어플리케이션에서는 이미 만들어진 Connection을 재사용(reuse)한다. \n\n![](https://user-images.githubusercontent.com/2231510/209923693-a45f6129-3053-4089-a626-ef77143b6032.png)\n(ref:https://raw.githubusercontent.com/practicalli/graphic-design/live/practicalli-clojure-webapps-database-postgres-no-connection-pool.png)\n\n\n## References\n- [Why do we need a Database Connection Pool? - every programmer must know](https://dineshchandgr.medium.com/why-do-we-need-a-database-connection-pool-every-programmer-must-know-9f90e7c8e5af)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/DB-Index":{"title":"DB Index","content":"\n## Simple indexes\n## Secondary indexes\n## B-trees\n## Hash tables\n","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/ERC-1155":{"title":"ERC-1155","content":"","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/ERC-721":{"title":"ERC-721","content":"","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/ERC721A":{"title":"ERC721A","content":"- [ERC721A](https://www.erc721a.org/)\n- [[notes/ERC-721]] 표준의 확장. \n- 토큰을 배치로 발행하여 막대한 양의 gas fee를 방지. 여러 토큰을 한번에 발행  \n\n### ERC721A 구현하기 \n- [[notes/Hardhat]]으로 프로젝트 세팅하기 \n\n```sh\nnpx hardhat\n```\n\n\n\n## References\n- [# **ERC721A** Quick Start](https://coinsbench.com/erc721a-quick-start-24131e198e37)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Ethereum":{"title":"Ethereum","content":"\n## Ethereum\n- 컴퓨터가 내장된 블록체인.\n- 비트코인과 다른 점 : 암호화폐로서의 기능 뿐만 아니라 프로그래밍이 가능. 네트워크에서 분산형 애플리케이션을 구축 및 배포할 수 있음.\n- 중앙 주체의 통제 없이 앱과 조직을 구축하고, 자산을 보유하고, 거래하고 소통할 수 있음\n\n## EVM\n- [[notes/Ethereum Virtual Machine]]\n- 글로벌 가상 컴퓨터, 모든 참여자들이 코드 실행을 요청 할 수 있고, 코드 실행은 EVM 상태를 변경시킴\n- [https://ethereum.org/ko/developers/docs/evm](https://ethereum.org/ko/developers/docs/evm)\n\n## Ether\n- ETH : native cryptocurrency of Ethereum\n- 화폐로서 사용되는 암호화폐\n- 거래 요청 확인 및 실행한 컴퓨터에 대한 보상으로 지급됨\n\n## Ethereum Classic\n- 오리지널 이더리움 네트워크 해킹을 해결하기 위해 하드포크 하기 전의 오픈소스 블록체인\n- ETC : 이더리움 클래식의 고유 통화\n\n## Smart contracts\n- 이더리움 블록체인 상에서 실행되는 프로그램\n- 이더리움 블록체인 상의 특정 주소에 있는 코드(function)과 데이터(state)의 모음\n\n### Smart contract 동작 방식\n- 네트워크 상에 미리 결정된 조건이 충족될 때 동작 실행\n\n## Minting Ether\n- 이더리움 원장(Ethereum ledger)에 새로운 이더리움을 발행하는 것\n- underlying Ethereum 만이 새로운 ether를 만들 수 있다.\n\n## Burning Ether\n- 이더리움 원장(Ethereum ledger)에서 이더리움을 삭제하는 것\n\n## Denominations of ether\n- 이더 종파\n- 이더리움에서 적은 금액으로 거래가 자주 일어나, 이를 용이하게 하기 위해 만든 단위\n- \"Wei\"와 \"Gwei\"가 가장 유명하다.\n- [https://ethereum.org/ko/developers/docs/intro-to-ether/#denominations](https://ethereum.org/ko/developers/docs/intro-to-ether/#denominations)\n\n### Wei\n- 이더(ether)의 가장 작은 단위\n- 1 wei = 10^-18 ether = 0.000000000000000001 ether\n- 1 ether = 10^18 wei = 1,000,000,000,000,000,000 wei\n- 주로 기술적 구현단에서 자주 사용됨.\n- 비트코인 탄생에 큰 영향을 준 B-Money를 고안한 인물인 [Wei Dai](https://en.wikipedia.org/wiki/Wei_Dai)의 이름을 따서 만들어졌다.\n\n### Gwei\n- giga-wei. 1,000,000,000 wei\n- Gas 이야기 할 때 많이 사용됨.\n\n## Transferring ether\n- 각 트랜잭션에는 `value` 필드 : 전송할 ether의 양(wei 단위로)\n- sender -\u003e recipient 주소로 옮겨짐\n- recipient 주소가 smart contract라면 smart contract 실행에 대한 gas fee 지불하는데 새용될 수도 있다.\n- [https://ethereum.org/ko/developers/docs/intro-to-ether/#transferring-ether](https://ethereum.org/ko/developers/docs/intro-to-ether/#transferring-ether)\n\n  \n## Ethereum accounts\n- 이더리움에서 거래할 수 있는 ether 잔고를 가지고 있는 entity\n- account은 사용자가 사용하거나 smart contract를 배포할 수 있다.\n\n## Types of Ethereum accounts\n- 1) Externally-owned account (EOA) : priveate key를 가지고 있는 계정\n- 2) Contract account : 네트워크에 배포된 smart contract.\n\n### 1) Externally-owned account (EOA)\n- 만드는데 비용이 들지 않는다.\n- 트랜잭션을 일으킬 수 있다.\n- EOA 사이에서 ETH나 토큰을 전송할 수 있다.\n- public key와 private key 암호화된 키 쌍을 가지고 있다.\n\n### 2) Contract account\n- 생성시 비용이 든다. 네트워크 스토리지를 사용하기 때문에\n- 트랜잭션 수신하는 응답으로만 트랜잭션을 보낼 수 있다. (스스로 트랜잭션을 보낼 수 없다.)\n- 외부에서 contract account로의 전송을 통해 여러 가지 작업할 수 있는 코드를 트리거링 할 수 있다. ex. 토큰 보내기 혹은 새로운 contract 만들기 등\n- private 키가 없다. 대신 code 내 로직에 의해 컨트롤 된다.\n\n\n## Ethereum accounts have four fields\n![](https://ethereum.org/static/19443ab40f108c985fb95b07bac29bcb/302a4/accounts.png)\n - [AN ACCOUNT EXAMINED](https://ethereum.org/ko/developers/docs/accounts/#an-account-examined)\n\n### nonce\n- 각 account에서 보낸 트랜잭션의 수. 트랜잭션 카운터\n- 한 트랜잭션을 한번만 처리할 수 있게 됨. replay attack 방지.\n- account 에서 생성된 contract 갯수.\n\n### balance\n- 주소가 소유한 wei의 수.\n\n### codeHash\n- EVM(이더리움 가상머신) 내 account 코드.\n- 변하지 않는 값. (다른 필드들은 변함)\n- contract account의 경우, contract의 코드를 가리킨다.\n- account가 메세지를 받게되면 코드 실행\n- 코드 조각은 나중에 검색할 수 있도록 해당 해시 아래 상태 데이터베이스(state database)에 포함됨\n- EOA의 경우, 빈 string 해시 값.\n\n### storageRoot\n- storage hash\n- account의 storage content의 해시 값.\n- default는 비어 있음.\n\n## Contract address\n- 42자로 구성된 16진수 주소\n\t- ex. `0x06012c8cf97bead5deae237070f9587f8e7a266d`\n- Contract가 이더리움 블록체인에 배포될 때 부여된다.\n- 만든 사람의 주소와 해당 주소에서 보낸 트랜잭션의 수([nonce](#nonce))를 통해 만들어진다.\n\n## Validator Keys\n- 작업 증명(proof-of-work)에서 지분 증명(proof-of-stake)로 변경되며 필요해짐\n- BLS(Boneh-Lyn-Shacham) 키는 검증인(validator)를 식별하는데 사용 \n- BLS키는 효율적으로 집계하여 네트워크 합의 도달하는데 필요한 대역폭을 줄일 수 있다. \n- private key + public key\n\n## Wallets\n- account != wallet\n- account와 인터렉션 할 수 있는 interface 이자 application\n\n## Querying Ether\n- [[notes/Etherscan]]에서 주소 검색하여 잔액을 확인할 수 있다. \n\n## DApp\n- decentralized application\n- decentralized network 상 위에 smart contract와 front end 인터페이스로 만들어진 어플리케이션. \n\t- smart contract는 접근 가능하며 투명하게 공개된다. \n- 장점\n\t- Zero downtime\n\t\t- 블록체인 네트워크 상에서 운영되기 때문에 \n\t- privacy\n\t- 검열이 따로 없음\n\t- 데이터 무결성\n\t\t- 블록체인에 데이터가 저장되기 때문에 불변이며 위조할 수 없다. \n\t- 검증 가능한 동작 \n\t\t- 별도 중앙 기관 없이 따로 신뢰할 것 없이 사용 가능하다. \n\t\t- 현실 세계에서는  은행 시스템 사용시 금융 기관을 믿고 사용하지만 DApp에서는 그럴 필요가 없다.\n- 단점\n\t- 운영이 어렵다.\n\t\t- 블록체인에 올라가고나면 수정이 어렵다. \n\t- 퍼포먼스 이슈 \n\t\t- 이더리움이 지향하는 보안, 무결성, 투명성, 신뢰성 수준 달성을 위해 모든 노드가 모든 트랜잭션을 실행 및 저장. 증명 합의에도 시간이 걸리게 된다. \n\t- 네트워크 정체\n\t\t- 하나의 DApp이 너무 많은 리소스를 사용하게 되면 전체 네트워크가 정체된다. 현재 네트워크는 초당 10~15개의 트랜잭션만 처리 가능하며, 이보다 더 많은 트랜잭션이 생기면 풀이 빠르게 증가 할 수 있다. \n\t- 사용성\n\t\t- 사용자 역시 블록체인의 보안 방식을 설정해야함으로 진입 장벽이 높을 수 있다.\n\t- 중앙 집중화 \n\t\t- 사용자 친화적으로 하려면 전통적인 중앙 집중화된 서비스로 만들게 되는데, 이렇게 되면 블록체인의 장점들을 더 이상 사용할 수 없게 된다. \n\n## Transaction\n- account의 암호화된 명령\n- 예를 들어, account =\u003e account ETH 전송\n- [EVM](#EVM) 상태를 변경하는 트랜잭션은 전체 네트워크로 브로드캐스트 되어야 한다.\n\t- **recipient** : 수신 주소 \n\t\t- EOA : 전송 받는 사람\n\t\t- Contact account : 이 트랜잭션은 contract code를 실행하는 트랜잭션임. \n\t- **signature** : 보낸 사람 식별자 \n\t\t- 보낸 사람의 private key가 트랜잭션에 싸인하고 보낸 사람이 이 트랜잭션을 승인 했다고 확인 할 때 생성됨. \n\t- **nonce** : 계정의 트랜잭션 번호. 순차적으로 증가하는 카운터\n\t- **value** : 전송하는 ETH 양 ([WEI](#wei))\n\t- **data** : 임의 데이터 (optional)\n\t- **gasLimit** : 트랜잭션에서 사용할 수 있는 최대 가스 단위의 양. 계산 단계에서 나오는 가스 양\n\t- **maxPriorityFeePerGas** : validator에게 보낼 최대 가스량\n\t- **maxFeePerGas** : 거래에 대해 지불할 수 있는 최대 가스량 ( baseFeePerGas 와 maxPriorityFeePerGas 포함)\n\n## Gas\n- 이더리움 네트워크에서 특정 작업을 실행하는데 필요한 계산 노력의 양을 측정하는 단위 \n- 거래를 실행하기 위해 계산 자원 필요 =\u003e 각 거래는 수수료가 필요.\n- 이 거래를 성공적으로 수행하기 위한 필요한 수수료 \n- `gasLimit` 와 `maxPriorityFeePerGas` 를 이용하여 validator에게 줄 최대 거래 수수료를 결정한다. \n\n### 거래 수수료 계산 방법 \n- 이더리움 네트워크 거래 수수료 계산 방식은 [[notes/London upgrade]] 이후로 변경됨.\n- 기존 동작 방식 (런던 업그레이드 전)\n\t- `gasLimit` : 21,000 unit, gas price : 200 gwei 인 경우 =\u003e Gas units * price = 21,000 * 200 = 4,2000,000 gwei (0.0042 ETH)\n- 이후 동작 방식 (런던 업그레이드 이후)\n\t- gasLimit` : 21,000 unit`, **base fee** 10 gwei, tip은 2 gwei \n\t  =\u003e 21,000 ( 10 + 2) = 252,000 gwei (0.000252ETH)\n\t- validator는 0.000042 ETH 팁을 받고, base fee인 0.00021 ETH는 burn 된다.\n\t- `maxFeePerGas` 설정할 수 있다.\n\t\t- refund = 최대 수수료 - ( base fee + priority fee )\n\t- 이를 통해 기본료 이상의 과도한 지불을 막는다.\n\n## Block\n- 트랜잭션을 담고 있다. \n- 즉, 트랜잭션은 기록이고 블록은 장부다. \n- hash는 블록 데이터에서 암호화되어 이 링크로 블록들을 연결 \n\t- 한번 연결된 hash는 모든 이용자가 알고 있기 때문에 쉽게 변조할 수 없다. \n\n### 왜 block이 필요한가\n- 이더리움 네트워크에 잇는 모든 참가자가 동기화 상태를 유지하고 트랜잭션의 정확한 기록을 동의\n- 밸리데이터(validator)들은 랜덤으로 트랜잭션을 블록에 담을 수 있는 권한을 받고 그 트랜잭션을 블록에 담아 또 다른 밸리데이터들에게 공유 \n\n### block 작동 방식 \n- 트랜잭션 기록 보존을 위해 블록은 반드시 정렬된다\n- 블록이 밸리데이터에 의해 합쳐지고 나면, 네트워크에 모두 전파된다.\n- 블록이 합쳐지고 나면 새로운 벨리데이터를 선택하고 다음 블록을 만든다.\n- 현재 이더리움은 proof-of-stake(POS) 프로토콜로 명시되어있다. \n\n### Proof-of-stake Protocol \n- 지분 증명 \n- 밸리데이터가 되기 위해서는 담보로 32ETH 지불해야한다. \n- 부정행위가 걸릴 경우, 이 담보에서 사라지게 됨으로 네트워크 보호용으로 사용된다.\n- 모든 [[notes/ethereum 2.0#슬롯 (slot)]]마다 [[notes/Block Proposer]]로 부터 밸리데이터가 무작위로 선택\n- 밸리데이터는 트랜잭션을 묶고, 실행, 새로운 상태(state)를 결정 후 다른 밸리데이터들에게 전달 \n\t- 다른 밸리데이터들 : 변경 사항들을 실행해보고, 유효하다고 판단하면 해당 블록을 자체 데이터베이스에 추가 \n- 동일 슬롯에 대해 두개의 충돌 블록이 있을 경우 [fork-choice algorithm](https://github.com/ethereum/annotated-spec/blob/master/phase0/fork-choice.md) 으로 가장 많이 연결된 ETH가 지원하는 블록 선택\n\n### What's in a block\n![](https://user-images.githubusercontent.com/2231510/205472611-01a88b46-e4f4-4d97-8907-1d2f095761b3.png)\n- `slot` : 이 블록이 속한 슬롯 \n- `proposer_index` : 블록 제안한 밸리데이터의 ID\n- `parent_root` : 이전 블록 해시\n- `state_root` : 상태 오브젝트의 루트 해시\n- `body`\n\t- `randao_reveal` : 다음 [[notes/Block Proposer]]을 위해 사용될 값 \n\t- `eth1_data` : 담보 컨트렉트 정보\n\t- `graffiti` : 블록 태그를 위한 임의 데이터\n\t- `proposer_slashings` :  잘라낼 밸리데이터 목록\n\t- `attester_slashings` : 잘라낼 밸리데이터 목록\n\t- `attestations` : 현재 블록을 지원하는 증명 목록\n\t- `deposits` : 담보 컨트랙트를 위한 새로운 담보 리스트 \n\t- `voluntary_exits` : 네트워크 내 밸리데이터 목록\n\t- `sync_aggregate` : light client에 전달하는 밸리데이터의 subset\n\t- `execution_payload` : 실행 client로 부터의 트랜잭션\n\n### Block Time\n- 블록을 분리하는 시간\n- 이더리움에서 시간은 슬롯([[notes/ethereum 2.0#슬롯 (slot)]] = 12초\n- 모든 밸리데이터가 온라인 상태고 완전히 동작한다고 가정했을 때, 모든 슬롯에 블록이 있다. -\u003e 즉, 블록 시간은 **12초** \n- 하지만, 밸리데이터가 오프라인일수도 있어서, 슬롯이 빌 수도 있음. \n\n### Block Size\n- 각 블록의 목표 사이즈는 1500만 가스.\n- 하지만 네트워크 수요에 따라 증가, 감소가 가능하여 최대 3000만 가스(목표의 2배)까지 늘어날 수 있다.\n- 블록 내 모든 트랜잭션에서 지출되는 가스피의 총량은 블록 가스 한도보다 작아야 한다.\n\t- 블록이 임의로 커져버리지 않게 하기위한 장치\n\t- 블록이 너무 커지면 전체 노드의 리소스와 속도 요구사항으로 인해 네트워크를 따라갈 수 없게 될 수 있음\n\n### Base fee\n- 모든 블록에는 base fee가 있어 예비 가격 역할을 함\n- 블록에 들어가려면 이 base fee 보다는 커야 함\n- 각각의 블록마다 독립적으로 계산됨. \n- 이전 블록에 의해 결정됨으로 사용자는 fee를 예측할 수 있음\n- 블록이 채굴될때마다 연소(burned)된다. \n\n### Priority fee (tips)\n- \n\n### Max fee\n\n\n\n## References\n- Ethereum official website : [https://ethereum.org/ko/what-is-ethereum/](https://ethereum.org/ko/what-is-ethereum/)\n- [Learn Ethereum Blockchain daily and Keep the Knowledge Awake :)](https://medium.com/coinsbench/learn-ethereum-blockchain-daily-and-keep-the-knowledge-awake-day-1-6d482ae67ac7)\n- [Account Abstraction \u0026 ERC 4337](https://medium.com/decipher-media/account-abstraction-erc-4337-2b8dff6b0a34)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Ethereum-Virtual-Machine":{"title":"Ethereum Virtual Machine","content":"\n\n## References\n- [The Ethereum Virtual Machine — How does it work?](https://medium.com/mycrypto/the-ethereum-virtual-machine-how-does-it-work-9abac2b7c9e)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Etherscan":{"title":"Etherscan","content":"\n- [Etherscan](https://etherscan.io/)\n- 웹 어플리케이션으로 address로 [[notes/Ethereum]]의 모든 트랜잭션과 블록을 추적할수 있는 툴\n\t- transaction\n\t- block\n\t- address \n- 읽는 방법 \n\t- [[notes/How NFT smart contract really work]]\n\n## Transaction Details\n- \n## Block \n- \n## Address\n\n","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/FastAPI-OpenAPI":{"title":"FastAPI OpenAPI custom setting","content":"\n## References\n- [Extending OpenAPI](https://fastapi.tiangolo.com/advanced/extending-openapi/)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/GitHub-Copilot-Chat":{"title":"GitHub Copoilot Chat","content":"GitHub은 역시 코드로 승부하나보다. VSCode Plugin으로 GitHub Copilot Chat이 베타로 오픈되었다. 업무하며 약 일주일 사용해보았고, 기존에 ChatGPT와 왔다갔다 하며 사용할때보다 훨씬 유용하고 정말 AI programming assistant 역할에 맞게 잘 수행하는 것 같다. \n\n## 기능 \n### 1. `/explain` \n- selected code 를 자연어로 설명. \n- 익숙하지 않은 코드를 빠르게 읽어야할 때, 각 함수나 변수가 어디서 어떻게 쓰이는지 정리. 새로운 코드나 오픈소스 읽을때 아주 요긴하게 사용 가능 . \n- ChatGPT에서는 내가 코드를 다 복붙해야지만 맥락을 읽어주지만, 제가 따로 복붙을 해주지 않은 코드까지 확인하고 내가 가진 코드에서 개념을 설명해줘서 따로 이리저리 코드 여행을 다니지 않을 수 있어 \u0008좋았다. \n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/2335b511-cab3-429e-b2f6-89efcfff4aca)\n- 한국어로도 가능\n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/4b32a475-73ed-47d4-b28b-c0232fd793fc)\n\n\n### 2. `/fix` \n- IDE에서 기본적으로 제공하는 fix는 pre defined 된 문장으로 내가 작업하고 있는 맥락과 맞지 않거나 이해하기 어려운 경우가 종종 있었음. \n- 코파일럿 챗에서는 내 코드의 맥락을 파악하여 설명해주어 더 이해하기 좋았다. \n- 코드에서 바로 대화가 가능하기도 하고. \n\n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/a29d38ac-c48d-4048-bdad-8a2ee1534678)\n- 코드 select 한 다음 `/fix`로 질문 할 수 도 있음\n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/c7f83c78-61b2-46da-92c8-6d997c861d99)\n\n### 3. `/simplify` \n- 복잡한 코드를 좀 더 간소화 버전으로 리팩토링 해주는 기능. \n- 일단 돌아가게 짠 다음, 리팩토링 혹은 코드를 간소화 하고자 할 때 이용하기 좋았음. \n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/54051bb1-9f71-4c05-af6c-ffb552656fa2)\n\n\n### 4. `/tests` \n- selected code의 유닛테스트 생성. 테스트 어떻게 짤까의 힌트를 얻을 수 있다. \n- 제대로된 예제를 못찾아서 그런지 모르겠지만 크게 잘 대답해주는 것인지 모르겠다. \n\n### 5. Question suggestion\n- 지금 chat의 맥락에서 더 고민해볼만한 질문들을 먼저 제안. \n- 대화에서 단발성 질문으로 끝나는 것이 아니라 더 깊이 언어적으로 기술적으로 함께 공부할 수 있어 좋았다. \n![twitter_Fw26Gh5aEAAQ9lM](https://github.com/jiyeonseo/digital-garden/assets/2231510/702e66a9-a9d7-40a8-9cca-8b307158d54c)\n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/1469c58b-aa41-4fea-ac72-5652821598ee)\n\n\n## Fun Facts \n- 좋은 코드만 짜려고 한다. 복잡한 코드 짜달라고 하니 거절한다. \n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/f8b492ac-dcf0-4fa0-aeed-edc356dba147)\n번외로 ChatGPT는 잘 짜준다. \n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/a4343d60-988a-4b91-a0ba-8b29e6720b56)\n \n- 코드 이외의 질문에는 대답을 안하는 편\n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/165d908e-1b23-4a10-8036-4e992f7616f7)\n\n- 물론 프롬프트를 어떻게 주느냐에 따라 다르다\n![](https://github.com/jiyeonseo/digital-garden/assets/2231510/d7a16a7f-411f-4f22-8e28-186e930ca84f)\n\n- Plugin prompt 분석한 repo\n\t-  https://github.com/saschaschramm/github-copilot\n\n## References\n- join wait list https://github.com/github-copilot/chat_waitlist_signup/join ","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Hardhat":{"title":"Hardhat","content":"- [hardhat](https://hardhat.org/)\n- ","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/How-NFT-smart-contract-really-work":{"title":"How NFT smart contract really work","content":"\n\u003e Ethereum NFT 기준\n\n## OpenSea \n\n- 예제 [Doodle #1815](https://opensea.io/assets/ethereum/0x8a90cab2b38dba80c64b7734e58ee1db38b8992e/1815)\n![](https://user-images.githubusercontent.com/2231510/204299525-29388efa-cc3f-4fed-bd2b-9acc83e8d2a5.png\")\n![](https://user-images.githubusercontent.com/2231510/204299525-29388efa-cc3f-4fed-bd2b-9acc83e8d2a5.png)\n\n- OpenSea 주소에서 `chain`, `contract address`, `token` 확인할 수 있다.\n- `https://opensea.io/assets/{chain}/{contract address}/{token id}`\n\n![](https://user-images.githubusercontent.com/2231510/204303462-86a6c32d-033c-4052-ac52-c559d0a2c944.png)\n- Details 에서도 동일하게 NFT에 대해 알 수 있다.\n- Contract Address 링크 : NFT Collection contract [[notes/Etherscan]] 페이지로 연결\n- Token ID 링크 : NFT Token의 metadata \n\n## Etherscan\n- [예제 Contract 0x8a90CAb2b38dba80c64b7734e58Ee1dB38B8992e](https://etherscan.io/address/0x8a90cab2b38dba80c64b7734e58ee1db38b8992e)\n\n### \"Contract\" tab\n- Code\n\t- Contract Source Code : solidity. contract code 내용\n\t- Contract ABI \n\t- Contract Creation Code\n\t\t- ByteCode\n\t\t- Opcodes\n- Read Contract : 해당 스마트 컨트렉트에 대해 READ 할수 있는 function들 \n\t- 예를 들어, `onwnerOf`  function에 `tokenId`를 넣으면 해당 `tokenId`의 NFT를 가진 owner query 가능\n\t  ![](https://user-images.githubusercontent.com/2231510/204311713-6f1ea517-9144-43bc-9add-3e39f0ce9386.png)\n\t- `tokenURI` : NFT metadata link \n\t  ![](https://user-images.githubusercontent.com/2231510/204314326-005287a8-b0f2-43d6-a94a-dd5b8c4bac92.png)\n\t  - [[notes/IPFS]] 주소\n\t  - `https://ipfs.io/ipfs/{뒤쪽 주소}` \n\t\t  - 앞부분은 바뀌지 않고 맨 뒤 token ID만 변경된다. \n\t  - [https://ipfs.io/ipfs/QmPMc4tcBsMqLRuCQtPmPe84bpSjrC3Ky7t3JWuHXYB4aS/13](https://ipfs.io/ipfs/QmPMc4tcBsMqLRuCQtPmPe84bpSjrC3Ky7t3JWuHXYB4aS/13)\n\t  - 이렇게 다른 곳에 저장되어있기 때문에 **owner**가 원하면 metada를 바꿀 수 있다.\n\t  - owner를 만약 resign(이 역시도 function) 한다면 owner가 없게 되고 해당 NFT는 영원히 바꿀 수 없게 된다. \n\t- `balanceOf` : owner 주소가 해당 contract NFT 를 몇개 가졌는지 \n\t  ![](https://user-images.githubusercontent.com/2231510/204318782-5f27a4cd-4f0d-42ff-92cc-04e2d2cdf3d7.png)\n\t- `totalSupply` : 이 contract의 최대 발행갯수 \n\t  ![](https://user-images.githubusercontent.com/2231510/204319392-9b9c2e31-1b97-43f7-8a67-ee509a4594a2.png)\n\t  \n- Write code \n\t- 지갑과 연결하여 code를 실행시킬 수 있다. \n\t- `setBaseURI` : Metadata URL 세팅하기 \n\t  ![](https://user-images.githubusercontent.com/2231510/204317487-52539b7e-2fe6-444f-b450-f93f8cd83604.png)\n\t  (내가 `owner`가 아니기 때문에 denied 됨)\n\t  ![](https://user-images.githubusercontent.com/2231510/204317791-d5d95e9d-1074-453d-b198-e8f78f78c8d6.png)\n\t  (코드 보면 `onlyOwner` contract owner 만 가능하게 되어있음 )\n\t  나중에 metadata가 호오오옥시나 바뀌게 되면 이 `setBaseURI`로 변경할 수 있음. \n\t  - `withdraw` : `onlyOwner`\n\t    해당 contract의 balance를 해당 function call 한 사람에게 transfer 한다. (누구든 부를 수 있긴 하지만 `onlyOwner`에서 막히니 owner만이 balance를 가져갈 수 있다.)\n\t    ![](https://user-images.githubusercontent.com/2231510/204320002-9f55dc99-5744-4f15-ac68-8cc8d5480336.png)\n\t    \n## NFT Staking\n- [예시 Wizards \u0026 Dragons Game (WnD)](https://opensea.io/collection/wizards-dragons-game-v2)\n- [Contract Etherscan](https://etherscan.io/address/0x999e88075692bcee3dbc07e7e64cd32f39a1d3ab#readContract)\n- `Contract` tab \u003e `Read Contract` \u003e `tower` 다른 contract 주소가 있음\n  ![](https://user-images.githubusercontent.com/2231510/204322362-d41719e9-015d-403f-91e0-8bc9986dfd42.png)\n  staking contract \n  ![](https://user-images.githubusercontent.com/2231510/204323453-a5c3738a-c8d6-45cd-a02b-40523d298f07.png)\n  `transferFrom` : [[notes/ERC-20]] standard function\n\t  - `tokenOwner` 로 부터 이 `address` 에게 NFT를 보내겠다. \n- unstaking\n  ![](https://user-images.githubusercontent.com/2231510/204324932-81b03754-0647-4039-9982-b511ff4bca45.png)\n  \"claim\", \"unstaking\" function을 보면 대부분 여기에 reward에 대한 코드가 있다. \n\n\n## References\n- [HOW NFT SMART CONTRACTS REALLY WORK - Can metadata be changed? How staking works?](https://www.youtube.com/watch?v=Wu436_IwWmo)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/IPFS":{"title":"IPFS","content":"- [ipfs.tech](https://ipfs.tech/)\n- InterPlanetary File System. \n- 분산형 파일 시스템.\n- P2P 방식. \n- NFT Metadata 저장하는 곳으로 많이 쓰임. \n\t- 다른 서비스로는  [[arweave.org]] 도 있음.","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/K6-Load-Test":{"title":"K6 부하 테스트","content":"\n공식 페이지 : https://k6.io/\n\nGrafana k6 is an open-source load testing tool that makes performance testing easy and productive for engineering teams. k6 is free, developer-centric, and extensible.\n\nUsing k6, you can test the reliability and performance of your systems and catch performance regressions and problems earlier. k6 will help you to build resilient and performant applications that scale.\n\nk6 is developed by Grafana Labs and the community.\n\n## Key Feature\n- k6 is packed with features, which you can learn all about in the documentation. Key features include:\n\n- CLI tool with developer-friendly APIs.\n- Scripting in JavaScript ES2015/ES6 - with support for local and remote modules\n- Checks and Thresholds - for goal-oriented, automation-friendly load testing\n\n## 사용처 \n\nk6 users are typically Developers, QA Engineers, SDETs, and SREs. They use k6 for testing the performance and reliability of APIs, microservices, and websites. Common k6 use cases are:\n\n### Load testing\nk6 is optimized for minimal resource consumption and designed for running high load tests (spike, stress, soak tests) .\n\n### Performance and synthetic monitoring\nWith k6, you could run tests with a small amount of load to continuously validate the performance and availability of your production environment.\n\n### Chaos and reliability testing\nk6 provides an extensible architecture. You can use k6 to simulate traffic as part of your chaos experiments or trigger them from your k6 tests.\n\n## 사용할 수 없는 경우 \n\nk6 is a high-performing load testing tool, scriptable in JavaScript. The architectural design to have these capabilities brings some trade-offs:\n\n### Does not run natively in a browser\nBy default, k6 does not render web pages the same way a browser does. Browsers can consume significant system resources. Skipping the browser allows running more load within a single machine.\n\nHowever, with xk6-browser, you can interact with real browsers and collect frontend metrics as part of your k6 tests.\n\n### Does not run in NodeJS\nJavaScript is not generally well suited for high performance. To achieve maximum performance, the tool itself is written in Go, embedding a JavaScript runtime allowing for easy test scripting.\n\nIf you want to import npm modules or libraries using NodeJS APIs, you can bundle npm modules with webpack and import them in your tests.\n\n## 설치 \nMac 에서는 아래와 같이 `brew`를 이용하여 설치 할 수 있다. \n```\nbrew install k6\n```\n이외 다른 OS는 [installation 페이지](https://k6.io/docs/getting-started/installation/ )를 참고하면 된다.\n\n## 테스트 스크립트 작성 방법\nhttps://k6.io/docs/getting-started/running-k6/ \n\n## 결과값 해석 \nhttps://k6.io/docs/getting-started/results-output/ \n\n## 200 OK 이외의 값 \nhttps://k6.io/docs/using-k6/checks/ \nabout this https://github.com/grafana/k6/issues/1828 \n\n## 결과 비쥬얼라이제이션 Grafana랑도 연결 가능 \nhttps://k6.io/docs/results-visualization/grafana-cloud/\n\n## Loki extension 과도 연결 가능 \nhttps://grafana.com/docs/loki/latest/clients/k6/ \n\n## Postman에서 K6로 넘어오기\nhttps://github.com/grafana/postman-to-k6 \nhttps://k6.io/blog/load-testing-your-api-with-swagger-openapi-and-k6/\n\n## 예제들\n- 환경(env) 에 따라 다른 domain 사용 방법 : https://github.com/quiiver/merino-explorations/blob/b32f61f11f2a31fa281111ddceecc76f13f89b60/load-tests/test.js\n- k6 제공하는 샘플 : https://github.com/grafana/k6/tree/master/samples/REST_API_testsuite\n- redirect 테스트 : https://github.com/grafana/k6/blob/master/samples/redirects.js \n \n## k6 learn \nhttps://github.com/grafana/k6-learn\n\n## awesome K6\nhttps://github.com/grafana/awesome-k6 \t","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/LaunchDarkly":{"title":"LaunchDarkly","content":"\n- [[notes/unleash]]와 거의 비슷하지만, enterprise만 제공하고 있다. \n-  stream 방식으로 polling 방식 unleash 보다 반영이 더 빠름\n-   unleash와 다르게 client쪽에서 변수를 좀 더 자유롭게 사용할 수 있음. (unleash는 미리 정의해두어야함)\n-   rollout 전략에서 비율 조절 뿐만 아니라 복합 속성으로 여러개 섞을 수 있음\n-   [available client side도 고를수 있음.](https://docs.launchdarkly.com/home/getting-started/feature-flags?site=launchDarkly#making-flags-available-to-client-side-and-mobile-sdks)\n-   [toggle scheduling도 가능](https://docs.launchdarkly.com/home/feature-workflows/scheduled-changes)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/Logstash":{"title":"Logstash","content":"\n## Configuration\n\n```yaml\ninput {\n  beats {\n    port =\u003e 5044\n  }\n}\n\nfilter{\n}\n\noutput {\n  s3 {\n    region =\u003e \"us-east-1\"\n    bucket =\u003e \"log-bucket\"\n    prefix =\u003e \"%{+YYYY}/%{+MM}/%{+dd}\"\n    codec =\u003e line { format =\u003e \"%{message}\"}\n  }\n}\n\n```\n\n## Input\n### filebeat\n\n### file\n\n\n## Filter\n\n## Output\n### S3\n- ``\n\n## References \n- [Using Logstash to Send Directly to an S3 Object Store](https://joshua-robinson.medium.com/using-logstash-to-send-directly-to-an-s3-object-store-34a4365a0960)","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/London-upgrade":{"title":"London Upgrade","content":"\n- 런던 [[notes/hard fork]]\n- 2021년 8월 5일 \n- 수수료 구조 개선 및 공급량 조절 등 \n\n## EIP-1559\n- 가스비를 줄이기 위한 새로운 수수료 구조 도입 (수수료 절감)\n- 런던 업그레이드의 핵심 내용\n- 문제점\n\t- 더 높은 수수료를 제시하는 거래가 더 빠르게 이루어지는 구조. 이로 인해 가스비 경쟁이 과열 =\u003e 일부 거래가 지나치게 높은 수수료를 지불하게 됨.\n\t- 사용자가 직접 계산 해야 함 =\u003e 과도하게 비싸게 지출할 수도 있음\n- 개선\n\t- 자동으로 계산된 기본 수수료로 지불 \n\n## EIP-3554\n- 이더리움 채굴 난이도 폭탄을 12월 1일로 연기\n- 난이도 폭탄 : 이더리움 플랫폼에 기본적 내장된 코드로, 채굴 난이도를 높이는 코드이다. \n\t- 난이도가 높아지면 자연스럽게 작업증명(PoW)의 수요가 줄어들며, 지분증명(PoS)의 수요가 높아진다.\n\t- 즉, 채굴 방식 변경을 위한 코드다. 작업증명(PoW) → 지분증명(PoS)\n\n## EIP-3198 \n- 기본료에 대응하는 연산부호 도입(Basefee opcode)\n\n## EIP-3529 \n- 가스비 환불 기능 제거 (블록 크기에 유연성을 두는 EIP-15999를 방해하는 기능을 없애자는 차원\n\n## EIP-3541 \n- 0xEF 바이트로 시작하는 새 콘트랙트 생성 거부\n- EIP(Ethereum Improvement Proposal) : 이더리움 개선 제안","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/NATS":{"title":"NATS","content":"- 분산 시스템에서 사용되는 메세징 및 이벤트 드리븐 아키텍쳐를 위한 오픈소스 메세징 시스템\n- 간단하고 확장성이 높은 메세징 시스템\n\n## JetStream\n- 대용량 데이터를 처리하고 분산형 데이터 시스템에서 데이터를 저장 및 검색 할 수 있도록 기능 확장\n\n## References\n- ","lastmodified":"2023-10-02T05:51:50.81545888Z","tags":null},"/notes/NFT":{"title":"NFT","content":"- Non-Fungible Token : 대체 불가능 토큰\n- 모두 동일한 가치를 가지는 화폐와 달리 **\"고유성\"**을 가진 토큰\n- 창작물에 대한 저작권이나 소유권\n- 게임 내 유니크한 아이템 등 재화에 대한 소유권\n- 예술품, 부동산, 골동품 등 등기가 필요한 자산에 대한 소유권\n- 회원권과 같은 자격에 대한 증명 \n\n\n## Marketplace\n- OpenSea\n\n## References\n- [NFT, 대체 불가능한 토큰](https://youtu.be/P40WjHh1Hzs)\n- ","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/NoSQL-Injection":{"title":"NoSQL Injection","content":"\n\n## References\n- https://www.imperva.com/learn/application-security/nosql-injection/","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/PDF%EB%A1%9C-%EC%98%A4%EB%94%94%EC%98%A4%EB%B6%81-%EB%A7%8C%EB%93%A4%EA%B8%B0":{"title":"Python으로 PDF 오디오북 만들기","content":"- `pyttsx3` : TTS(text-to-speech) 용 (version: `2.90`)\n- `PyPDF2` : PDF 파일을 다루기 위한 라이브러리 (version : `3.0.0`)\n\n## Code \n```python \nimport sys\nimport pyttsx3\nimport PyPDF2\n\n# python main.py ./test.pdf 인자로 읽을 파일 받기\nfile_path = sys.argv[1]\n\nif len(sys.argv) != 2:\n\tprint(\"Insufficient arguments\")\n\tsys.exit()\n\n# binary mode로 파일 읽기\npdf_file = open(file_path, 'rb')\n\n# PdfFileReader로 파일 읽을 Reader Object 생성\npdfReader = PyPDF2.PdfReader(pdf_file)\n\n# 읽은 총 페이지 수 \npages = len(pdfReader.pages)\n\n# pyttsx3.Engine 초기화 해주기\nspeaker = pyttsx3.init()\n\n# 페이지 돌며 text 읽어오기 \nfor num in range(pages):\n\t# 해당 페이지 읽기\n\tpage = pdfReader.pages[num] # pdfReader.getPage(num)\n\t# 해당 페이지 내 text 뽑아내기 \n\ttext = page.extract_text() \n\t# 뽑아낸 text 읽기 \n\tspeaker.say(text)\n\tspeaker.runAndWait() \n\n# mp3로 저장하려면 아래와 같이 하면 된다.\nspeaker.save_to_file(text, 'audio.mp3')\nspeaker.runAndWait()\n```\n\n## GitHub Code (with Poetry)\n- https://github.com/jiyeonseo/pdf-to-tts-mp3-python \n\n## References\n- [Make Audio Book from any PDF using Python | Python Project](https://morioh.com/p/42a6957afa8a?f=5c21fb01c16e2556b555ab32)\n- [How to save pyttsx3 results to MP3 or WAV file?](https://www.geeksforgeeks.org/how-to-save-pyttsx3-results-to-mp3-or-wav-file/)\n- [Change pyttsx3 language](https://stackoverflow.com/questions/65977155/change-pyttsx3-language)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Poetry":{"title":"Poetry","content":"\n- [Python poetry](https://python-poetry.org/)\n\nPython의 기본 패키지 매니저인 pip의 불편한점 \n- 기본적으로 global 설치 : `virtualenv`와 같은 가상 환경을 따로 작업해주어야 한다. \n- lock 파일이 없어 협업시 의존성 버전 불일치가 일어날 수 있음. \n\n## 장점\n### `poetry.lock` \n\n### virtualenv \n- 추가 작업없이 virtualenv를 사용할 수 있다. \n\n## 설치 방법 \n### Linux, MacOS, Windows(WSL)\n```\ncurl -sSL https://install.python-poetry.org | python3 -\n```\n\n### windows (powershell)\n```\n(Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -\n```\n\n## 새 프로젝트 시작하기 \n```\npoetry new new-poetry-repository\ncd new-poetry-repository\n```\n들어가보면 다음과 같은 프로젝트 구조로 되어있다. ([[notes/Tree 명령어]] 를 사용)\n```\nnew-poetry-repository/\n├── README.md\n├── new_poetry_repository\n│   └── __init__.py\n├── pyproject.toml\n└── tests\n    └── __init__.py\n```\n\n만약, 패키지 이름을 바꾸려면 아래와 같이 `name`을 따로 줄 수도 있다.\n```\npoetry new new-poetry-repository --name cheese-poetry\n```\n\n```\nnew-poetry-repository\n├── README.md\n├── cheese_poetry\n│   └── __init__.py\n├── pyproject.toml\n└── tests\n    └── __init__.py\n```\n\n## 이미 있는 프로젝트 내에 세팅하기\n\n```sh\npoetry init\n```\n- `pyproject.toml` 파일이 생성되며 안에 의존성이 추가된다. \n\n## 의존성 추가 \n```sh\npoetry add {package}\npoetry add aioredis\n```\n\n## `pyproject.toml`\n\n```toml\n[tool.poetry]\nname = \"cheese-poetry\"\nversion = \"0.1.0\"\ndescription = \"\"\nauthors = [\"cheese \u003cseojeee@gmail.com\u003e\"]\nreadme = \"README.md\"\npackages = [{include = \"cheese_poetry\"}]\n\n[tool.poetry.dependencies]\npython = \"^3.10\"\n\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n```\n\n### `poetry check`\n - `pyproject.toml` 파일 validation\n\n### `poetry install`\n - `pyproject.toml` 의 의존성 로컬에 설치하기 \n```sh\npoetry install --no-dev # dev-dependencies 빼고 \n```\n### `poetry update`\n- 의존성 모두 업데이트 하기 \n- `poetry.lock`을 삭제하고 새로 `poetry install` 하는 것과 동일한 동작\n\n## poetry.lock\n- 설치된 패키지의 정확한 버전을 명시하여 어떠한 특정 버전이 이 프로젝트에서 사용되고 있는지 lock \n- 여러 사람과 협업시 동일한 버전의 의존성을 가질 수 있게 됨\n- 만약 `poetry.lock` 이 없다면 `pyproject.toml` 에 명시된 내용에서 가장 최신 버전을 받게 된다.\n\n## Virtual Environment\n```sh\n# 설정 가능한 python 환경들 확인하기 \npoetry env list\n\n# venv로 사용할 python 환경\npoetry env use python3\n\n# venv 사용하여 python 사용하기 \npoetry run python ./main.py\n```\n지금 사용중인 virtual env 위치 확인하기 \n```sh\npoetry show -v\n```\n\n\n## References\n- [파이썬 의존성 관리자 Poetry 사용기](https://spoqa.github.io/2019/08/09/brand-new-python-dependency-manager-poetry.html)\n- [Dependency management with Python Poetry](https://realpython.com/dependency-management-python-poetry/)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/PostgreSQL":{"title":"PostgreSQL","content":"\n## Vacuum\n- DB 디스크 조각 모음\n- 데이터가 `update`/`delete` \n- \n### vacuum 시간 확인하기\n```sql\nSELECT relname, last_vacuum, last_autovacuum FROM pg_stat_user_tables;\n```\n\n## pg_user\n### select all user\n```sql\nSELECT \n\tusename AS role_name, \n\tCASE \n\t\tWHEN usesuper AND usecreatedb \n\t\t\tTHEN CAST('superuser, create database' AS pg_catalog.text) \n\t\tWHEN usesuper \n\t\t\tTHEN CAST('superuser' AS pg_catalog.text) \n\t\tWHEN usecreatedb \n\t\t\tTHEN CAST('create database' AS pg_catalog.text) \n\t\tELSE \n\t\t\tCAST('' AS pg_catalog.text) \n\tEND role_attributes \t\nFROM pg_catalog.pg_user \nORDER BY role_name desc;\n```\n\n### create user\n```sql\nCREATE USER \u003cname\u003e;\nCREATE USER \u003cname\u003e WITH PASSWORD '\u003cpassword\u003e';\nALTER USER \u003cname\u003e WITH PASSWORD '\u003cpassword\u003e';\n```\n\n\n### grant privileges\n```sql\nGRANT ALL PRIVILEGES ON DATABASE \u003cdatabase\u003e TO \u003cname\u003e;\nSELECT * from information_schema.table_privileges WHERE grantee = '\u003cname\u003e' LIMIT 5;\n```\n\n## References\n- [PostgreSQL: 베큠(VACUUM)을 실행해야되는 이유 그리고 성능 향상](https://blog.gaerae.com/2015/09/postgresql-vacuum-fsm.html)\n- https://tableplus.com/blog/2018/04/postgresql-how-to-grant-access-to-users.html","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Rate-Limiter":{"title":"처리율 제한 장치 Rate Limitter","content":"\n## 필요한 이유\n- 일정 시간 당 요청수를 제한함.\n\t- e.g. RPS (Request Per Second)\n- 서비스에 한 번에 엄청난 수의 요청을 받게 된 경우 서버를 안정적으로 운영하기 위해 특정 요청에 대해서만 허용하는 방법. 요청의 임계치를 정하여 그 값을 초과하게 되면 처리하지 않는다. \n- 특히, DDOS와 같이 불필요한 요청을 하여 시스템을 공격을 방어하기 위해 사용.\n- 수용 가능한 요청에 대해 처리하며, 이로 인해 서버 리소스 비용을 조절할 수 있게 됨으로써 비용 절감의 효과도 얻을 수 있다.\n\n아래와 같이 실제 서비스에 닿기 전 유효한 요청인지 받을 수 있을지에 대해 Rate Limiter가 판단 후  실제 서비스로 요청이 갈 수 있도록 한다. \n\n![](https://miro.medium.com/max/720/1*maqXnVMCWj_Z28qfmB_ZgQ.webp)\n( ref : https://towardsdatascience.com/designing-a-rate-limiter-6351bd8762c6 )\n\n너무 많은 요청이 와서 이를 막을 경우 [HTTP status 429 Too Many Requests](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429)를 반환한다. 이러한 중간 역할을 하는 장치를 주로 API Gateway라고 부르는데, 처리율 제한 뿐만 아니라 SSL 종단(termination), 인증(Autherntication), IP 차단/허용(deny/allow list) 등을 지원하는데, 클라우드 프로바이더들이 제공하는 managed를 사용할수도 있고, 직접 만들어 사용할 수도 있다. \n\n## 처리율 제한 알고리즘\n### 토큰 버킷 알고리즘 \n\n### 누출 버킷 \n\n### 고정 윈도 카운터\n\n### 이동 윈도 로그\n\n### 이동 윈도 카운터\n\n## 처리율 제한 규칙\n\n### 1) 시간당 처리율 \n- RPS, PRM 등 시간 내 요청 수 제한\n\n\n### 2) Compute Unit \n- API endpoint 마다 정보를 쿼리하는데 필요한 계산에 따라, 각 API 요청에 대한 가중치를 부여하는 방법. 이 단위를 Compute Unit 줄여 CU라고 부른다. \n- CUPS (Compute Unit Per Second) \n\n## Response\n- API 요청 입장에서도 얼마나 나의 limit이 남았는지, 그리고 초과되었다면 언제 부터 다시 요청이 가능한지 알수 있으면 더 효율적으로 API 요청을 할 수 있다. \n- `x-ratelimit-limit` : 윈도우 마다의 제한 수 \n- `x-ratelimit-remaining` : 현재 윈도우 내 남은 요청 제한 수 \n- `x-ratelimit-retry-after` : 요청 제한이 넘어간 경우, 얼마 뒤(대부분 \"초\") 다시 요청을 보내야하는 지\n\n## References\n- [Designing a rate limiter](https://towardsdatascience.com/designing-a-rate-limiter-6351bd8762c6)\n- [가상 면접 사례로 배우는 대규모 시스템 설계 기초](http://www.yes24.com/Product/Goods/102819435)\n- [Examples of HTTP Rate Limiting Response headers](https://stackoverflow.com/questions/16022624/examples-of-http-api-rate-limiting-http-response-headers)\n- [What is a compute unit(CU)?](https://moralis.io/faq/what-is-a-compute-unit-cu/)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Redash":{"title":"Redash","content":"\n## 지원 데이터 소스 \n- Amazon 계열 : Athena, CloudWatch, DynamoDB, Redshift\n- Google 계열 : Analytics, BigQuery, Spreadsheets\n- Microsoft Azure 계열 : Data Warehouse / Synapse, SQL Database, SQL Server\n- Cassandra\n- Clickhouse\n- CockroachDB\n- CSV (self-hosted에서는 지원하지 않음)\n- MongoDB\n- PostgresQL\n- [Supported Data Sources](https://redash.io/help/data-sources/querying/supported-data-sources)\n\n## Queries\n- \n\n## Dashboards\n- \n\n## Alerts\n\n\n## References\n- [Creating and Editing Queries](https://redash.io/help/user-guide/querying/writing-queries)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Redis-Cluster-cannot-be-connected.-Please-provide-at-least-one-reachable-node":{"title":"[redis-py Cluster] Redis Cluster cannot be connected. Please provide at least one reachable node","content":"\n[[notes/memorydb]] 를 node 2개(master + replica)로, client는 [redis-py](https://github.com/redis/redis-py) cluster로 연결하고 사용하고 있었다. Memory DB는 Redis Cluster로 구성되어있기 때문에 하나의 node가 내려가더라도 대기중인 replica가 올라가기 때문에 내구성이 뛰어나고, 모든 노드에 똑같이 복사가 되기 때문에 데이터의 유실도 없다.  \n\nredis-py 는 아래와 같이 client 설정을 해주었다. \n```py\nfrom redis.asyncio.cluster import RedisCluster as AsyncRedisCluster\n\n...\n\nREDIS_CONNECTION_PARAMS = {\n\t\"password\": app_settings.redis_password,\n\t\"username\": app_settings.redis_user,\n\t\"host\": app_settings.redis_endpoint,\n\t\"port\": app_settings.redis_port,\n\t\"encoding\": \"utf-8\",\n\t\"ssl\": True,\n\t\"decode_responses\": True,\n\t\"require_full_coverage\": False,\n}\n\nself._redis_cluster = AsyncRedisCluster(**REDIS_CONNECTION_PARAMS)\n...\n```\n\n그러던 어느날, Client쪽에서 다음과 같은 에러가 떨어졌다. \n```\nRedis Cluster cannot be connected. Please provide at least one reachable node: None\n```\n즉, 붙을 수 있는 node가 없다는 에러다. 확인한 결과 분명 Momory DB는 떠 있는 상태였다. 다만 이벤트를 확인해 보았을 때, 어떠한 이유로 master node가 내려간 것으로 보인다. \n\n![unnamed__3_](https://user-images.githubusercontent.com/2231510/218296467-ab03ff37-b8c3-4108-a684-27c882de628e.png)\n- master node 였건 `*-0001-002` 가 어떠한 이유로 Failover되어 replica node 였던 `*-0001-001` 가 master로 승격되었고,\n- 바로 이어서 다시 `*-0001-001`에 Failover 되며 다시 `*-0001-002`  가 master로 승격되었다. \n\n이후, 위 에러가 발생하였다. 분명 node가 내려가더라도 서비스 장애 없이 잘 되어야 할 것 같은데 node를 찾지 못했다. \n\n## MemoryDB Failover 테스트하기 \n\n우선 현상을 재현해보기 위해 Memory DB의 master node를 일부러 내리는 테스트를 해보았다. 두가지 방법으로 master node를 내려볼 수 있다. \n\n### 1) AWS Console\n![](https://user-images.githubusercontent.com/2231510/218296636-63f167a0-a7d6-4024-b4b4-ae147f0407d7.png)\n- AWS MomoryDB Console -\u003e 테스트할 클러스터 선택 \u003e 상단 \"프라이머리 장애 조치\"  \n- 제대로 실행 되면 왼쪽 \"Events\" 탭에 장애 조치 시작인 \"FailoverSharedAPI Called\" 와 완료 \"Recovery completed\" 되는 이벤트들을 확인 할 수 있다. \n\n### 2) AWS CLI\n```\n# Linux, macOS, Unix\naws memorydb failover-shard \\  \n   --cluster-name my-cluster \\  \n   --shard-name 0001\n\n# Windows\naws memorydb failover-shard ^  \n   --cluster-name my-cluster ^  \n   --shard-name 0001\n```\n위와 같이 요청하면, 다음과 같은 응답값이 온다. \n```\n\n{  \n     \"Events\": [  \n        {  \n             \"SourceName\": \"my-cluster\",  \n             \"SourceType\": \"cluster\",  \n             \"Message\": \"Failover to replica node my-cluster-0001-002 completed\",  \n             \"Date\": \"2021-08-22T12:39:37.568000-07:00\"  \n         },  \n         {  \n             \"SourceName\": \"my-cluster\",  \n             \"SourceType\": \"cluster\",  \n             \"Message\": \"Starting failover for shard 0001\",  \n             \"Date\": \"2021-08-22T12:39:10.173000-07:00\"  \n         }  \n    ]  \n }\n```\n\n### 유의 사항 \n- 클러스터당 24시간에 최대 5번 사용 가능\n- 다른 클러스터의 샤드에서 작업을 동시에 호출 할 수 있다. \n- 연속 호출되는 경우 첫 번째 노드 교체가 완료되어야 그 다음 요청 호출 가능하다. \n- 이 기능은 어플리케이션 동작을 테스트 하기 위한 것이며 운영을 위한 기능이 아니다. 따라서 대규모 운영 환경에서는 AWS 자체적으로 해당 요청을 차단 할 수도 있다. \n\n## redis-py 확인하기\n\n위 테스트를 몇번 해 본 결과, 첫번째 장애 이후에는 문제없이 잘 동작한다. 하지만 두번째 장애가 난 후에는 계속하여 노드를 찾지 못한다. \n\n### 1)  `reinitialize_steps` 설정 \nRedis Client 설정값 중 `reinitialize_steps` 라는 녀석이 있다.  ([redis-py/redis/cluster.py](https://github.com/redis/redis-py/blob/428d60940f386d3680a413aa327889308f82c5de/redis/cluster.py#L506-L515))\n\n\u003e reinitialize_steps (int, default: 5) –\n\u003e Specifies the number of MOVED errors that need to occur before reinitializing the whole cluster topology. If a MOVED error occurs and the cluster does not need to be reinitialized on this current error handling, only the MOVED slot will be patched with the redirected node. To reinitialize the cluster on every MOVED error, set reinitialize_steps to 1. To avoid reinitializing the cluster on moved errors, set reinitialize_steps to 0.\n\n즉, `MOVED error`가 난 slot에 대해서 redirected node로 패치를 해준다는 것인데. \n`MOVEDError`([redis-py/redis/exceptions.py](https://github.com/redis/redis-py/blob/master/redis/exceptions.py#L173-L180))란 cluster에서 해당 키가 없는 노드에다가 요청하면 Cluster 에서 올바른 노드를 알려주는 Error다. \n```py \nclass MovedError(AskError):\n    \"\"\"\n    Error indicated MOVED error received from cluster.\n    A request sent to a node that doesn't serve this key will be replayed with\n    a MOVED error that points to the correct node.\n    \"\"\"\n\n    pass\n```\n\nRedis client를 통해 command를 실행하였을 때 MOVED error가 발생하게 되면 내부에서 `_should_reinitialized` 함수가 불리우게 된다. ([redis-py//redis/cluster.py](https://github.com/redis/redis-py/blob/master/redis/cluster.py#L1134-L1147)) \n```py\n...\n\texcept MovedError as e:\n\t\t# First, we will try to patch the slots/nodes cache with the\n\t\t# redirected node output and try again. If MovedError exceeds\n\t\t# 'reinitialize_steps' number of times, we will force\n\t\t# reinitializing the tables, and then try again.\n\t\t# 'reinitialize_steps' counter will increase faster when\n\t\t# the same client object is shared between multiple threads. To\n\t\t# reduce the frequency you can set this variable in the\n\t\t# RedisCluster constructor.\n\t\tself.reinitialize_counter += 1\n\t\tif self._should_reinitialized():\n\t\t\tself.nodes_manager.initialize()\n\t\t\t# Reset the counter\n\t\t\tself.reinitialize_counter = 0\n\t\telse:\n\t\t\tself.nodes_manager.update_moved_exception(e)\n\n\t\tmoved = True\n...\n```\n\n이 함수 내에서 Redis Client 설정시 넘겨주었던 `reinitialized_steps` 가 사용된다. \n```py\ndef _should_reinitialized(self):\n\t# To reinitialize the cluster on every MOVED error,\n\t# set reinitialize_steps to 1.\n\t# To avoid reinitializing the cluster on moved errors, set\n\t# reinitialize_steps to 0.\n\n\tif self.reinitialize_steps == 0:\n\t\treturn False\n\telse:\n\t\treturn self.reinitialize_counter % self.reinitialize_steps == 0\n```\n\u0008따라서, 넘겨준 n번의 MOVED error가 발생하였을 때, 그 때 reinitialize 해주는 로직이다. MOVED가 일어날 때 마다 reinitialize 해주려면 `1`로, 일어나지 않게 하려면 `0`으로 세팅하면 된다. (기본 값은 `5`이다)\n\n위 상황을 미뤄 보았을 때, 변경된 node를 알아채지 못하여 reachable node를 못찾은 건가 싶어 `1`로 설정하고 다시 테스트를 해보았다. 하지만 여전히 해결되지 못했다. \n\n### 2) `NodeManager` 이슈\n\n정확하게 저 에러 메세지가 일어나는 부분부터 다시 확인을 하였다. \n에러가 난 부분은 아래 코드이다. ([redis-py/redis/cluster.py](https://github.com/redis/redis-py/blob/master/redis/cluster.py#L1551-L1555))\n```py\nclass NodesManager:\n...\n\tdef initialize(self):\n\t...\n\tstartup_nodes_reachable = False\n\t\n\tfor startup_node in self.startup_nodes.values():\n\t\tstartup_nodes_reachable = True\n\t\n\t...\n\tif not startup_nodes_reachable:\n\t\traise RedisClusterException(\n\t\t\tf\"Redis Cluster cannot be connected. Please provide at least \"\n\t\t\tf\"one reachable node: {str(exception)}\"\n\t\t) from exception\n```\n\n`NodeManager` 에서 initialize 시에 reachable한 node가 없는 경우 생기는 이슈다. 여기서 `startup_nodes_reachable`는 `NodeManager` 생성시 넘어온 startup_nodes를 루프를 돌며 설정이 되는데 이때, 모든 node가 reachable 하지 못했던 것이였다. \n\n여기서 사용한 `self.startup_nodes`는 `RedisCluster` 처음 생성될 때 url 혹은 host, port 정보를 통해 Cluster에 등록된 node들을 한번에 가져와 등록을 해준다. ([redis-py/redis/cluster.py](https://github.com/redis/redis-py/blob/master/redis/cluster.py#L534-L554)) \n\n```py\nclass RedisCluster(AbstractRedisCluster, RedisClusterCommands):\n...\ndef __init__(\n\tself,\n\thost: Optional[str] = None,\n\tport: int = 6379,\n\tstartup_nodes: Optional[List[\"ClusterNode\"]] = None,\n\tcluster_error_retry_attempts: int = 3,\n\tretry: Optional[\"Retry\"] = None,\n\trequire_full_coverage: bool = False,\n\treinitialize_steps: int = 5,\n\tread_from_replicas: bool = False,\n\tdynamic_startup_nodes: bool = True,\n\turl: Optional[str] = None,\n\t**kwargs,\n\t):\n\t...\n\tif url is not None:\n\t\turl_options = parse_url(url)\n\t\t...\n\t\tkwargs.update(url_options)\n\t\thost = kwargs.get(\"host\")\n\t\tport = kwargs.get(\"port\", port)\n\t\tstartup_nodes.append(ClusterNode(host, port))\n\telif host is not None and port is not None:\n\t\tstartup_nodes.append(ClusterNode(host, port))\n\t...\n\tself.nodes_manager = NodesManager(\n\t\tstartup_nodes=startup_nodes, # 여기! \n\t\tfrom_url=from_url,\n\t\trequire_full_coverage=require_full_coverage,\n\t\tdynamic_startup_nodes=dynamic_startup_nodes,\n\t\t**kwargs,\n\t)\n```\n\n이 과정은 RedisClient가 처음 init 될때 생성한  `startup_nodes` 로 `__init__` 이후에는 변하지 않는다. 즉, 처음 RedisClient 객체가 생성할 때 가지고 온 node로 계속하여 initialize를 하는 것이다. `NodeManager`에서는 node의 IP addr를 보고 있기 때문에, node가 내려갔다 다시 뜨면서 IP가 변경되면서 `NodeManager`에서는 해당 node를 찾을 수 없다.\n\n내 상황의 경우 cluster에 유효한 node가 처음 뜰 때 `startup_node` 로 등록되었고 2번 failover를 하게되면 더 이상 이 Cluster Client가 알 수 있는 node를 모두 사용했기 때문에 더 이상 reachable node가 없는 것이였다.찾아보니 [이미 2022년 11월에 redis-py issue](https://github.com/redis/redis-py/issues/2472)로 올라와있는 상태였고, 2023년 2월 현재 아직 fix가 되지 않은 상태이다. 이상적인 방법은 Client가 reinitialize 될때, \n라이브러리를 업데이트를 기다리고 있을 수만은 없어 exception 발생시 다시 Client 자체를 새로 생성하여 `__init__`을 다시 하여 node를 찾을 수 있게 임시방편을 추가했다. ","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Redis-OM-Python":{"title":"Redis OM Python","content":"- [Object Mapper for Redis and Python](https://github.com/redis/redis-om-python)\n- high-level 추상화로 데이터 모델과 쿼리를 코드로 편하게 할수 있도록 도와주는 라이브러리\n- 인메모리 DB인 Redis에서도 기존 RDB 라이브러리(SQLAlchemy, Peewee, Django ORM 등)에서와 같이 **declarative model**로 데이터를 다룰 수 있게 해준다. \n- **Pydantic** 사용하여 데이터 유효성 검사 기능 역시 편리하게 사용할 수 있다. \n- Query문과 Secondary indexes  제공. \n- 동기, 비동기(asyncio) 모두 제공.\n- Python 뿐만 아니라 [.NET](https://github.com/redis/redis-om-dotnet), [Node.js](https://github.com/redis/redis-om-node), [Spring/Java](https://github.com/redis/redis-om-spring) 등 다양한 라이브러리를 제공하고 있다. \n\n## 설치하기 \n```sh\n# With pip\n$ pip install redis-om\n\n# Or, using Poetry\n$ poetry add redis-om\n```\n\n## Redis 연결\n```py\n# Model마다 redis connection을 연결하는 경우\nCustomer.Meta.database = get_redis_connection(url=\"redis://localhost:6379\",\n                          decode_responses=True))\n\n# 전체 같은 redis connection인 경우 \nredis = get_redis_connection()\nMigrator(redis).run()\n```\n\n## Base models 만들기\n- `HashModel` : Hash 형식으로 redis에 값을 저장.\n- `JsonModel` : Json object 형식으로 redis에 값을 저장.\n\n```py\nimport datetime\nfrom typing import Optional\nfrom pydantic import EmailStr\nfrom redis_om import HashModel\n\nclass Customer(HashModel):\n\tfirst_name: str\n\tlast_name: str\n\temail: EmailStr\n\tjoin_date: datetime.date\n\tage: int\n\tbio: Optional[str]\n\nandrew = Customer( # andrew라는 Customer 객체 생성\n\tfirst_name=\"Andrew\",\n\tlast_name=\"Brookins\",\n\temail=\"andrew.brookins@example.com\",\n\tjoin_date=datetime.date.today(),\n\tage=38,\n\tbio=\"Python developer, works at Redis, Inc.\"\n)\n\n# 모델은 unique PK를 자동으로 생성한다.\nprint(andrew.pk) # (Redis 통신 따로 필요 없음.)\n# \u003e '01FJM6PH661HCNNRC884H6K30C'\n\n# `save()` 호출로 Redis에 모델 저장 \nandrew.save()\n\n# pk로 Customer 에서 객체를 찾을 수도 있다.\nassert Customer.get(andrew.pk) == andrew\n```\n- 자동으로 생성되는  PK는 unique 하며 정렬 가능하다. (sortable)\n- 저장하게 되면 default는 다음과 같이 저장된다. \n\t- Key :  `:{package}:{class_name}:{pk}`\n\t- Value : pk, 정의된 field들\n![](https://user-images.githubusercontent.com/2231510/209757427-59aab035-d09c-4332-ae86-32375257108f.png)\n직접 원하는 내부 값으로 `pk`값 지정해 줄 수 있다. 이 경우,  따로 PK field가 생성되지 않는다.\n```py\nclass Customer(HashModel):\n\t#  `:{package}:{class_name}:{first_name}` 으로 키가 생성된다.\n\tfirst_name: str = Field(primary_key=True) \n\tlast_name: str\n\temail: EmailStr\n\tjoin_date: datetime.date\n\tage: int\n\tbio: Optional[str]\n\n...\nCustomer.get(f\"{first_name}\") # PK로 쿼리시 지정 PK로 찾을 수 있다. \n```\n![](https://user-images.githubusercontent.com/2231510/209892848-aecf280a-f42a-4c35-8fda-736b27aa5f01.png)\n\n### Globally unique primary keys\n- Redis OM은 자동으로 유니크 키값을 생성하며 이 값으로 객체를 저장하거나 검색시 사용할 수 있다. \n- 객체 생성시 바로 반환되며 Redis와의 통신은 따로 필요하지 않다. \n- 이렇게 할 수 있는 것은 [[notes/ULID]] 스펙을 따르고 있기 때문이다. \n\n### BaseModel `Meta` class\n기본적으로 `:{package}:{class_name}:{pk}` 의 키 구조를 갖고 있기 때문에, 나중에 리팩토링으로 인하여 파일의 위치가 변경되거나 class의 이름이 변하게 되면 데이터를 찾을때 찾기 어려울 수 있다. 이를 대비하여, 나에게 맞는 key 네이밍으로 생성할 수 있다.  Base Model의 기본 Meta class릴 보면 다음과 같은 모양으로 되어있으며 필요에 따라 세팅해주면 된다. \n```py\n@dataclasses.dataclass\nclass DefaultMeta:\n\tglobal_key_prefix: Optional[str] = None\n\tmodel_key_prefix: Optional[str] = None\n\tprimary_key_pattern: Optional[str] = None\n\tdatabase: Optional[redis.Redis] = None\n\tprimary_key: Optional[PrimaryKey] = None\n\tprimary_key_creator_cls: Optional[Type[PrimaryKeyCreator]] = None\n\tindex_name: Optional[str] = None\n\tembedded: Optional[bool] = False\n\tencoding: str = \"utf-8\"\n\nclass Customer(HashModel):\n\tfirst_name: str\n\tlast_name: str\n\t...\n\n\tClass Meta:\n\t\tglobal_key_prefix = \"cheese_project\"\n\t\tmodel_key_prefix = \"helloworld\" \n\t\tprimary_key_pattern = \"customer:{pk}\" \n```\n- `global_key_prefix` : 가장 앞 `{global_key}:` prefix (default : `None`) (ex. `cheeseproject:{package}:{pk}` )\n- `model_key_prefix` : `{package}` 쪽 (ex. `cheeseproject:helloworld:{pk}` )\n- `primary_key_pattern` : `{pk}` 쪽 (ex. `cheeseproject:helloworld:customer:{pk}`)\n\n## Data validation with Pydantic\n- 기존 레디스에서는 데이터 스키마를 강제하지 않고 있지만 Redis OM의 Pydantic model을 이용하면 다른 RDB에서와 같이 validation을 체크 할 수 있다. \n\n```py\ntry:\n\tCustomer(\n\t\tfirst_name=\"Andrew\",\n\t\tlast_name=\"Brookins\",\n\t\temail=\"Not an email address!\",\n\t\tjoin_date=datetime.date.today(),\n\t\tage=38,\n\t\tbio=\"Python developer, works at Redis, Inc.\"\n\t)\nexcept ValidationError as e:\n\tprint(e)\n\t\"\"\"\n\tpydantic.error_wrappers.ValidationError: 1 validation error for Customer\n\temail\n\tvalue is not a valid email address (type=value_error.email)\n\t\"\"\"\n```\n\n## Query expressions\n- ORM의 또다른 강력한 무기는 API를 이용한 쿼리이다. Redis OM 역시 [RediSearch](https://redis.com/modules/redis-search/) 를 이용하여 Redis에서도 DB처럼 쿼리 및 인덱싱을 할 수 있도록 해준다. \n- AWS memoryDB는 RediSearch가 설치가 안되어있어 아래 기능을 사용할 수 없다.  \n\t- AWS에서 사용하려면 Redis에서 직접 제공하고 있는 [Redis Enterprise Cloud](https://aws.amazon.com/marketplace/pp/prodview-mwscixe4ujhkq) 를 사용해야 한다.\n```py\nfrom redis_om import get_redis_connection\n\nclass Customer(HashModel):\n\tfirst_name: str\n\tlast_name: str = Field(index=True) # 인덱싱할 키를 정해주고 \n\temail: EmailStr\n\tjoin_date: datetime.date\n\tage: int = Field(index=True)\n\tbio: Optional[str]\n\n# last name이 \"Brookins\" 인 모든 customers\nCustomer.find(Customer.last_name == \"Brookins\").all()\n```\n\n### Embedded model\n- `HashModel`에서는 List, Set, Hash와 같은 다른 타입은 사용할 수 없다\n- `JsonModel` 에서는 가능하다. \n```py\nfrom redis_om import EmbeddedJsonModel, JsonModel, Field\n\nclass Address(EmbeddedJsonModel):\n\taddress_line_1: str\n\taddress_line_2: Optional[str]\n\tcity: str = Field(index=True)\n\tstate: str = Field(index=True)\n\tcountry: str\n\tpostal_code: str = Field(index=True)\n\nclass Customer(JsonModel):\n\tfirst_name: str = Field(index=True)\n\tlast_name: str = Field(index=True)\n\temail: str = Field(index=True)\n\tjoin_date: datetime.date\n\tage: int = Field(index=True)\n\tbio: Optional[str] = Field(index=True, full_text_search=True, default=\"\")\n\taddress: Address\n\n# \"San Antonio, TX\"에 사는 모든 customers 구하기 \nCustomer.find(Customer.address.city == \"San Antonio\",\n\t\t\t\tCustomer.address.state == \"TX\")\n```\n\n### 다른 Redis 명령어 사용하기 \n```py\nfrom redis_om import HashModel\n\nclass Demo(HashModel):\n    some_field: str\n\nredis_conn = Demo.db()\nredis_conn.sadd(\"myset\", \"a\", \"b\", \"c\", \"d\")\n\nprint(redis_conn.sismember(\"myset\", \"e\")) # False\nprint(redis_conn.sismember(\"myset\", \"b\")) # True\n```\n\n## Asynchronous 하게 사용하기\nRedis OM은 Asyncio도 모두 지원하고 있다. \n- `aredis` module에서 import 받아야 한다. \n```py\n# asynchronously\nfrom aredis_om import HashModel, NotFoundError  \nfrom aredis_om import get_redis_connection\n```\n- Query 방법\n```py\nfrom aredis_om import HashModel\n\nclass Customer(HashModel):\n\tfirst_name: str\n\t...\n\nawait Customer.all_pks()\n```\n\n## Redis Cluster에서 사용하기 \n\nAWS MemoryDB 와 같은 상용 서비스를 사용할 경우, 혹은 가용성을 위하여 Redis cluster 구성하여 사용하는 경우는 아래와 같이 Redis Client를 직접 주입해주면 된다. \n\n```py\nfrom redis.asyncio.cluster import RedisCluster as AsyncRedisCluster\n\n\nREDIS_DATA_URL = f\"rediss://{app_settings.redis_user}:{app_settings.redis_password}@{app_settings.redis_endpoint}:{app_settings.redis_port}\"\nself._redis_cluster = AsyncRedisCluster.from_url(REDIS_DATA_URL,\n\t\t\t\t\t\t\t\t\t\t\t\tdecode_responses=True,\n\t\t\t\t\t\t\t\t\t\t\t\trequire_full_coverage=False)\n\nCustomer.Meta.database = self._redis_cluster\n```\n\n## References\n- [Introducing Redis OM for python](https://redis.com/blog/introducing-redis-om-for-python/)\n- [Introducing the Redis OM Client Libraries](https://redis.com/blog/introducing-redis-om-client-libraries/)\n- [Redis OM Python](https://redis.io/docs/stack/get-started/tutorials/stack-python/)\n- [FastAPI Integration](https://github.com/redis/redis-om-python/blob/main/docs/fastapi_integration.md) - asynchronous example code\n- [Flask Integration](https://github.com/redis-developer/redis-om-python-flask-skeleton-app) - synchronous example code","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Redis-troubleshooting":{"title":"Redis 트러블슈팅","content":"\n## \"WRONGTYPE Operation against a key holding the wrong kind of value\"\n- Redis는 [여러 데이터 타입](https://redis.io/docs/data-types/)을 제공한다. 각각에 맞는 명령어를 써 주어야 하는데 실제 키 값의 타입과 명령어가 맞지 않으면 이와 같은 에러가 난다. \n- 실제 value의 타입과 명령어가 일치하는지 확인 필요\n\t- value 타입 확인 명령어 : `type \u003ckey\u003e`\n\n### 타입별 값 가져오는 명령어 \n- type `string` -\u003e `GET \u003ckey\u003e`, `MGET \u003ckey\u003e`\n\t- [INCR](https://redis.io/commands/incr/) 은 string 값도 integer로 파싱하여 +1 해준다. \n- type `hash` -\u003e `HGET \u003ckey\u003e` , `HMGET \u003ckey\u003e`\n- type `list` -\u003e `Irange \u003ckey\u003e \u003cstart\u003e \u003cend\u003e`\n- type `sets` -\u003e `smembers \u003ckey\u003e`\n- type `sorted sets` -\u003e `ZRANGEBYSCORE \u003ckey\u003e \u003cmin\u003e \u003cmax`\n\n### References\n- [WRONGTYPE Operation against a key holding the wrong kind of value php](https://stackoverflow.com/questions/37953019/wrongtype-operation-against-a-key-holding-the-wrong-kind-of-value-php)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Reverse-proxy-server-with-FastAPI":{"title":"FastAPI로 reverse proxy server 만들기","content":"[[notes/Rate Limiter]] 와 같이 중간에 Auth, Rate Limit, IP Ban 등 기능을 하는 중간 Gateway 서버로 사용시 아래와 같이 만들 수 있다.\n\n```python\nimport httpx\nfrom fastapi import FastAPI, Request\n\nfrom starlette.requests import Request\nfrom starlette.responses import StreamingResponse\nfrom starlette.background import BackgroundTask\n\napp = FastAPI(docs_url=None, redoc_url=None, openapi_url=None)\n\nproxy_base_host = \"localhost\"\nproxy_base_port = 8000\nclient = httpx.AsyncClient(base_url=f\"http://{proxy_base_host}:{proxy_base_port}\")\n\nasync def _reverse_proxy(request: Request):\n    url = httpx.URL(path=request.url.path,\n                    query=request.url.query.encode(\"utf-8\"))\n\t_headers = {\n\t\t**request.headers,\n\t\t\"host\" : proxy_base_host\n\t}\n    rp_req = client.build_request(request.method, url,\n                                  headers=_headers,\n                                  content=await request.body())  \n    rp_resp = await client.send(rp_req, stream=True) \n    return StreamingResponse(\n        rp_resp.aiter_raw(),\n        status_code=rp_resp.status_code,\n        headers=rp_resp.headers,\n        background=BackgroundTask(rp_resp.aclose),\n    )\n\napp.add_route(\"/{path:path}\",\n              _reverse_proxy, [\"GET\", \"POST\"])\n```\n\n## References\n- [Can fastapi proxy another site as a response to the request?](https://github.com/tiangolo/fastapi/issues/1788)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/SQL-Injection":{"title":"SQL Injection","content":"\n## References \n- https://owasp.org/www-community/attacks/SQL_Injection","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/TimescaleDB-Operational-Query":{"title":"TimescaleDB 운영 쿼리","content":"---\n## Timescale DB Version 확인\n```sql\nSELECT extversion FROM pg_extension where extname = 'timescaledb';\n```\n\n## Hypertable 만들기\n```sql\nSELECT create_hypertable('public.cheese_table_name', 'time');\n```\n\n## Hypertable interval 설정하기\n```sql\nSELECT set_chunk_time_interval('public.cheese_table_name', INTERVAL '24 hours');\nSELECT set_chunk_time_interval('public.cheese_table_name', INTERVAL '3 days');\n```\n- doc : [Change hypertable chunk intervals](https://docs.timescale.com/timescaledb/latest/how-to-guides/hypertables/change-chunk-intervals/#change-the-chunk-interval-length-on-an-existing-hypertable)\n\n## 테이블 사이즈 확인하기 \n```sql\nSELECT table_name, pg_size_pretty(pg_relation_size(quote_ident(table_name))) , pg_relation_size(quote_ident(table_name)) \nFROM information_schema.tables \nWHERE table_schema = 'public' \nORDER BY 3 \n```\n\n## Internal Table 까지 모두 사이즈 확인하기 (hypertable, compressed 모두 포함 )\n```sql\n\n\nSELECT table_schema, table_name, pg_size_pretty(pg_relation_size('\"'||table_schema||'\".\"'||table_name||'\"')) , pg_relation_size('\"'||table_schema||'\".\"'||table_name||'\"') \nFROM information_schema.tables \nORDER BY 4\n```\n\n## Compression 하기\n```sql\n\n-- 5일보다 오래된 chunk 찾기 \nSELECT show_chunks('cheese_table_name', older_than =\u003e INTERVAL '5 days');\n\n-- 특정 chunk compression 하기 \nSELECT compress_chunk( '\u003cchunk_name\u003e');\nSELECT compress_chunk('_timescaledb_internal._hyper_5_53187_chunk');\n\n-- compression 결과 확인 \nSELECT * FROM chunk_compression_stats('example');\n\n-- 기간 내 compression 안된게 있는 경우 수동 compression \nSELECT compress_chunk(i, if_not_compressed =\u003e true)\n    FROM show_chunks(\n        'example',\n        now()::timestamp - INTERVAL '1 week',\n        now()::timestamp - INTERVAL '3 weeks'\n    ) i;\n\n```\n\ndoc : [Manual compression](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/manually-compress-chunks/)\n\n## Decompression 하기\n```sql\nSELECT decompress_chunk('_timescaledb_internal.\u003cchunk_name\u003e');\n```\n\ndoc : [Decompression](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/decompress-chunks/)[](https://docs.timescale.com/timescaledb/latest/how-to-guides/compression/decompress-chunks/)\n\n## Compression된 Hypertable에 데이터 다시 넣기 (Backfill)\n```sql\n-- chunk 확인하기 \nSELECT show_chunks('public.cheese_table_name'); \n\n-- policy 먼저 확인하기 \nSELECT j.job_id\n    FROM timescaledb_information.jobs j\n    WHERE j.proc_name = 'policy_compression'\n        AND j.hypertable_name = 'public.cheese_table_name'; -- 1006\n\n-- policy 멈춰주기 \nSELECT alter_job(\u003cjob_id\u003e, scheduled =\u003e false);\nSELECT alter_job(1006, scheduled =\u003e false);\n\n-- chunk decompression 하기 \nSELECT decompress_chunk('_timescaledb_internal.\u003cchunk_name\u003e');\n\n-- policy 다시 활성화 시켜주기\nSELECT alter_job(\u003cjob_id\u003e, scheduled =\u003e true);\nSELECT alter_job(1006, scheduled =\u003e true);\n```\n\n## 등록된 모든 job 확인하기 \n- refresh continous aggregate policy\n- compression policy \n```sql\nSELECT * FROM timescaledb_information.jobs;\n```\n\n## Replication lag 체크하기 \n```sql\nSELECT \n  CASE \n    WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn() THEN 0\n    ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp()) \n  END AS log_delay;\n```\n\n## Job \n- retention, continuous aggregate 등 주기적으로 작업되는 policy들은 모두 job으로 등록되어있다. \n- doc : [Actions and automation](https://docs.timescale.com/api/latest/actions/)\n\n### 등록된 job 확인\n```sql\nSELECT *\nFROM timescaledb_information.jobs j\n```\n\n```markdown\n|job_id|application_name|schedule_interval|max_runtime|max_retries|retry_period|proc_schema|proc_name|owner|scheduled|config|next_start|hypertable_schema|hypertable_name|check_schema|check_name|\n\n|------|----------------|-----------------|-----------|-----------|------------|-----------|---------|-----|---------|------|----------|-----------------|---------------|------------|----------|\n\n|1|Telemetry Reporter [1]|24:00:00|00:01:40|-1|01:00:00|_timescaledb_internal|policy_telemetry|postgres|true||2022-12-18 08:02:08.220 +0900|||||\n\n|1001|Refresh Continuous Aggregate Policy [1001]|01:00:00|00:00:00|-1|01:00:00|_timescaledb_internal|policy_refresh_continuous_aggregate|nftbankci|true|{\"end_offset\": \"01:00:00\", \"start_offset\": \"3 days\", \"mat_hypertable_id\": 7}|2022-12-17 12:48:56.433 +0900|_timescaledb_internal|_materialized_hypertable_7|_timescaledb_internal|policy_refresh_continuous_aggregate_check|\n\n|1003|Compression Policy [1003]|35 days|00:00:00|-1|01:00:00|_timescaledb_internal|policy_compression|nftbankci|true|{\"hypertable_id\": 7, \"compress_after\": \"5 days\"}|2023-01-05 20:39:47.486 +0900|_timescaledb_internal|_materialized_hypertable_7|_timescaledb_internal|policy_compression_check|\n\n|1011|Retention Policy [1011]|1 day|00:05:00|-1|00:05:00|_timescaledb_internal|policy_retention|nftbankci|true|{\"drop_after\": \"90 days\", \"hypertable_id\": 20}|2022-12-17 16:55:15.014 +0900|_timescaledb_internal|_materialized_hypertable_20|_timescaledb_internal|policy_retention_check|\n\n```\n\n- `Refresh Continuous Aggregate Policy`\n\t- continuous aggregate 내가 지정한 테이블 이름으로 보이지 않는다. 내부적으로는 internal table로 되어있다. \n\t```sql\n\t   select * from _timescaledb_internal._materialized_hypertable_20\n\t```\n\t\n- `Compression Policy`\n\t- 일정 기간이 지난 데이터는 압축한다. \n\t- read만 가능 update, delete를 위해서는 uncompression을 따로 해주어야 한다.\n\t- doc : [Compression](https://docs.timescale.com/api/latest/compression/)\n- `Retention Policy`\n\t- 일정 기간이 지난 후에는 자동 삭제한다. \n\t- doc : [Data Retention](https://docs.timescale.com/api/latest/data-retention/)\n\n\n### job 삭제\n```sql\nSELECT delete_job(\u003cjob id\u003e);\nSELECT delete_job(1000);\n```","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Tree-%EB%AA%85%EB%A0%B9%EC%96%B4":{"title":"Tree 명령어","content":"- 폴더 구조를 시각적으로 보기 쉽도록 트리 형태로 보여주는 명령어\n\n## Install\n\n### MacOS (Homebrew)\n```\nbrew install tree\n```\n\n### Linux (RHEL / CentOS / Fedora / Rocky / Alma Linux)\n```\nyum install tree  \n## CentOS/RHEL 8.x and Fedora user try the dnf command ##  \ndnf install tree\n```\n\n### Linux (Debian / Mint / Ubuntu Linux)\n```\nsudo apt-get install tree\n```\n\n## How to use\n```\ntree .\n\n➜  new-poetry-repository tree\n.\n├── README.md\n├── new_poetry_repository\n│   └── __init__.py\n├── pyproject.toml\n└── tests\n    └── __init__.py\n\n```\n\n## References\n- [Linux see directory tree structure using tree command](https://www.cyberciti.biz/faq/linux-show-directory-structure-command-line/)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/ULID":{"title":"ULID","content":"- Universally Unique Lexicographically Sortable Identifiers\n- 128 bits 이며 UUID와 호환 가능\n- 매 밀리세컨드마다 1.21e+24 유니크값 생성 가능\n- 시간을 나타내는 앞 48bits와 임의값 80bits로 구성된 값. \n```\n 01AN4Z07BY      79KA1307SR9X4MV3\n\n|----------|    |----------------|\n Timestamp          Randomness\n   48bits             80bits\n```\n- Timestamp\n\t- timestamp에서 밀리세컨드 단위로 기록하여 생성 순서대로 정렬할 수 있다.\n\t- 10889년까지 만들수 있음. \n- 대소문자 구별하지 않음 \n- Crockford's Base32 인코딩 (I, L, O, U 제외) - UUID 보다 더 나은 성능 \n- [monotonicity](https://github.com/ulid/spec#monotonicity) 옵션을 사용하여 랜덤 숫자에 1씩 증가하여 충돌을 피할 수도 있다. \n\n## UUID의 한계점\n- [Universally Unique Identifier(UUID)](https://datatracker.ietf.org/doc/html/rfc4122.html)는 중앙 관리식이 아니면서도 유일성을 보장해주는 방식\n- 32개의 16진수로 표시되며 총 5개의 version이 있다. \n\t- v1/v2 : 고유한 MAC주소에 대한 접근 필요. 다양한 환경에 사용되기 어려움\n\t- v3/v5 : 고유한 시드가 필요하고 무작위 ID 생성으로 여러 데이터 구조에서 조각화가 될 수 있다. \n\t- v4 : 완전 랜덤으로 조각화 될 가능성이 있다. \n\n## References\n- [ulid spec](https://github.com/ulid/spec)\n- [UUID vs ULID](https://velog.io/@injoon2019/UUID-vs-ULID)\n- [How probable are collisions with ULID’s monotonic option?](https://zendesk.engineering/how-probable-are-collisions-with-ulids-monotonic-option-d604d3ed2de)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/Uncle-Block":{"title":"Uncle Block","content":"\n## References \nhttps://docs.alchemy.com/docs/what-are-uncle-blocks","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/arweave.org":{"title":"arweave.org","content":"\n- [www.arweave.org](https://www.arweave.org/)\n- ","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/atomic-swap":{"title":"Atomic swap","content":"\n- 중앙화된 거래소를 거치지않고 서로 다른 코인을 직접 교환하는 것\n- full name : atomic cross chain trading\n- 코인 스왑(coin swap) 혹은 에어스왑(airswap)이라고도 한다. ","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/backend-communication-design-patterns":{"title":"백엔드 통신 패턴","content":"\n# 백엔드 통신 패턴\n\n백엔드 컴포넌트 사이 통신(일명 server-to-server 통신) 방법에 따라 성능차이 혹은 fallback 에 대한 처리 시나리오 등 변경될 수 있다. \n\n## Pattern 1. 요청-응답 패턴 \n- 마치 클라이언트-백엔드처럼 핑퐁 동기 통신 \n\n![Untitled-2023-08-13-1619](https://github.com/jiyeonseo/digital-garden/assets/2231510/66bd6349-55c8-4549-bb7a-d6b589ff1ee7)\n\n- 요청하고 기다렸다가 응답이 오면 그 다음 수행 \n- 예) RESTful API : 특정 endpoint(URL)로 GET, POST, PUT, DELETE 와 같은 http 요청을 하여 필요한 데이터를 응답값으로 받아 처리 \n### 요청-응답 패턴 장점\n- 단순하고 구현이 용이하여 가장 많이 사용되는 패턴\n- 여러 상황에 대부분 다 적합한 편\n- 확장성 : 각 요청이 개별적이기 때문에 단순하게 여러 요청을 처리하기 쉬움 \n- 신뢰성 : 항상 요청은 응답을 보내야 함으로, 제대로 이루어 지지 않은 경우 이를 모니터링 하기 용이함. \n- 디버깅 용이성 : 응담에는 항상 상태 코드와 메세지가 내려가기 때문에 받는 쪽에서 에러 처리가 용이함. \n\n### 요청-응답 패턴 단점\n- latency 문제 : 요청에 대해 응답이 올 때 까지 기다리기 때문에, 요청이 너무 많이 몰리는 상황에서는 latency가 길어질 수 있음. \n- 장애 발생시 데이터 불일치 : 요청 처리한 후 응답 중간에 네트워크 이슈가 생기면 데이터 불일치가 생길 수 있음.\n- Broadcasting 비효율 : 동일 데이터를 여러 클라이언트에 전송시 효율이 떨어진다. \n\n\n## Pattern 2. publish-subscribe 패턴 (PubSub)\n- 컴포넌트 간의 비동기 통신을 위해 사용. \n- 함께 작동해야하지만 디팬던시를 분리시키고자 할때 적합\n\n![Untitled-2023-08-13-1619-9](https://github.com/jiyeonseo/digital-garden/assets/2231510/ca878a2c-20c2-40d3-9d41-99b90d075dfe)\n\n- publisher와 subscriber 중간에 메세지 큐(메세지 브로커)를 사용 \n- 메세지를 채널(혹은 토픽)로 그룹화 \n- publisher : 메세지를 만들어 보내는 쪽. 메세지를 만들어 채널/토픽에 던지기만함  \n- subscriber : 메세지를 소비하는 쪽 . 구독하고자 하는 채널/토픽에서 메세지가 올때마다 copy를 받음\n- 예 ) Apache Kafka, MQTT \n\n### publish-subscribe 패턴 장점\n- 비동기 통신 : latency 병목을 줄여 실시간 어플리케이션에 적합\n- 느슨한 결합(Loose Coupling) : 컴포넌트 사이가 묶여있지 않음 \n- 확장성 : subscriber 제한이 따로 없고, subscriber가 구독할 수 있는 publisher의 수가 정해져 있지 않음. 계속 확장 가능 \n- 언어와 프로토콜이 독립적 : 언어나 환경, 플랫폼에 종속적이지 않기 때문에 크로스 플랫폼 호환성이 뛰어남 \n- 로드 밸런싱 ; 여러 subscriber가 특정 이벤트를 구독하는 경우, subscriber 간에 이벤트를 균등하게 배분함으로써 로그 밸런싱 기능을 제공할 수 있다.\n\n### publish-subscribe 패턴 단점\n- 시스템 오버헤드 : 단순히 pub/sub 뿐만 아니라 메세지 브로커, 채널과 subscribe 등 관리 포인트들이 늘어난다.\n- 메세지 복사 : 구성 혹은 네트워크 상황에 따라 메세지가 중복 될 수 있다. 이를 해결하기 위해 중복 및 추가 처리 작업을 해야할 수도 있다.\n- 확장성이 더 문제일지도 : 많은 양의 메세지와 subscriber가 생기면 그 역시 관리 대상이 됨\n- 복잡한 에러 처리 : 메세지 전송 실패, subscribe 실패 등 이슈 상황에 대한 처리가 더 복잡 할 수 있음. \n### 좋은 사용 시나리오\n- 실시간 채팅이나 여러 플레이어를 위한 게임에서 지연 시간은 짧고 실시간으로 응답을 하는 기능\n- 이벤트 알림 시스템\n- 로깅 및 캐싱에 의존하는 분산 시스템에서 \n\n\n## Pattern 3. Short Polling 패턴\n-  pull-based 통신 방법으로 서버에 새로운 업데이트가 있는지 지속적으로 땡겨(polling)가는 \u001d식 \n- 예를 들어, 친구한테 \"나한테 메세지 왔어?\" \"아니\" (좀 있다가...) \"나한테 메세지 왔어?\" \"아니\" (좀 있다가...) \"나한테 메세지 왔어?\" \"ㅇㅇ 여기\"  \n- `요청-응답 패턴` 과 다른점은 데이터 사용 여부와 상관 없이 정기적으로 미리 정해놓은 시간에 계속 통신 \n\n### Short Polling 패턴 장점\n- 단순성 : 구현이 쉬우며 서버/클라이언트 간에 상태를 따로 신경쓸 필요가 없어, 복잡성을 최소화 해야하는 경우에 적합\n- 호환성 : 플랫폼과 환경에 종속성이 없어 크로스 플랫폼 가능\n- 주기적인 업데이트가 필요한 시나리오에 적합 : 대시보드, 날씨 앱, 리소스 모니터링 등 \n\n### Short Polling 패턴 단점\n- latency : 미리 정해진 간격이 있기 때문에 그 시간 만큼 지연 시간 발생. 실시간 통신이 불가능 \n- 비효율성 : 데이터 변화가 없음에도 계속 폴링하기에 비효율적이고 불필요한 네트워크 및 서버 오버헤드를 초래할 수 있음\n- 스케일링 : 너무 많은 클라이언트가 동시에 폴링하는 경우 서버의 리소스를 과다하게 사용할 수 있음. \n\n## Pattern 4. Long Polling 패턴\n- Short polling과 동일하게 polling 이지만 push-based 통신 방법으로, 연결을 계속 하고 있다가 서버에서 업데이트가 있는 경우 서버에서 보내주는 방식 \n- 예를 들어, 친구랑 전화를 연결하고 \"업뎃 있으면 알려줘\" (계속 전화 연결중) \"옛다 업뎃.\" \n- 클라이언트/서버간에 실시간 혹은 실시간에 가까운 업데이트 실행을 위해 사용\n\n### Long Polling 패턴 장점\n- 짧은 latency : 업데이트가 있는 경우 클라이언트에 즉시 전송되기 때문에 기존 polling 방식보다 지연 시간이 딻다.\n- 실시간 업데이트 : 이미 클라이언트/서버 연결이 된 상태이기 때문에 다음 폴링까지 기다리지 않고 바로 실시간 업데이트 가능 \n\n### Long Polling 패턴 단점\n- 리소스 소모 : polling 시간동안 클라이언트 수만큼 연결을 열어 두어야 한다. 그러므로 클라이언트/서버 모두 리소스 소모가 많다.\n- 여전히 존재하는 latency : short polling 보다는 짧지만 여전히 웹소켓과 같은 다른 실시간 통신보다는 latency가 존재\n- 확장 어려움 : 동시에 많은 클라이언트를 처리해야하는 서버 입장에서는 리소스가 많이 드는 부담. 클라이언트가 많아질수록 효율적 관리 어려움 \n\n### 좋은 사용 시나리오\n- 실시간 업데이트, 이벤트 중심 어플리케이션, 이벤트 알림 시스템 등 \n \n## Pattern 5. Push 패턴\n- 연결된 클라이언트에 실시간으로 업데이트를 전달.\n- 클라이언트가 물어보는 것이 아닌 서버가 클라이언트에게 응답을 push \n- 가장 널리 사용되는 프로토콜은 \"web Socket\"\n\n### Push 패턴 장점\n- 실시간 업데이트 : 서버가 업데이트를 바로 보내줌 \n- latency 감소 : 업데이트가 있을 때 클라이언트에 바로 주기 때문에 지연 시간이 감소 \n- 효율성 : 지나친 요청(폴링, 클라이언트 요청)이 필요하지 않기 때문에 네트워크 리소스를 효율적으로 사용 가능 \n\n### Push 패턴 단점\n- 확장성 : 클라이언트 수가 늘어나게 되면, 연결을 맺고 있어야 하는 서버 입장에서는 리소스 부담\n- 클라이언트 지원 : 모든 클라이언트 플랫폼이 push 기술을 지원하고 있지 않음으로 이로 인한 한계가 있을 수 있음 \n\n### 좋은 사용 시나리오\n- 채팅, 메세징 앱, 알림 시스템, IoT 데이터 스트리밍, 온라인 게임 등 \n\n## References\n- [Communication Design Patterns for Backend Development](https://www.freecodecamp.org/news/communication-design-patterns-for-backend-development/)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/bitcoin":{"title":"비트코인","content":"\n- 그래픽카드가 비싸진 이유는 비트코인때문이라는 말이 많지만, 이제 채굴 난이도가 높아서 ASIC 비트코인 채굴 전용 기계가 아니면 무용지물이다. ","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/build-your-own-redis-with-c-cpp-1":{"title":"(Build Your Own Redis with C/C++) 1. socket 통신, Protocol Parsing","content":"\u003e [Build Your Own Redis With C/C++](https://build-your-own.org/redis) 을 보고 정리한 글입니다. 더 자세한 나용은 원문을 참고하실 수 있습니다. 직접 실습한 코드는 [jiyeonseo/build-your-own-redis-with-c-cpp](https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp) 에서 찾아볼 수 있습니다.\n\n`chap 1`은 책에 대한 introduction으로 생략. \n\n## Socket 동작 방식 \n- Redis는 서버-클라이언트 TCP 연결을 통하여 요청/응답 수신\n\n### 서버 workflow 수도코드\n```c\nfd = socket() \nbind(fd, address)\nlisten(fd)\nwhile True:\n    conn_fd = accept(fd)\n    do_something_with(conn_fd)\n    close(conn_fd)\n```\n\n- `fd` : 리눅스 커널에서 TCP 연결, 디스크 파일, 수신 포트 등을 나타내는 integer\n- `bind()` : `socket()`을 통해 받은 `fd` 로 `address` 연결\n- `listen()` : 해당 `address` 연결을 받을 수 있게 \n- `accept()` : 수신 `fd`를 받아 연결 소켓을 반환. `conn_fd` \n- `read()` : TCP 연결에서 데이터를 수신 \n- `write()` : 데이터 전송\n- `close()` : `fd`가 참고하고 있는 리소스를 삭제하고 `fd` 숫자를 재활용\n\n### 클라이언트 workflow 수도코드\n```c\nfd = socket()\nconnect(fd, address)\ndo_something_with(fd)\nclose(fd)\n```\n- `connect()` : 소켓 `fd` 주소를 받아 `address`와 연결\n\n## Simple Server/Client \n\n### Server \n```cpp\n// 먼저 소켓 `fd` 생성\nint fd = socket(AF_INET, SOCK_STREAM, 0);\n```\n- `AF_INET` : IPv4 용. IPv6 혹은 dual-stack socket을 열 경우 `AF_INET6` 사용\n- `SOCK_STREAM` : TCP 통신을 위한 stream\n\n```cpp\n// 소켓 옵션 세팅\nint val = 1;\nsetsockopt(fd, SOL_SOCKET, SO_REUSEADDR, \u0026val, sizeof(val));\n```\n- `setsockopt()` : 소켓 옵션 세팅 \n\t- `SO_REUSEADDR` : 서버가 재시작될때 동일한 주소 바인딩 가능\n\t\t- 소켓이 bind() 함수를 호출하여 로컬 IP 주소와 포트 번호를 할당 받을 때, 이미 그 포트를 사용 중인 다른 소켓이 있더라도 해당 포트를 재사용할 수 있도록 한다. \n\t\t- 다시 시작시 동일 포트 번호로 사용함으로써 불필요한 대기 시간 없이 바로 다시 사용 가능.\n\t\t- 주의) 같은 포트 번호를 사용하는 두 개의 소켓이 동시에 바인드되어 있다면, 동일한 IP 주소와 포트 번호로 들어오는 패킷이 어느 소켓으로 전달될지 알 수 없게 된다.\n\n```cpp\n// bind와 listen으로 0.0.0.0:1234 바인딩 하기 \n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(0);    // wildcard address 0.0.0.0\n    int rv = bind(fd, (const sockaddr *)\u0026addr, sizeof(addr));\n    if (rv) {\n        die(\"bind()\");\n    }\n\n    // listen\n    rv = listen(fd, SOMAXCONN);\n    if (rv) {\n        die(\"listen()\");\n    }\n```\n\n```cpp\n// 각각의 커넥션에 대해 do_something 하기\nwhile (true) {\n        // accept\n        struct sockaddr_in client_addr = {};\n        socklen_t socklen = sizeof(client_addr);\n        int connfd = accept(fd, (struct sockaddr *)\u0026client_addr, \u0026socklen);\n        if (connfd \u003c 0) {\n            continue;   // error\n        }\n\n        do_something(connfd);\n        close(connfd);\n    }\n```\n\n위 `do_something` 은 아래와 같이 read/write를 한다. \n```cpp\nstatic void do_something(int connfd) {\n    char rbuf[64] = {};\n    ssize_t n = read(connfd, rbuf, sizeof(rbuf) - 1);\n    if (n \u003c 0) {\n        msg(\"read() error\");\n        return;\n    }\n    printf(\"client says: %s\\n\", rbuf); // 클라이언트로부터 온 메세지 출력\n\n    char wbuf[] = \"world\";\n    write(connfd, wbuf, strlen(wbuf)); // 응답으로 world를 보낸다 \n}\n```\n- `read`와 `write`가 byte 수를 반환. \n\n### Client \n```cpp\nint fd = socket(AF_INET, SOCK_STREAM, 0);\n    if (fd \u003c 0) {\n        die(\"socket()\");\n    }\n\n    struct sockaddr_in addr = {};\n    addr.sin_family = AF_INET;\n    addr.sin_port = ntohs(1234);\n    addr.sin_addr.s_addr = ntohl(INADDR_LOOPBACK);  // 127.0.0.1\n    int rv = connect(fd, (const struct sockaddr *)\u0026addr, sizeof(addr));\n    if (rv) {\n        die(\"connect\");\n    }\n\n    char msg[] = \"hello\";\n    write(fd, msg, strlen(msg)); // 연결되면 hello 라는 메세지를 보낸다. \n\n    char rbuf[64] = {};\n    ssize_t n = read(fd, rbuf, sizeof(rbuf) - 1);\n    if (n \u003c 0) {\n        die(\"read\");\n    }\n    printf(\"server says: %s\\n\", rbuf);\n    close(fd);\n```\n\n\u003e 코드 : https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp/tree/main/03\n\n\n## Protocol Parsing\n클라이언트와 주고 받을 프로토콜을 정의해보자. 먼저 요청 길이 선언부터.\n### Server\n```cpp\n    while (true) {\n        // accept\n        struct sockaddr_in client_addr = {};\n        socklen_t socklen = sizeof(client_addr);\n        int connfd = accept(fd, (struct sockaddr *)\u0026client_addr, \u0026socklen);\n        if (connfd \u003c 0) {\n            continue;   // error\n        }\n\n        // only serves one client connection at once\n        while (true) {\n            int32_t err = one_request(connfd);\n            if (err) {\n                break;\n            }\n        }\n        close(connfd);\n    }\n```\n- client와 연결 후, while 룹이 돌며 하나의 요청에 대해 파씽\u0026 응답. \n\n```cpp\n// 실제 request처리할 `one_request` 함수에서 사용할 헬퍼 함수 2개를 먼저 만들어 본다. \nstatic int32_t read_full(int fd, char *buf, size_t n) {\n\t// n byte가 될때까지 커널에서 읽기 \n\t// 데이터\n    while (n \u003e 0) {\n        ssize_t rv = read(fd, buf, n); \n        if (rv \u003c= 0) {\n            return -1;  // error, or unexpected EOF\n        }\n        assert((size_t)rv \u003c= n);\n        n -= (size_t)rv;\n        buf += rv;\n    }\n    return 0;\n}\n\nstatic int32_t write_all(int fd, const char *buf, size_t n) {\n    // 버퍼가 가득차면 부분적으로만 데이터를 성공적으로 쓸 수 있기 때문에 \n    // 우리가 필요한 것보다 적은 bytes를 반환하도록 해준다. \n    while (n \u003e 0) {\n        ssize_t rv = write(fd, buf, n);\n        if (rv \u003c= 0) {\n            return -1;  // error\n        }\n        assert((size_t)rv \u003c= n);\n        n -= (size_t)rv;\n        buf += rv;\n    }\n    return 0;\n}\n```\n위 `write`와 `read` 헬퍼 함수를 이용하여 다음과 같이 요청 처리 함수 `one_request` 를 작성할 수 있다. \n\n```cpp\nconst size_t k_max_msg = 4096;\n\nstatic int32_t one_request(int connfd) {\n    // 4 bytes header\n    char rbuf[4 + k_max_msg + 1];\n    errno = 0;\n    int32_t err = read_full(connfd, rbuf, 4);\n    if (err) {\n        if (errno == 0) {\n            msg(\"EOF\");\n        } else {\n            msg(\"read() error\");\n        }\n        return err;\n    }\n\n    uint32_t len = 0;\n    memcpy(\u0026len, rbuf, 4);  // assume little endian\n    if (len \u003e k_max_msg) {\n        msg(\"too long\");\n        return -1;\n    }\n\n    // request body\n    err = read_full(connfd, \u0026rbuf[4], len);\n    if (err) {\n        msg(\"read() error\");\n        return err;\n    }\n\n    // do something\n    rbuf[4 + len] = '\\0';\n    printf(\"client says: %s\\n\", \u0026rbuf[4]);\n\n    // reply using the same protocol\n    const char reply[] = \"world\";\n    char wbuf[4 + sizeof(reply)];\n    len = (uint32_t)strlen(reply);\n    memcpy(wbuf, \u0026len, 4);\n    memcpy(\u0026wbuf[4], reply, len);\n    return write_all(connfd, wbuf, 4 + len);\n}\n```\n- line 7과 line 25에서 `read` 가 두 번 되고 있다. \"buffered IO”를 이용하면 syscall을 줄일 수 있다. 한 번의 버퍼에 최대한 많은 양을 읽고 여러 요청을 한번에 파싱하는 방법으로 더 효율적이다. \n\n### Client\n```cpp\nstatic int32_t query(int fd, const char *text) {\n    uint32_t len = (uint32_t)strlen(text);\n    if (len \u003e k_max_msg) {\n        return -1;\n    }\n\n    char wbuf[4 + k_max_msg];\n    memcpy(wbuf, \u0026len, 4);  // assume little endian\n    memcpy(\u0026wbuf[4], text, len);\n    if (int32_t err = write_all(fd, wbuf, 4 + len)) {\n        return err;\n    }\n\n    // 4 bytes header\n    char rbuf[4 + k_max_msg + 1];\n    errno = 0;\n    int32_t err = read_full(fd, rbuf, 4);\n    if (err) {\n        if (errno == 0) {\n            msg(\"EOF\");\n        } else {\n            msg(\"read() error\");\n        }\n        return err;\n    }\n\n    memcpy(\u0026len, rbuf, 4);  // assume little endian\n    if (len \u003e k_max_msg) {\n        msg(\"too long\");\n        return -1;\n    }\n\n    // reply body\n    err = read_full(fd, \u0026rbuf[4], len);\n    if (err) {\n        msg(\"read() error\");\n        return err;\n    }\n\n    // do something\n    rbuf[4 + len] = '\\0';\n    printf(\"server says: %s\\n\", \u0026rbuf[4]);\n    return 0;\n}\n```\n\n이 장에서는 아주 간단한 len 에 대한 프로토콜만 실습하여보았지만 실제 프로토콜은 훨씬 더 복잡하다. 또 바이너리 대신 텍스트를 사용하는데, 이는 사람이 읽기 쉬운 장점이 있지만, 파씽 부분에서 바이너리보다 더 신경써야 하는 부분이 많다. 또 프로토콜에 따라 구분 부호가 달라지거나 없을 수 있기 때문에 프로토콜 분석은 실습보다 더 어려울 수 있다. \n\n\u003e 코드 : https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp/tree/main/04\n\n[[notes/build your own redis with c cpp 2]] 에 이어집니다. \n\n---\n## Source Code \n- [jiyeonseo/build-your-own-redis-with-c-cpp](https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp)\n## References \n- [Build Your Own Redis with C/C++](https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/build-your-own-redis-with-c-cpp-2":{"title":"(Build Your Own Redis with C/C++) 2. Event Loop","content":"\u003e [Build Your Own Redis With C/C++](https://build-your-own.org/redis) 을 보고 정리한 글입니다. 더 자세한 나용은 원문을 참고하실 수 있습니다. 직접 실습한 코드는 [jiyeonseo/build-your-own-redis-with-c-cpp](https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp) 에서 찾아볼 수 있습니다. [[notes/build your own redis with c cpp 1]] 이어지는 노트입니다. \n\n## The Event Loop and Nonblocking IO\n서버와의 네트워킹 동시 연결 처리 방법 3가지 \n- Forking : 클라이언트와의 연결마다 새로운 프로세스 만드는 방법 \n- Multi-threading : 프로세스 대신 여러 쓰레드를 사용하는 방법  \n- Event loops : 폴링과 논블로킹 IO를 이용하는 것으로 주로 단일 쓰레드위에서 실행. 프로세스와 쓰레드 오버헤드로 인해 대부분 이벤트 룹을 많이 사용하는 추세. \n\nevent loop을 이용한 서버쪽은 다음과 같이 표현할 수 있다. \n```\nall_fds = [...]\nwhile True:\n    active_fds = poll(all_fds) # blocking 없이 바로 작동 가능한지 확인 \n    for each fd in active_fds:\n        do_something_with(fd)\n\ndef do_something_with(fd):\n    if fd is a listening socket:\n        add_new_client(fd)\n    elif fd is a client connection:\n        while work_not_done(fd):\n            do_something_to_client(fd)\n\ndef do_something_to_client(fd):\n    if should_read_from(fd):\n        data = read_until_EAGAIN(fd)\n        process_incoming_data(data)\n    while should_write_to(fd):\n        write_until_EAGAIN(fd)\n    if should_close(fd):\n        destroy_client(fd)\n```\n- `fd` 로 IO 작업을 하기 위해서는 nonblocking 모드여야 함\n\t- blocking 모드에서는 아래와 같은 경우 block 된다. \n\t\t- `read`  실행시 커널에 데이터가 없으면\n\t\t- `write` 실행시 버퍼가 가즉 찼으면 \n\t\t- `accept` 실행시 커널 큐에 커넥션이 없으면 \n\t- nonblocking 모드에서는, 그냥 성공 하거나 아직 준비 안됨 오류인 `EAGAIN` 오류를 내며 실패. \n\t\t- `EAGAIN` 오류가 나면 `poll` 을 통해 준비가 다 끝난 후 다시 시도해야만 함. \n- `poll` : 이벤트 룹에서의 유일한 blocking 작업. \n- 논블락킹 모드에서 blocking 밖에 지원하지 않는 API (예를 들어 `gethostbyname` 이나 disk IO) 는 쓰레드 풀에서 수행해야만 한다. \n- `fd`를 논블락킹 모드로 세팅하기 위해서는 `fcntl`을 사용하면 된다. \n```cpp\nstatic void fd_set_nb(int fd) {\n    errno = 0;\n    int flags = fcntl(fd, F_GETFL, 0);\n    if (errno) {\n        die(\"fcntl error\");\n        return;\n    }\n\n    flags |= O_NONBLOCK;\n\n    errno = 0;\n    (void)fcntl(fd, F_SETFL, flags);\n    if (errno) {\n        die(\"fcntl error\");\n    }\n}\n```\n- Linux에서는 `poll` 이외에도 `select`, `epoll`과 같은 syscall들이 있다. \n\t- `select` : 기본적으로는 `poll`과 비슷. 하지만 최대 `fd` 제한수가 적어 요즘에는 사용되고 있지 않음. \n\t- `epoll` : stateful API. \n\t\t- `epoll_create` : `fd` 생성\n\t\t- `epoll_wait` : `fd` 작동 \n\t\t- `epoll_ctl` : `fd` 조작\n\n위 Event loop을 이용해서 서버 코드를 업데이트 해보자. 먼저 `Conn`.   \n```cpp\nenum {\n    STATE_REQ = 0,\n    STATE_RES = 1,\n    STATE_END = 2,  // mark the connection for deletion\n};\n\nstruct Conn {\n    int fd = -1;\n    uint32_t state = 0;     // either STATE_REQ or STATE_RES\n    // buffer for reading\n    size_t rbuf_size = 0;\n    uint8_t rbuf[4 + k_max_msg];\n    // buffer for writing\n    size_t wbuf_size = 0;\n    size_t wbuf_sent = 0;\n    uint8_t wbuf[4 + k_max_msg];\n};\n```\n- nonblocking 모드에서 IO 작업(read, write)를 위한 버퍼 필요 \n- `state` connection 상태용 \n\t- `STATE_REQ` : reqding request 용 \n\t- `STATE_RES` : sending response 용\n\n```cpp \n    int fd = socket(AF_INET, SOCK_STREAM, 0);\n    if (fd \u003c 0) {\n        die(\"socket()\");\n    }\n\n    // bind, listen and etc\n    // code omitted...\n\n    // a map of all client connections, keyed by fd\n    std::vector\u003cConn *\u003e fd2conn;\n\n    // set the listen fd to nonblocking mode\n    fd_set_nb(fd);\n\n    // the event loop\n    std::vector\u003cstruct pollfd\u003e poll_args;\n    while (true) {\n        // prepare the arguments of the poll()\n        poll_args.clear();\n        // for convenience, the listening fd is put in the first position\n        struct pollfd pfd = {fd, POLLIN, 0};\n        poll_args.push_back(pfd);\n        // connection fds\n        for (Conn *conn : fd2conn) {\n            if (!conn) {\n                continue;\n            }\n            struct pollfd pfd = {};\n            pfd.fd = conn-\u003efd;\n            pfd.events = (conn-\u003estate == STATE_REQ) ? POLLIN : POLLOUT;\n            pfd.events = pfd.events | POLLERR;\n            poll_args.push_back(pfd);\n        }\n\n        // poll for active fds\n        // the timeout argument doesn't matter here\n        int rv = poll(poll_args.data(), (nfds_t)poll_args.size(), 1000);\n        if (rv \u003c 0) {\n            die(\"poll\");\n        }\n\n        // process active connections\n        for (size_t i = 1; i \u003c poll_args.size(); ++i) {\n            if (poll_args[i].revents) {\n                Conn *conn = fd2conn[poll_args[i].fd];\n                connection_io(conn);\n                if (conn-\u003estate == STATE_END) {\n                    // client closed normally, or something bad happened.\n                    // destroy this connection\n                    fd2conn[conn-\u003efd] = NULL;\n                    (void)close(conn-\u003efd);\n                    free(conn);\n                }\n            }\n        }\n\n        // try to accept a new connection if the listening fd is active\n        if (poll_args[0].revents) {\n            (void)accept_new_conn(fd2conn, fd);\n        }\n    }\n```\n- 이벤트 룹에서 가장 먼저 필요한 것은 `poll` 설정\n\t- listening `fd`  :  `POLLIN`  상태로 \n\t- connection `fd` :  struct `Conn` 에 따라 상태가 변경 \n- 때에 따라, poll 상태가 reading(`POLLIN`) 이거나 writing (`POLLOUT`)이 아닌 경우도 있다. \n- `epoll`을 사용한다면 `epoll_ctl` 로 설정된 `fd` 로 업데이트 해주어야 한다. \n- `poll` argument로 timeout 값 설정도 있는데 여기서는 크게 중요하지 않음으로 임의의 큰 수를 넣어줌. \n- `poll`을 반환 받으면 reading/writing 준비가 될때 마다 알림을 받을 수 있다. \n- `accept_new_conn` 은 새로운 connection을 받고 `struct Conn` 객체를 만든다. (아래)\n\n```cpp\nstatic int32_t accept_new_conn(std::vector\u003cConn *\u003e \u0026fd2conn, int fd) {\n    // accept \n    struct sockaddr_in client_addr = {};\n    socklen_t socklen = sizeof(client_addr);\n    int connfd = accept(fd, (struct sockaddr *)\u0026client_addr, \u0026socklen);\n    if (connfd \u003c 0) {\n        msg(\"accept() error\");\n        return -1;  // error\n    }\n\n    // set the new connection fd to nonblocking mode\n    fd_set_nb(connfd);\n    // creating the struct Conn\n    struct Conn *conn = (struct Conn *)malloc(sizeof(struct Conn));\n    if (!conn) {\n        close(connfd);\n        return -1;\n    }\n    conn-\u003efd = connfd;\n    conn-\u003estate = STATE_REQ;\n    conn-\u003erbuf_size = 0;\n    conn-\u003ewbuf_size = 0;\n    conn-\u003ewbuf_sent = 0;\n    conn_put(fd2conn, conn);\n    return 0;\n}\n```\n- 클라이언트 연결 상태 체크(state machine)를 위한 `connection_io()`\n```cpp\nstatic void connection_io(Conn *conn) {\n    if (conn-\u003estate == STATE_REQ) {\n        state_req(conn);\n    } else if (conn-\u003estate == STATE_RES) {\n        state_res(conn);\n    } else {\n        assert(0);  // not expected\n    }\n}\n```\n- `STATE_REQ` 는 읽기 상태 \n```cpp\nstatic void state_req(Conn *conn) {\n    while (try_fill_buffer(conn)) {}\n}\n\nstatic bool try_fill_buffer(Conn *conn) {\n    // try to fill the buffer\n    assert(conn-\u003erbuf_size \u003c sizeof(conn-\u003erbuf));\n    ssize_t rv = 0;\n    do {\n        size_t cap = sizeof(conn-\u003erbuf) - conn-\u003erbuf_size;\n        rv = read(conn-\u003efd, \u0026conn-\u003erbuf[conn-\u003erbuf_size], cap);\n    } while (rv \u003c 0 \u0026\u0026 errno == EINTR);\n    if (rv \u003c 0 \u0026\u0026 errno == EAGAIN) {\n        // got EAGAIN, stop.\n        return false;\n    }\n    if (rv \u003c 0) {\n        msg(\"read() error\");\n        conn-\u003estate = STATE_END;\n        return false;\n    }\n    if (rv == 0) {\n        if (conn-\u003erbuf_size \u003e 0) {\n            msg(\"unexpected EOF\");\n        } else {\n            msg(\"EOF\");\n        }\n        conn-\u003estate = STATE_END;\n        return false;\n    }\n\n    conn-\u003erbuf_size += (size_t)rv;\n    assert(conn-\u003erbuf_size \u003c= sizeof(conn-\u003erbuf) - conn-\u003erbuf_size);\n\n    // Try to process requests one by one.\n    // Why is there a loop? Please read the explanation of \"pipelining\".\n    while (try_one_request(conn)) {}\n    return (conn-\u003estate == STATE_REQ);\n}\n```\n- `try_fill_buffer` : read buffer를 데이터로 채워주는 함수 \n\t- read buffer가 제한적이기 때문에 만약 꽉 차게 되면 그 전에 `EAGAIN` 에러를 발생시킨다. \n\t- 따라서, 읽기 후 read buffer를 처리하고 `EAGAIN` 발생 전까지 룹을 돈다. \n- `read` syscall은 `EINTR` 에러 후에 리트라이 해주어야 한다.\n\t- `EINTR`은 syscall이 중단 되었다는 뜻으로, 어플리케이션과 상관 없이 재시도를 해주어야 한다. \n- `try_fill_buffer` 에서 loop을 도는 이유 \n\t- 요청/응답 프로토콜에서 클라이언트가 요청 보내놓고 계속 기다리는 것이 아니라 계속 필요한 요청을 계속 보낼 수 있으면 시간을 더 절약할 수 있음. -\u003e \"pipelining\" \n\t- 따라서, read buffer에 하나의 요청만 포함된다 라고 할 수 없음. 하나의 read buffer에는 여러 요청이 있을 수 있음. \n- `try_one_request` 에서 read buffer에 있는 요청 하나씩을 꺼내와 응답을 만들고 `STATE_RES` 상태값으로 변경한다. \n```cpp\nstatic bool try_one_request(Conn *conn) {\n    // try to parse a request from the buffer\n    if (conn-\u003erbuf_size \u003c 4) {\n        // not enough data in the buffer. Will retry in the next iteration\n        return false;\n    }\n    uint32_t len = 0;\n    memcpy(\u0026len, \u0026conn-\u003erbuf[0], 4);\n    if (len \u003e k_max_msg) {\n        msg(\"too long\");\n        conn-\u003estate = STATE_END;\n        return false;\n    }\n    if (4 + len \u003e conn-\u003erbuf_size) {\n        // not enough data in the buffer. Will retry in the next iteration\n        return false;\n    }\n\n    // got one request, do something with it\n    printf(\"client says: %.*s\\n\", len, \u0026conn-\u003erbuf[4]);\n\n    // generating echoing response\n    memcpy(\u0026conn-\u003ewbuf[0], \u0026len, 4);\n    memcpy(\u0026conn-\u003ewbuf[4], \u0026conn-\u003erbuf[4], len);\n    conn-\u003ewbuf_size = 4 + len;\n\n    // remove the request from the buffer.\n    // note: frequent memmove is inefficient.\n    // note: need better handling for production code.\n    size_t remain = conn-\u003erbuf_size - 4 - len;\n    if (remain) {\n        memmove(conn-\u003erbuf, \u0026conn-\u003erbuf[4 + len], remain);\n    }\n    conn-\u003erbuf_size = remain;\n\n    // change state\n    conn-\u003estate = STATE_RES;\n    state_res(conn);\n\n    // continue the outer loop if the request was fully processed\n    return (conn-\u003estate == STATE_REQ);\n}\n```\n\n변경된 conn을 받는 `state_res` 는 아래와 같다.\n- `EAGAIN` 이 될때까지 계속 write buffer를 flush 하고, flush가 완료되면 state를 `STATE_REQ`로 바꿔준다.  \n\n```cpp\nstatic void state_res(Conn *conn) {\n    while (try_flush_buffer(conn)) {}\n}\n\nstatic bool try_flush_buffer(Conn *conn) {\n    ssize_t rv = 0;\n    do {\n        size_t remain = conn-\u003ewbuf_size - conn-\u003ewbuf_sent;\n        rv = write(conn-\u003efd, \u0026conn-\u003ewbuf[conn-\u003ewbuf_sent], remain);\n    } while (rv \u003c 0 \u0026\u0026 errno == EINTR);\n    if (rv \u003c 0 \u0026\u0026 errno == EAGAIN) {\n        // EAGAIN 이 되면 멈춘다.\n        return false;\n    }\n    if (rv \u003c 0) {\n        msg(\"write() error\");\n        conn-\u003estate = STATE_END;\n        return false;\n    }\n    conn-\u003ewbuf_sent += (size_t)rv;\n    assert(conn-\u003ewbuf_sent \u003c= conn-\u003ewbuf_size);\n    if (conn-\u003ewbuf_sent == conn-\u003ewbuf_size) {\n        // response가 모두 보내지면, STATE_REQ로 다시 state를 바꾸어 준다.\n        conn-\u003estate = STATE_REQ;\n        conn-\u003ewbuf_sent = 0;\n        conn-\u003ewbuf_size = 0;\n        return false;\n    }\n    // 아직 write buffer(wbuf)에 데이터가 남아있다면 다시 쓰기를 시도한다.\n    return true;\n}\n```\n\n\u003e 코드 : https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp/tree/main/06","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/build-your-own-redis-with-c-cpp-3":{"title":"(Build Your Own Redis with C/C++) 3. Implement basic commands","content":"\u003e [Build Your Own Redis With C/C++](https://build-your-own.org/redis) 을 보고 정리한 글입니다. 더 자세한 나용은 원문을 참고하실 수 있습니다. 직접 실습한 코드는 [jiyeonseo/build-your-own-redis-with-c-cpp](https://github.com/jiyeonseo/build-your-own-redis-with-c-cpp) 에서 찾아볼 수 있습니다. [[notes/build your own redis with c cpp 2]] 이어지는 노트입니다. \n\n기본 command 스키마는 아래와 같이 한다. \n```\n+------+-----+------+-----+------+-----+-----+------+\n| nstr | len | str1 | len | str2 | ... | len | strn |\n+------+-----+------+-----+------+-----+-----+------+\n```\n- `nstr` : number of string. 문자열 갯수. (32 bits)\n- `len` : length of the following string. 문자열 길이 (32 bits)\n\n응답은 아래와 같이 32 bits 상태 코드와 응답 메세지로 구성된다. \n```\n+-----+---------+\n| res | data... |\n+-----+---------+\n```\n\n\n## `get`, `set`, `del`\n","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/common-vulnerabilities-with-nodejs":{"title":"서버 개발하며 쉽게 놓치는 취약점 5가지","content":"## 1.  Injection Attacks\n- [[SQL Injection]]\n- [[NoSQL Injection]]\n- [[Common Injection]]\n```javascript\napp.get(\"/user\", (req, res) =\u003e {\n  const id = req.query.id;\n  const query = `SELECT * FROM users WHERE id = ${id}`;\n```\n- 문제점 : query parameter `id`로 `1 OR 1=1`와 같이 오게되면 `SELECT * FROM users WHERE id = 1 OR 1=1` 처럼 쿼리문이 되어 전체 users를 return 할 위험이있다. \n- 개선 : prepared statement로 쿼리하고 `id` 체크 후 사용하도록 \n\t- user input validation 중요!\n```javascript\napp.get(\"/user\", (req, res) =\u003e {\n  const id = req.query.id;\n  const query = \"SELECT * FROM users WHERE id = ?\";\n  connection.query(query, [id], (error, results) =\u003e {\n    if (error) {\n      throw error;\n    }\n    res.send(results);\n  });\n});\n```\n\n## 2.  Cross-Site Scripting (XSS)\n- 웹사이트를 통해 악의적인 스크립트를 삽입하여 공격.\n- URL param으로 스크립트를 삽입하여, 스크립트가 실행되도록 유도 \n```javascript\napp.get(\"/\", (req, res) =\u003e {\n\tconst name = req.query.name; \n\tres.send(`\u003ch1\u003eHello, ${name}\u003c/h1\u003e`); \n});\n```\n- 문제점 : param `\u003cscript\u003ealert('XSS')\u003c/script\u003e` 와 같이 들어오는 경우\n\n## 3.  Denial-of-Service (DoS)\n\n## 4.  Improper Authentication and Authorization\n\n## 5.  Insecure Direct Object References\n\n\n## References\n- [# 5 Common Server Vulnerabilities with Node.js](https://blog.javascripttoday.com/blog/node-js-server-vulnerabilities/)\n","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/erc-20":{"title":"ERC-20","content":"- [ERC-20 Token Standard](https://ethereum.org/en/developers/docs/standards/tokens/erc-20/)\n\n- 각 토큰은 다른 토큰과 정확히 동일한 속성을 가지고 있다. ETH과 동일하게 작동하며, 1개의 토큰은 다른 토큰과 항상 같다. \n\n```sol\nmapping(address =\u003e uint256) private _balances;\n```\n- 누가(adress) =\u003e 얼마(unit256) 를 가지고 있는지 저장  \n\n## Methods \n```\nfunction name() public view returns (string)\nfunction symbol() public view returns (string)\nfunction decimals() public view returns (uint8)\nfunction totalSupply() public view returns (uint256)\nfunction balanceOf(address _owner) public view returns (uint256 balance)\nfunction transfer(address _to, uint256 _value) public returns (bool success)\nfunction transferFrom(address _from, address _to, uint256 _value) public returns (bool success)\nfunction approve(address _spender, uint256 _value) public returns (bool success)\nfunction allowance(address _owner, address _spender) public view returns (uint256 remaining)\n\n```\n- `transfer` : `from` 계좌 =\u003e `to`계좌로 잔고를 바꿈 ([구현 코드](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/ERC20.sol#L226-L248))\n\n## References\n- [OpenZeppelin - ERC-20 Implementation](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/contracts/token/ERC20/ERC20.sol)\n- ","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/ethereum-2.0":{"title":"이더리움 2.0","content":"- PoW(작업증명) 으로 보완하지 못했던 부분들을 \n- PoS(지분증명)의 시간 단위는 슬롯과 에팍\n\n## 밸리데이터 \n- 보증금 32ETH 를 예치하여야 한다.\n- 역할 \n\t- 밸리데이터 집단을 저장 및 유지 관리 \n\t- Crosslinks 처리\n\t- 블록 합의 처리\n\n## 슬롯 (slot)\n- 시간의 가장 작은 단위 \n- 12초 = 1 슬롯 (1 슬롯당 1개의 블록 형성)\n- 32슬롯 = 1 에팍. 즉 384초 = 1 에팍\n\n## 에팍 (epoch)\n- 매 에팍마다 모든 밸리데이터들에게 임무가 주어짐 \n- 1 에팍 = 32 슬롯 이므로, 32 밸리데이터를 선택, 각 슬롯에 배치\n\t- 이들이 블록 프로듀서. 블록을 만듬\n\t- 이 밸리데이터들은 블록 만들고 검증도 하여 \"노드 위원회\" 라고도 부른다.\n\t- 2/3 노드 위원회가 이 블록이 정확하다 승인하면 검증이 완료 됨. \n- 모든 검증이 완료되면 다음 에팍에서 새로운 슬롯에 각 밸리데이터들 배치 \n\n## 비콘체인\n- 밸리데이터들을 램덤하게 배치하고 상태 저장 관리.\n\n## References\n- [해시넷 - 슬롯](http://wiki.hash.kr/index.php/%EC%8A%AC%EB%A1%AF_(%EB%B8%94%EB%A1%9D%EC%B2%B4%EC%9D%B8))\n- [# Ethereum 2.0 Phase 0 -- Beacon Chain Fork Choice](https://github.com/ethereum/annotated-spec/blob/master/phase0/fork-choice.md)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/ethers.js":{"title":"ethers.js","content":"- [ethers.js](https://docs.ethers.io/v5/)\n-  Web3 JavaScript 라이브러리로 2016년에 Richard Moore가 만들었다. \n- 기존 라이브러리와 다르게 web3 기반으로 [[notes/Ethereum]] 네트워크와 상호작용이 쉽다.\n- 처음에는 ethers.io를 위해 만들어졌음\n- Typescript로 작성되어있으며 \n\n## References\n-[Full Guide: What is Ethers.js?](https://moralis.io/full-guide-what-is-ethers-js/)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/hard-fork":{"title":"하드포크","content":"\n- 블록체인 업그레이드 작업\n- 기존 블록체인에서 다른 블로체인으로 넘어갈때 사용하는 방식\n\n## 이유 \n- 기술적 문제 혹은 보안 개선을 위해\n- 새로운 기능을 추가 하기 위해 \n- 거래 반전을 위해","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/memorydb":{"title":"MemoryDB","content":"- [Redis Cluster](https://redis.io/docs/management/scaling/)로 다중AZ 트랜잭션으로 빠르게 읽으면서도 내구성있는 DB. \n- 따로 RDB + Cache 구성 필요 없이, Redis 구성 하나만으로 Consistency와 속도의 장점을 모두 가질 수 있다.\n\n## 특징 \n- 복제본 노드에 대한 일관성 보장\n- milisecond 단위 write와 microsecond 단위의 read\n- Redis client 그대로 사용 가능\n### Cluster\n- 노드의 모음\n\t- primary node : 읽기/쓰기\n        - readonly : 읽기\n- 데이터 세트는 샤드로 분할되어 저장됨\n### Node\n- Amazon EC2 instance\n### Shard\n- primary\n\n## Terraform 으로 Cluster 만들기\n\n```sql\nresource \"aws_memorydb_cluster\" \"example\" {\n  acl_name                 = \"open-access\"\n  name                     = \"my-cluster\"\n  node_type                = \"db.t4g.small\"\n  num_shards               = 2\n  security_group_ids       = [aws_security_group.example.id]\n  snapshot_retention_limit = 7\n  subnet_group_name        = aws_memorydb_subnet_group.example.id\n}\n```\n\n-   [(Terraform) ****Resource: aws_memorydb_cluster****](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/memorydb_cluster)\n\n## References\n- [Amazon MemoryDB for Redis](https://docs.aws.amazon.com/memorydb/latest/devguide/what-is-memorydb-for-redis.html)\n","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/readme.io-setting":{"title":"readme.io 세팅","content":"\n## API References Try it Authentication  추가하기 \n![](https://user-images.githubusercontent.com/2231510/205079888-b4b68d17-aefc-4043-be51-6a94e89e64cd.png)\n- `openapi.json` 으로 싱크하는 경우, open api spec 중 `SecurityScheme` 을 맞춰주어야 한다. \n- [Security Scheme Object](https://docs.readme.com/main/docs/openapi-compatibility-chart#security-scheme-object)\n\n### FastAPI에서 추가하기 \n```python\nfrom fastapi import FastAPI, Security\nfrom fastapi.security import APIKeyHeader\n\nx_api_key = APIKeyHeader(name=\"x-api-key\", auto_error=False)\n\nasync def auth(x_api_key: str = Security(x_api_key)):\n  if x_api_key == get_config(\"API_KEY\"):\n    return x_api_key\n  else:\n    raise UnauthorizedException()\n\nrouter = APIRouter(dependencies= [Depends(auth)])\n\napp = FastAPI()\napp.include_router(router)\n\n```\n\nswagger에서도 Authorize가 생긴 것을 볼 수 있다. \n![](https://user-images.githubusercontent.com/2231510/205088702-dc58cc59-75d9-47d1-8215-2329a673400d.png)\n`openapi.json` 확인하면 `components.securitySchemes` 가 추가 되어있다.\n![](https://user-images.githubusercontent.com/2231510/205089535-3e12ea04-6082-44ff-93f3-ac7ca1e3a491.png)\n- default값 까지 넣으려면 아래와 같이 `x-default` 를 추가해주면 된다.\n ```json\nsecurityDefinitions: {\n     API_KEY: {\n        type: \"apiKey\",\n        name: \"x-api-key\",\n        in: \"header\",\n        \"x-default\": \"demo-api-key\",\n\t},\n},\n```\n- [swagger authentication spec](https://swagger.io/docs/specification/authentication/) ","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/search-engine-hello":{"title":"hello 검색 엔진","content":"- [https://beta.sayhello.so/](https://beta.sayhello.so/)\n- The search engine for instant answers\n- 질문에 대해 바로 대답(answer)를 보여주고 써먹을 수 있는 코드 조각을 바로 보여주는 개발자 친화 검색 엔진 \n\n![](https://user-images.githubusercontent.com/2231510/204835776-eae19bc0-3a41-44c9-bed5-03ddbd0d51fd.png)\n\n\n## How to best use Hello\n- 자연어 검색어 지원. \n- `How to~` `What is~` 와 같이 검색하기\n- \"check if string is a palindrome\" =\u003e \"how to check if string is a palindrome in javascript\"\n- 질문 형식으로 검색하기 \n\t- \"rust\" =\u003e \"what is rust?\"\n\n## VSCode Extension\n\n![](https://hello-code-snippets-vscode-extension-assets-public.s3.amazonaws.com/demo.png)\n\n- [Hello Code Snippets](https://marketplace.visualstudio.com/items?itemName=HelloCognition.hello-code-snippets)\n","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/stable-coin":{"title":"스테이블코인","content":"\n## References\n","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/supabase":{"title":"supabase","content":"- [supabase](https://supabase.com/)\n- Fairebase 대체제로 오픈소스 프로젝트. Backend as a Service로 백엔드 서버를 간단한 설정만으로 빠르게 구축해준다. \n\n## Features\n### Database\n- PostgreSQL \n- JWT authentication을 이용하여 클라이언트단에서 바로 SQL 쿼리가 들어오더라도 룰에 맞게 쿼리 실행. \n- 간단한 CRUD는 supabase에서 제공하는 instant API를 이용하여 바로 쿼리 가능 \n- \n\n## Authentication\n\n## Storage\n\n## Edge Functions\n\n## Realtime\n","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/unleash":{"title":"unleash","content":"- 피쳐 토글 서비스 (비슷한 서비스로는 [[notes/LaunchDarkly]] 가 있다.)  \n- 코드 배포와 기능 배포를 서로 분리시킴으로써 더욱 안전한 배포 유연한 기능 오픈/클로즈를 수행할 수 있다. \n- Client (Server Side) / Frontend (Web+Mobile) 각각의 SDK를 잘 지원하고 있어 여러 방면에서 사용하기 좋다. \n![](https://docs.getunleash.io/assets/images/unleash-architecture-40c7293e777a7bea0df4edeeef8a6bf4.svg)\n- Enterprise와 opensource 둘 다 제공하고 있어 입맛에 알맞게 사용할 수 있다. \n\t- Managed 는 $80/Month\n\t- [Dockerfile](https://docs.getunleash.io/reference/deploy/getting-started)\n\t- [Helm chart](https://github.com/unleash/helm-charts/)\n\t\n## Feature 토글 타입\n- Unleash에서는 5가지 토글 타입을 제공하고 있다. ([doc](https://docs.getunleash.io/reference/feature-toggle-types))\n- 토글 타입별로 기능차이는 없으며 표현되는 **아이콘 모양만 다르고** 각각의 **예상 수명시간**이 다를 뿐이다. \n\t- 토글 타입을 정했더라도 나중에 변경 가능하다. \n\t- [타입별 예상 수명시간](https://www.getunleash.io/blog/feature-toggle-life-time-best-practices) \n- Feature 토글 타입\n\t- Release : trunk based 환경에서 CD에서 계속해서 배포시 (예상 수명 : 40 days)\n\t- Experiment : 여러 변수를 사용하는 경우 혹은 A/B 테스팅(예상 수명 : 40 days)\n\t- Operational :  운영 측면에서 사용하는 경우 (예상 수명 : 7 days)\n\t- Kill switch : 천천히 기능 삭제해나갈때. (예상 수명 : 영구) - [kill switch best practice](https://www.getunleash.io/blog/kill-switches-best-practice)\n\t- Permission : 특정 유저들에게만 기능 혹은 프러덕트를 열어주는 경우 (예상 수명 : 영구)\n- `stale` 로 mark 해주면 더 이상 사용하지 않는 토글로 표시해둘 수 있다. \n\t- \u0008바로 삭제하게 되면 혹시나 예상치 못한 장애로 이어질 수 있지만 이렇게 먼저 표시를 해두게 되면 \"health\" 탭에서 stale 된 토글이 현재 얼마나 들어오고 있는지 확인할 수 있다. \n\t- [Technical Debt](https://docs.getunleash.io/reference/technical-debt) 이 기능이 깨끗한 코드를 유지하는데 큰 도움이 될 것 같다.\n\n![](https://user-images.githubusercontent.com/2231510/208935165-cda5e879-5848-47e7-a15a-357c8e5daae8.png)\n\n## API Token 만들기 \n- [How to create API Tokens](https://docs.getunleash.io/how-to/how-to-create-api-tokens)\n- 연결 코드에서 사용할 API Token을 먼저 만들어야 한다.\n- 서버사이드는 Type `Client`, 모바일이나 웹은 Type `Frontend`, Unleash 자체에 대한 API를 위해서는 Type `Admin` 으로 만들면 된다.\n- environment 마다 token을 발행하여 환경별로 기능을 조절할 수 있다. \n![](https://user-images.githubusercontent.com/2231510/208928220-536afe05-ba09-4875-8dc4-6bb8d223f4c7.png)\n- 생성하면 SDK에서 연결시 사용해야하는 \"API URL\"이 나온다. \n\t- managed를 사용하게되면 `https://us.app.unleash-hosted.com/**/api/` \n\n## SDK 연결하기 - Python\n- [Python SDK](https://docs.getunleash.io/reference/sdks/python)\n```py \nfrom UnleashClient import UnleashClient  \n  \nclient = UnleashClient(  \nurl=\"`https://us.app.unleash-hosted.com/**/api/\",  # 위에서 받은 API URL 입력\napp_name=\"\u0008cheese\", # 나중에 admin ui에서 applications에 뜬다.  \ncustom_headers={'Authorization': '\u003cAPI token\u003e'})  # 위에서 만든 API token Thpe \"Client\"\n  \nclient.initialize_client()  \n  \nclient.is_enabled(\"unleash.beta.variants\")\n```\n- 위와 같이 연결 후 서버를 시작하면 다음과 같이 연결된 application들을 확인 할 수 있다. \n![](https://user-images.githubusercontent.com/2231510/208928977-8bd642f0-578c-4351-9915-04658a9725a6.png)\n\n\n## References\n- [맘편한세상에서 사용하는 피쳐 토글 서비스](https://tech.mfort.co.kr/blog/2022-11-24-feature-toggle/)\n- [# Feature Toggles (aka Feature Flags)](https://martinfowler.com/articles/feature-toggles.html)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null},"/notes/upload-python-library":{"title":"Python Project package PyPi에 올리기","content":"\n## pip 설치\n- Unix/mac OS\n```sh\npython3 -m pip install --upgrade pip\n```\n- windows\n```\npy -m pip install --upgrade pip\n```\n\n## Project 생성\n간단한 프로젝트 `packaging_tutorial` 다음과 같은 구성으로 준비한다. \n```\npackaging_tutorial/ \n└── src/\n    └── example_package_cheese/\n        ├── __init__.py\n        └── example.py\n```\n- `example_package_cheese` : project 명과 동일하게 해주는 것이 좋다. 설정도 더 간편하고 패키지사용자 입장에서도 구분하기 좋다. \n- `__init__.py` : 비어있는 파일. directory 자체를 package로 import 하기 위해 필요.\n- `example.py` : 실제 로직이 담길 파일. 아래와 같이 실제 로직을 추가해준다. \n```pyhon\ndef add_one(number):\n    return number + 1\n```\n\n## Package Files 생성\n\n```\npackaging_tutorial/\n├── LICENSE\n├── pyproject.toml\n├── README.md\n├── src/\n│   └── example_package_YOUR_USERNAME_HERE/\n│       ├── __init__.py\n│       └── example.py\n└── tests/\n```\n- `pyproject.toml` : 프로젝트 빌드 시스템 요구 사항과 정보를 담고 있는 파일 \n\t- 빌드툴로는 [Hatchling](https://packaging.python.org/en/latest/key_projects/#hatch), [setuptools](https://packaging.python.org/en/latest/key_projects/#setuptools), [Filt](https://packaging.python.org/en/latest/key_projects/#flit). [PDM](https://packaging.python.org/en/latest/key_projects/#pdm) 등이 있으며 여기서는 Hatchling으로 진행한다. \n```\n# Hatchlling\n[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n# setuptools\n[build-system]\nrequires = [\"setuptools\u003e=61.0\"]\nbuild-backend = \"setuptools.build_meta\"\n\n# filt\n[build-system]\nrequires = [\"flit_core\u003e=3.4\"]\nbuild-backend = \"flit_core.buildapi\"\n```\n- `requires` : 패키지를 빌드하는데 필요한 패키지 목록. \n\t- pip 와 같은 빌드 프론트엔드들에서 자동으로 격리된 virtual enviroment에서 임시로 설치하여 빌드에 사용되기 때문에 따로 설치할 필요는 없다. \n- `build-backend` : 빌드 프론트엔드에서 빌드할때 사용하는 Python 객체명\n\n###  `pyproject.toml` 에 metadata 작성하기 \n```toml\n[project]\nname = \"example_package_YOUR_USERNAME_HERE\"\nversion = \"0.0.1\"\nauthors = [\n  { name=\"Example Author\", email=\"author@example.com\" },\n]\ndescription = \"A small example package\"\nreadme = \"README.md\"\nrequires-python = \"\u003e=3.7\"\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\n\n[project.urls]\n\"Homepage\" = \"https://github.com/pypa/sampleproject\"\n\"Bug Tracker\" = \"https://github.com/pypa/sampleproject/issues\"\n```\n- `name` : 패키지의 이름. PyPI에 이미 올라와 있는 이름과 겹칠 수 없다. \n- `version` : 패키지의 버전.  [version spec](https://packaging.python.org/en/latest/specifications/version-specifiers/#version-specifiers)\n- `authors` : 작성자. `maintainers`도 동일한 모양으로 작성할 수 있다.\n- `readme` :  패키지 readme 파일 path\n- `requires-python` : 필요 python 버전 명시\n- `classifiers` : 추가적인 메타데이터. 호환 python 버전, 라이센스, OS 등. [PyPi classifier 목록](https://pypi.org/classifiers/)\n- `[project]` 에 사용할 수 있는 더 많은 메타데이터들은 [project metadata specification](https://packaging.python.org/en/latest/specifications/declaring-project-metadata/#declaring-project-metadata) 에서 확인 할 수 있다. \n- 이외에도 `keyword` 를 통해 사용자들이 더 찾기 쉽게 키워드를 등록할 수도 있고, `dependencies`를 이용하여 패키지에 필요한 dependecies들도 관리 할 수 있다. \n\n## \u0008패키지 빌드하기 \npip build를 위하여 PyPA build 설치 \n```\n# Unix/mac OS\npy -m pip install --upgrade build\n\n# Windows\npython3 -m pip install --upgrade build\n```\n\n위에 작성한 `pyproject.toml` 파일 위치에서 아래 커맨드로 빌드하기 \n```\n# Unix/mac OS\npython3 -m build\n\n# Windows\npy -m build\n```\n\n빌드하고 나면 아래와 같이 `/dist` directory가 생성된다. \n```\ndist/\n├── example_package_YOUR_USERNAME_HERE-0.0.1-py3-none-any.whl\n└── example_package_YOUR_USERNAME_HERE-0.0.1.tar.gz\n```\n- `.tar.gz` : [source distribution](https://packaging.python.org/en/latest/glossary/#term-Source-Distribution-or-sdist)\n- `.whl` : [built distribution](https://packaging.python.org/en/latest/glossary/#term-Built-Distribution) \n- 최신 pip는 `.whl` 로 우선적으로 설치되지만, 호환이 안되는 경우 `.tar.gz`으로 \n\n## 패키지 업로드하기 \n- 테스트 업로드를 하기 위해 TestPyPI 계정 만들기 \n\t- https://test.pypi.org/account/register/ (email verification 반드시 필요)\n\t- 더 자세한 사항은 [Using TestPyPI](https://packaging.python.org/en/latest/guides/using-testpypi/) 를 참고\n\t- 업로드를 위해서 [API Token](https://test.pypi.org/help/#apitoken) 을 사용하는데 API token은  [TestPyPI account](https://test.pypi.org/manage/account/#api-tokens) 에서 생성할 수 있다. \n\n업로드 하기 위하여 [twine](https://packaging.python.org/en/latest/key_projects/#twine) 을 먼저 설치\n```\n# Unix/macOS\npython3 -m pip install --upgrade twine\n\n# Windows\npy -m pip install --upgrade twine\n```\n\ntwine 이용하여 아래와 같이 업로드 할 수 있다. \n```\n# Unix/macOS\npython3 -m twine upload --repository testpypi dist/*\n\n# Windows\npy -m twine upload --repository testpypi dist/*\n```\n\n이 과정에서 username과 password를 입력하도록 되어있는데, \n- username :  `__token__` \n- password : 위에서 발급받은 API Token(`pypi-blahblah`)을 입력 \n위 업로드가 성공하면 `https://test.pypi.org/project/example_package_YOUR_USERNAME_HERE`. 에서 올라간 패키지를 확인할 수 있다. \n\u003e 예시 : https://test.pypi.org/project/cheese-package/0.1.0/\n\n## 패키지 설치하기 \n```\n# Unix/macOS\npython3 -m pip install --index-url https://test.pypi.org/simple/ --no-deps example-package-YOUR-USERNAME-HERE\n\n# Windows\npy -m pip install --index-url https://test.pypi.org/simple/ --no-deps example-package-YOUR-USERNAME-HERE\n```\n- `--index-url` :  라이브 되고 있는 PyPI 라이브러리가 아닌 TestPyPI의 라이브러리를 설치시 사용\n- `--no-deps` : 만약 동일한 이름의 라이브러리가 라이브 PyPI에 있는 경우, dependency 설치에 실패하거나 예상치 못한 다른 dependecy가 깔릴 수 있으므로. \n\n```py\nfrom example_package_YOUR_USERNAME_HERE import example\n\nexample.add_one(2)\n```\n\n## pypi.org 에 업로드하기 \n\n- [https://pypi.org] 계정만들기\n- `twine upload dist/*` 로 업로드하기 (이때, 라이브 PyPI로 올리는거니 `--repository` 따로 명시 필요 없음) \n- 패키지 설치시에는 `python -m pip install [your-package]` 로 설치\n\n## References \n- [Packaging Python Projects](https://packaging.python.org/en/latest/tutorials/packaging-projects/)\n- [circleci blog - Publishing a Python package](https://circleci.com/blog/publishing-a-python-package/?utm_source=google\u0026utm_medium=sem\u0026utm_campaign=sem-google-dg--japac-en-dsa-tROAS-auth-brand\u0026utm_term=g_-_c__dsa_\u0026utm_content=\u0026gclid=Cj0KCQiA9YugBhCZARIsAACXxeJChlMZzUeuiklpIknQj03iGqmlmwy4dj2MJIZ0xvahOHsyn1TB0wUaApS3EALw_wcB)","lastmodified":"2023-10-02T05:51:50.819458938Z","tags":null}}